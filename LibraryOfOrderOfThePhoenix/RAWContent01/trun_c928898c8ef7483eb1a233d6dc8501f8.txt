{
  "input": "I want you to identify HQ idiomatic patterns in Rust - for a reference doc for LLMs - saying this following columns  1. Code template 2. context when to use - this idiomatic code leads to either low bugs or to high efficiency or both 3. and it is an anti-pattern in this context 4. any alternate patterns \n\nI want you to do this explicitly from this repository - thoroughly comprehensively - https://github.com/rayon-rs/rayon\n\n## Exploring a programming language in layers\n``` text \nExploration of a langauge in layers \n- Language features independent of OS - L1\n    - no-std in rust\n- standard libraries of the language - L2 is written with the help of L1\n- external libraries of the language - L3 is written with help of only L1 or L1+L2\n    - tokio in Rust, Axum framework\n- now people start using the language\n    - they will find useful-logic-templates for L1, L2, L3 which are basically called idiomatic patterns of the language\n        - important to note\n            - L1-idiomatic is different from L2-idiomatic is different from L3-idiomatic\n            - idiomatic patterns are not thought of when the language features are released, they are discovered as an emergent property of the use the language itself, because a langauge is so complicated that all the permuations of combinations of using it cannot be predicted in advance\n        - these 3 idiomatic collections are 20% of the langauge which can be enough to write\n            - 99% code\n            - with lowest bugs\n            - with highest efficiency (memory usage, time usage)\n            - with easiest readability (long term maintainability)\n- At least in Rust idiomatic-low-bug code means the code which compiles in minimum attempts\n    - This might not be the most efficient code and might not be the most readable code\n    - This is different from other langauges because they can have runtime errors which can be caught at compile time in Rust",
  "output": {
    "introduction_to_rayon_idioms": "Rayon is a data-parallelism library for Rust designed to make converting sequential computations into parallel ones simple, efficient, and safe. Its design philosophy is centered on the principle of 'fearless concurrency', leveraging Rust's ownership and borrowing system to guarantee data-race freedom at compile time. An 'idiomatic' pattern in Rayon is one that uses its high-level abstractions to express parallelism with minimal changes to sequential code, leading to high efficiency, low bugs, and good readability. The cornerstone idiom is transforming a sequential iterator into a parallel one, for example, by changing `.iter()` to `.par_iter()`. This simple change allows Rayon's work-stealing scheduler to automatically and dynamically distribute the computational work across all available CPU cores. Idiomatic Rayon code avoids manual thread management (`std::thread::spawn`) and explicit locking (`Mutex`, `RwLock`) in hot loops, instead favoring functional-style patterns like `map`, `filter`, `fold`, and `reduce` on parallel iterators. The library guarantees that if the code compiles, it is free of data races and the final computed result will be the same as its sequential counterpart. However, a crucial caveat is that the order of side effects (like printing, logging, or I/O) is not guaranteed, as tasks are executed in a non-deterministic order. Therefore, idiomatic code separates pure, parallelizable computation from order-dependent side effects.",
    "parallel_iterator_patterns": [
      {
        "pattern_name": "par_iter()",
        "code_template": "use rayon::prelude::*;\n\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // Changed from .iter()\n         .map(|&i| i * i)\n         .sum()\n}",
        "usage_context": "This is the most common Rayon pattern, used for parallel immutable iteration. It is the direct parallel equivalent of the standard `.iter()`. Use it for CPU-bound, data-parallel tasks where you need to read from a collection to perform calculations, transformations, or aggregations without modifying the original data. It is highly efficient for large datasets as Rayon's work-stealing scheduler automatically balances the load. Its use leads to low bugs because it leverages Rust's borrow checker to prevent data races, guaranteeing that the parallel computation is safe if it compiles.",
        "anti_patterns": "A primary anti-pattern is using `par_iter()` on very small collections or for trivial operations where the overhead of task scheduling exceeds the performance gain from parallelism. It is also an anti-pattern for I/O-bound tasks (like network requests), which should use async runtimes. Attempting to mutate shared state (e.g., via a `Mutex`) inside the closure can lead to heavy lock contention, serializing execution and negating the benefits of parallelism.",
        "alternate_patterns": "For small workloads or I/O-bound tasks, the standard sequential `iter()` is the correct choice. To improve granularity on collections with many small but non-trivial items, one can use `par_chunks()` to process items in batches, ensuring each parallel task has a substantial amount of work."
      },
      {
        "pattern_name": "par_iter_mut()",
        "code_template": "use rayon::prelude::*;\n\nfn increment_all(data: &mut [i32]) {\n    data.par_iter_mut().for_each(|p| *p += 1);\n}",
        "usage_context": "This pattern is used for parallel mutable iteration, allowing for in-place modification of elements in a collection. It is the direct parallel equivalent of `.iter_mut()`. It is highly efficient for CPU-bound tasks that involve updating each element of a collection independently, such as applying a function to every element of a vector. The safety is guaranteed by Rust's borrow checker, which ensures that each parallel task gets exclusive access to the element it is modifying, thus preventing data races and leading to low-bug code.",
        "anti_patterns": "Similar to `par_iter()`, using this on tiny workloads is inefficient due to overhead. It is also an anti-pattern to perform operations that create dependencies or aliasing between elements being mutated in parallel, though the borrow checker will prevent most of these issues at compile time. Using it for I/O-bound work is also incorrect.",
        "alternate_patterns": "The standard sequential `iter_mut()` is the alternative for small datasets or when strict sequential modification is required. For batch processing, `par_chunks_mut()` provides a way to get mutable access to larger blocks of the collection in parallel."
      },
      {
        "pattern_name": "into_par_iter()",
        "code_template": "use rayon::prelude::*;\n\nfn collect_owned_strings(data: Vec<String>) -> Vec<String> {\n    data.into_par_iter()\n        .map(|s| s.to_uppercase()) // `s` is an owned String\n        .collect()\n}",
        "usage_context": "This pattern is used for parallel consuming iteration, where the collection is moved and the iterator yields owned elements (`T`). It is the parallel equivalent of `.into_iter()`. This is the correct choice when the parallel computation needs to take ownership of the data, for example, to move elements into a new data structure or when the transformation requires an owned value. This leads to high efficiency by avoiding unnecessary cloning or borrowing.",
        "anti_patterns": "Using `into_par_iter()` when you do not need to consume the collection is an anti-pattern, as it prevents the original collection from being used later. In such cases, `par_iter()` or `par_iter_mut()` should be preferred. It is also subject to the same overhead concerns on small workloads as other parallel iterators.",
        "alternate_patterns": "The standard sequential `into_iter()` is the direct alternative. If ownership is not required, `par_iter()` (for immutable access) or `par_iter_mut()` (for mutable access) are the correct patterns to use instead."
      }
    ],
    "map_reduce_aggregation_patterns": [
      {
        "pattern_name": ".map(...).sum()",
        "code_template": "use rayon::prelude::*;\n\nlet sum_of_squares: i32 = (0..1000).into_par_iter()\n    .map(|i| i * i)\n    .sum();",
        "usage_context": "This is the most concise and idiomatic pattern for simple numeric aggregation in parallel. It is highly efficient for summing up values where the item type implements the `std::iter::Sum` trait. The `map` operation is performed in parallel, and Rayon handles the parallel summation efficiently. It's readable and directly translates from sequential code.",
        "anti_patterns": "A major pitfall is using `.sum()` with standard floating-point numbers (`f32`, `f64`). Floating-point addition is not strictly associative due to rounding errors, which means the parallel sum can produce slightly different, non-deterministic results on each run. This can be a source of subtle bugs if exact reproducibility is required.",
        "alternate_patterns": "For more general reductions, `.reduce()` provides more control. For floating-point sums where precision is critical, a sequential Kahan summation algorithm or a custom `fold` implementation of a parallel compensated sum is a better alternative. For non-numeric types, `.reduce()` or `.fold()` must be used."
      },
      {
        "pattern_name": ".reduce(identity, op)",
        "code_template": "use rayon::prelude::*;\n\nlet sums = [(0, 1), (5, 6), (16, 2)]\n           .par_iter()\n           .cloned()\n           .reduce(|| (0, 0), |a, b| (a.0 + b.0, a.1 + b.1));",
        "usage_context": "This is a general-purpose pattern for combining all items in a parallel iterator into a single value. It requires an `identity` closure (providing the starting value, e.g., 0 for addition) and a combining operation `op`. This is highly efficient for parallelizing any associative reduction, such as finding the maximum value, performing component-wise vector addition, or other custom aggregations. Correct use leads to low bugs because the requirements (associativity, identity) force clear thinking about the reduction logic.",
        "anti_patterns": "The most critical anti-pattern is providing a combining operation that is not associative (e.g., `(a - b) - c != a - (b - c)`). Because Rayon executes operations in a non-deterministic order, a non-associative operation will yield unpredictable and incorrect results. Providing an incorrect identity value will also lead to wrong results.",
        "alternate_patterns": "For simple sums, `.sum()` is more concise. When the accumulator type needs to be different from the iterator's item type (e.g., summing `u8` values into a `u32` to prevent overflow), the `.fold().reduce()` pattern is the correct choice. For order-dependent reductions, a sequential `Iterator::reduce` is the only correct option."
      },
      {
        "pattern_name": ".fold().reduce()",
        "code_template": "use rayon::prelude::*;\nuse std::collections::HashMap;\n\nlet data = vec![1, 2, 2, 3, 3, 3];\nlet freqs = data.par_iter()\n    .fold(|| HashMap::new(), |mut acc, &x| { *acc.entry(x).or_insert(0) += 1; acc })\n    .reduce_with(|mut m1, m2| { \n        for (k, v) in m2 { *m1.entry(k).or_default() += v; }\n        m1 \n    })\n    .unwrap_or_default();",
        "usage_context": "This is the most powerful and versatile pattern for complex parallel aggregations, such as building a `HashMap` (histogram), `HashSet`, or concatenating strings. Its key feature is that the accumulator in `fold` can have a different type than the items being iterated over. Each thread `folds` its items into a local accumulator (e.g., a small `HashMap`). Then, the `reduce` step merges these intermediate accumulators into the final result. This pattern is highly efficient because it completely avoids shared-state locking, which is a major performance bottleneck.",
        "anti_patterns": "The primary anti-pattern this idiom replaces is using a shared `Arc<Mutex<T>>` accumulator inside a `for_each` loop. Attempting to lock a mutex for every single item serializes the computation and introduces massive contention, often making the parallel code slower than the sequential version. This is a classic pitfall for developers new to parallel programming.",
        "alternate_patterns": "For collections that implement `FromParallelIterator`, simply using `.collect()` is a higher-level and more concise alternative (e.g., `par_iter.collect::<HashMap<_,_>>()`). For simpler reductions where the accumulator type is the same as the item type, `.reduce()` is sufficient. A sequential `Iterator::fold` is the non-parallel alternative."
      }
    ],
    "fallible_and_error_handling_patterns": [
      {
        "pattern_name": "try_for_each for Early Exit on Side-Effects",
        "code_template": "use rayon::prelude::*;\nuse std::io::{self, Write};\n\n// This will stop iteration early if there's any write error.\n(0..100).into_par_iter()\n    .try_for_each(|x| writeln!(io::stdout(), \"{:?}\", x))\n    .expect(\"expected no write errors\");",
        "usage_context": "Executes a fallible operation for its side effects on each item in parallel. It's highly efficient for validation or processing tasks (like writing to a stream) where the entire operation should be aborted on the first failure. This prevents wasting computational resources and provides a clear, early error signal, leading to low bugs and high efficiency in error scenarios.",
        "anti_patterns": "Using `panic!` for recoverable errors instead of returning a `Result`. Manually implementing error propagation with channels or shared atomics is also an anti-pattern, as `try_for_each` provides a built-in, optimized mechanism for this. This method should not be used when you need to know about all failures, not just the first one.",
        "alternate_patterns": "For non-critical errors where you want to process all items, you can `map` operations into `Result`s and then `collect()` them into a `Vec<Result<T, E>>`. This allows for post-processing of all successes and failures but sacrifices early cancellation. For small datasets, a sequential `for` loop with `?` is simpler."
      },
      {
        "pattern_name": "try_fold with try_reduce for Fallible Aggregation",
        "code_template": "use rayon::prelude::*;\n\nlet bytes = 0..22_u8;\nlet sum = bytes.into_par_iter()\n               .try_fold(|| 0_u32, |acc, byte| acc.checked_add(byte as u32))\n               .try_reduce(|| 0, u32::checked_add);\n\nassert_eq!(sum, Some((0..22).sum()));",
        "usage_context": "Performs a fallible parallel reduction. `try_fold` handles accumulation within a thread's local chunk, short-circuiting only that chunk on error. It's then combined with `try_reduce` to merge the intermediate results, which provides global short-circuiting. This is the idiomatic pattern for parallel aggregations that can fail, such as summing numbers with overflow checks. It ensures correctness and efficiency by stopping work as soon as an invalid state is detected.",
        "anti_patterns": "Ignoring the potential for overflow in parallel sums. Using a standard `fold` and `reduce` and then checking for a sentinel error value is less explicit and more error-prone than using the `try_*` variants with `Result` or `Option`. Leaking a partially computed, incorrect result is a major pitfall that `try_reduce` prevents.",
        "alternate_patterns": "Collecting all intermediate results into a `Vec<Option<T>>` and then manually reducing them sequentially; this loses the benefit of parallel reduction and early exit. A sequential `try_fold` from the standard library is the alternative for small datasets or when parallelism is not required."
      },
      {
        "pattern_name": "Collecting Results for Comprehensive Error Reporting",
        "code_template": "use rayon::prelude::*;\n\nfn fallible_operation(i: &i32) -> Result<i32, &str> {\n    if *i % 2 == 0 { Ok(*i * 2) } else { Err(\"is odd\") }\n}\n\nlet data = vec![1, 2, 3, 4];\nlet results: Vec<Result<i32, &str>> = data.par_iter().map(|item| fallible_operation(item)).collect();",
        "usage_context": "When you need to process all items in a collection and get a report of every success and failure, rather than stopping on the first error. This is useful for batch validation or parsing tasks where you want to present the user with a complete list of all errors. While it doesn't short-circuit as aggressively as `try_for_each`, it is highly efficient for parallelizing the work itself.",
        "anti_patterns": "Using this pattern when early exit is desired, as it's wasteful to continue processing after a critical failure. The `FromParallelIterator` implementation for `Result<T, E>` does short-circuit on the first `Err`, but it doesn't offer the same strong guarantee of immediate work cancellation across all threads as the dedicated `try_*` methods.",
        "alternate_patterns": "The primary alternate is using `try_for_each` or `try_reduce` for early cancellation. Another is to use a `fold` to accumulate successes and failures into separate collections within each thread, then `reduce` to merge them."
      }
    ],
    "divide_and_conquer_patterns": [
      {
        "pattern_name": "rayon::join",
        "code_template": "fn quick_sort<T: PartialOrd + Send>(v: &mut [T]) {\n   const SEQUENTIAL_THRESHOLD: usize = 20; // Threshold for sequential fallback\n   if v.len() > SEQUENTIAL_THRESHOLD {\n       let mid = partition(v);\n       let (lo, hi) = v.split_at_mut(mid);\n       // Recursively sort the two halves in parallel.\n       rayon::join(|| quick_sort(lo),\n                   || quick_sort(hi));\n   } else if v.len() > 1 {\n       // Use sequential sort for small slices\n       v.sort_unstable();\n   }\n}\n\n// Dummy partition function for template completeness\nfn partition<T: PartialOrd + Send>(v: &mut [T]) -> usize {\n    let pivot = v.len() - 1;\n    let mut i = 0;\n    for j in 0..pivot {\n        if v[j] <= v[pivot] {\n            v.swap(i, j);\n            i += 1;\n        }\n    }\n    v.swap(i, pivot);\n    i\n}",
        "usage_context": "The `rayon::join` function is the idiomatic pattern for implementing divide-and-conquer algorithms where a problem can be recursively split into two independent, smaller subproblems. It is highly efficient for CPU-bound recursive tasks, such as parallel quicksort or mergesort. The key to its efficiency is 'potential parallelism': it submits the second task to the work-stealing queue and immediately starts executing the first. If an idle thread is available, it will steal and execute the second task in parallel. This low-overhead, dynamic scheduling leads to high efficiency and excellent load balancing, especially when the subproblems are well-balanced in terms of computational cost. Unlike `std::thread::spawn`, closures passed to `join` can borrow data from the local stack, which, combined with Rust's compile-time checks, leads to low-bug, data-race-free concurrent code.",
        "anti_patterns": "A primary anti-pattern is deep recursion without a sequential base case. Recursively calling `join` on trivial subproblems (e.g., single-element slices) creates an exponential number of tiny, high-overhead tasks that can make the parallel version significantly slower than the sequential one. Another anti-pattern is using `join` for highly unbalanced splits, where one task is much larger than the other; this diminishes the benefits of parallelism as one thread may sit idle. It is also an anti-pattern to perform blocking I/O (file or network operations) inside `join` closures, as this can block a worker thread and starve the entire thread pool, leading to poor performance or deadlocks. Finally, relying on the order of side-effects (like logging) is incorrect, as the execution order of the two closures is non-deterministic.",
        "alternate_patterns": "For spawning a variable number of tasks (more than two), `rayon::scope` is the more flexible and idiomatic alternative. For processing collections, `par_iter()` is a higher-level and often more convenient abstraction that is built on top of `join` and automatically handles splitting and sequential fallbacks. For very small subproblems, falling back to a sequential algorithm (e.g., `slice::sort_unstable`) is a critical alternate pattern for performance. For joining more than two tasks, the external `rayon-join` crate provides a `join_many!` macro that builds a balanced tree of binary `join` calls."
      }
    ],
    "structured_parallelism_patterns": [
      {
        "pattern_name": "rayon::scope",
        "code_template": "let mut results = vec![0; 4];\nlet input_data = vec![10, 20, 30, 40];\n\n// `scope` creates a context 's' for spawning tasks.\n// The function will not return until all spawned tasks are complete.\nrayon::scope(|s| {\n    // Spawn tasks that can safely borrow from the parent stack frame.\n    for (i, res) in results.iter_mut().enumerate() {\n        let input_slice = &input_data[i..=i]; // Borrow from 'input_data'\n        s.spawn(move |_| {\n            // This task can safely access 'res' (a mutable borrow)\n            // and 'input_slice' (an immutable borrow).\n            *res = input_slice[0] * 2; // Simulate work\n        });\n    }\n});\n\n// By this point, all tasks are guaranteed to have finished.\n// `results` will be `[20, 40, 60, 80]`",
        "usage_context": "The `rayon::scope` function is the idiomatic pattern for structured parallelism when you need to spawn a variable number of related tasks that must borrow data from the local stack frame. Its core 'fork-join' model guarantees that the `scope` function will not return until all tasks spawned within it have completed. This guarantee is what allows the Rust compiler to prove that borrows of local variables are safe, preventing dangling references and leading to extremely low-bug concurrent code. This pattern is essential for orchestrating multiple, lifetime-safe tasks, directly solving the limitation of `std::thread::spawn` which requires all captured data to have a `'static` lifetime.",
        "anti_patterns": "The primary anti-pattern `rayon::scope` solves is using `std::thread::spawn` with closures that attempt to borrow non-`'static` data from the local stack, which results in a compilation error. Within Rayon, using `scope` when a simpler primitive would suffice is also an anti-pattern; for example, using `scope` to spawn exactly two tasks is less efficient than using `rayon::join`, as `scope` allocates tasks on the heap while `join` can use the stack. Another pitfall is that deeply nested `scope` or `join` calls can lead to stack overflow under certain work-stealing conditions, as a blocked thread may execute other work on its current stack. Finally, using `rayon::spawn` when stack data is needed is incorrect; `scope` is the intended solution.",
        "alternate_patterns": "For spawning exactly two tasks, `rayon::join` is a more efficient and preferred alternative. For data-parallel processing of collections, `par_iter()` is the simplest and most idiomatic choice. `crossbeam::scope` provides a similar API for scoped threading but typically spawns new OS threads rather than using a work-stealing pool. Rayon also offers variants like `rayon::scope_fifo` which guarantees a First-In-First-Out stealing order (vs. the default LIFO for the local thread) and `rayon::in_place_scope` which guarantees the initial closure runs on the calling thread."
      }
    ],
    "parallel_slice_processing_patterns": [
      {
        "pattern_name": "par_chunks_mut for In-Place Parallel Block Processing",
        "code_template": "use rayon::prelude::*;\n\nlet mut slice = [1, 2, 3, 4, 5];\nslice.par_chunks_mut(2).for_each(|chunk| chunk.reverse());\nassert_eq!(slice, [2, 1, 4, 3, 5]);",
        "usage_context": "The idiomatic way to process a mutable slice in parallel by dividing it into non-overlapping, mutable chunks. It's highly efficient for tasks like image processing (operating on rows of pixels), matrix operations, or applying a transformation to blocks of data in-place. It guarantees no data races between chunks, leading to low bugs.",
        "anti_patterns": "Using a tiny `chunk_size`. The overhead of creating and scheduling parallel tasks for each chunk can dominate the execution time, making it slower than a sequential loop. Also, accessing other shared mutable state from within the closure can introduce lock contention, negating the benefits of parallelism.",
        "alternate_patterns": "Using `par_iter_mut()` provides finer-grained parallelism at the element level. For more control over splitting, one can use `with_min_len()` on an `IndexedParallelIterator` to manually tune granularity."
      },
      {
        "pattern_name": "par_windows for Overlapping Neighborhood Operations",
        "code_template": "use rayon::prelude::*;\n\nlet slice = [1, 2, 3, 4];\nlet windows: Vec<_> = slice.par_windows(2).collect();\nassert_eq!(windows, vec![&[1, 2][..], &[2, 3], &[3, 4]]);",
        "usage_context": "Creates a parallel iterator over all contiguous, overlapping windows of a specified size. This is ideal for algorithms that need to consider an element's neighbors, such as calculating moving averages, stencil computations in scientific computing, or feature detection in signal processing. It provides a high-level, safe abstraction for these common tasks.",
        "anti_patterns": "Using a `window_size` of 0, which will cause a panic. Using it on very small slices where the overhead of parallelization is not justified.",
        "alternate_patterns": "Manually creating windows with a `par_iter().enumerate().map()` combination, which is more complex and error-prone. For sequential processing, `slice.windows()` is the direct equivalent."
      },
      {
        "pattern_name": "par_split for Parallel Sub-slice Processing by Separator",
        "code_template": "use rayon::prelude::*;\n\nlet slice = [1, 2, 3, 0, 4, 5, 0, 6];\nlet products: Vec<i32> = slice.par_split(|x| *x == 0)\n                                      .map(|sub_slice| sub_slice.iter().product())\n                                      .collect();\nassert_eq!(products, vec![6, 20, 6]);",
        "usage_context": "Splits a slice into subslices based on a separator predicate and processes each subslice in parallel. This is highly efficient for processing data that is naturally partitioned by delimiters, such as parsing records from a large byte buffer separated by null characters or newlines.",
        "anti_patterns": "Using a predicate that creates a vast number of very small subslices, which can lead to high scheduling overhead and poor performance.",
        "alternate_patterns": "A sequential loop that manually finds separators and processes the subslices. For mutable splitting, `par_split_mut` is the corresponding pattern."
      }
    ],
    "parallel_sorting_patterns": [
      {
        "pattern_name": "par_sort_unstable for Maximum Performance Sorting",
        "code_template": "use rayon::prelude::*;\n\nlet mut v = vec![5, 2, 8, 1, 9];\nv.par_sort_unstable();\nassert_eq!(v, vec![1, 2, 5, 8, 9]);",
        "usage_context": "For sorting large slices where the relative order of equal elements does not need to be preserved. It's performed in-place (no extra allocation) and is generally the fastest parallel sorting method. It's the idiomatic choice for performance-critical sorting of primitive types or when stability is not a requirement.",
        "anti_patterns": "Using it on small arrays where the overhead of parallelization makes it slower than `slice::sort_unstable`. Using it when the stability of the sort is a requirement for algorithm correctness, as it can break logic that depends on the original order of equal items.",
        "alternate_patterns": "`par_sort` for stable parallel sorting. The standard library's `slice::sort_unstable` for sequential sorting or for small slices where parallel overhead is undesirable."
      },
      {
        "pattern_name": "par_sort for Stable Parallel Sorting",
        "code_template": "use rayon::prelude::*;\n\nlet mut v = vec![(2, \"b\"), (1, \"a\"), (2, \"a\")];\nv.par_sort_by_key(|k| k.0);\n// The relative order of (2, \"b\") and (2, \"a\") is preserved.\nassert_eq!(v, vec![(1, \"a\"), (2, \"b\"), (2, \"a\")]);",
        "usage_context": "For sorting large slices where the relative order of equal elements must be preserved. This is crucial for multi-pass sorting (e.g., sorting by a secondary key after a primary one) or when the original order has meaning. It's an adaptive parallel merge sort, which can be very fast on nearly-sorted data.",
        "anti_patterns": "Using it when stability is not needed, as it's generally slower and requires extra memory allocation (equal to the slice size) compared to `par_sort_unstable`. Using it on small arrays where both the allocation and parallelization overhead are detrimental.",
        "alternate_patterns": "`par_sort_unstable` for faster, unstable sorting. The standard library's `slice::sort` for sequential stable sorting."
      },
      {
        "pattern_name": "par_sort_by_cached_key for Expensive Key Extractions",
        "code_template": "use rayon::prelude::*;\n\nlet mut v = vec![\"apple\", \"banana\", \"cherry\"];\n// Assume to_uppercase() is an expensive operation.\nv.par_sort_by_cached_key(|s| s.to_uppercase());",
        "usage_context": "This is the critical idiom when the function to extract the sorting key is computationally expensive (e.g., involves string formatting, complex calculations, or filesystem access). It computes the key only once per element, caches it, and then sorts based on the cached keys. The key extraction itself is performed in parallel, leading to high efficiency.",
        "anti_patterns": "Using `par_sort_by_key` or `par_sort_unstable_by_key` with an expensive key function. These methods may call the key function multiple times per element during comparisons, leading to redundant work and poor performance. This is a classic performance pitfall that `par_sort_by_cached_key` solves.",
        "alternate_patterns": "Manually creating a `Vec` of `(key, original_value)` tuples, sorting it by key, and then extracting the original values. `par_sort_by_cached_key` automates this pattern efficiently and in parallel."
      }
    ],
    "parallel_collection_building_patterns": [
      {
        "pattern_name": "collect() (via FromParallelIterator)",
        "code_template": "use rayon::prelude::*;\nuse std::collections::HashMap;\n\nlet squares: Vec<i32> = (0..100).into_par_iter().map(|i| i * i).collect();\n\nlet map: HashMap<i32, i32> = (0..100).into_par_iter().map(|i| (i, i*i)).collect();",
        "usage_context": "This is the primary and most idiomatic pattern for creating a new collection from the results of a parallel iterator. It is implemented for most standard collections like `Vec`, `HashMap`, `HashSet`, and `String`. It offers high-throughput construction by having each thread collect its results into a local buffer; these buffers are then efficiently merged into the final collection without user-visible locking. For indexed iterators (like those from slices or ranges), `collect::<Vec<T>>()` is guaranteed to preserve the original order of elements, which is crucial for correctness and leads to low-bug code.",
        "anti_patterns": "The most significant anti-pattern is manually creating a shared collection (e.g., `Arc<Mutex<Vec<T>>>`) and pushing results into it from within a `for_each` closure. This introduces a global lock that serializes access, negates the benefits of parallelism, and leads to poor performance due to contention. Using `.collect()` avoids this entirely.",
        "alternate_patterns": "For collections or custom data structures that do not implement `FromParallelIterator`, the `fold-reduce` pattern is the correct alternative. This involves manually implementing the logic of creating thread-local collections (`fold`) and then merging them (`reduce`)."
      },
      {
        "pattern_name": "par_extend() (via ParallelExtend)",
        "code_template": "use rayon::prelude::*;\n\nlet mut vec = vec![0, 1, 2];\n// Extend the existing vector with items from a parallel iterator\nvec.par_extend(3..100);",
        "usage_context": "This pattern is used to efficiently add items from a parallel iterator to an *existing* collection. It is the parallel equivalent of the standard `extend()` method. Like `collect()`, it is a high-throughput operation that avoids manual locking by using thread-local intermediate storage which is then merged into the target collection. This is the idiomatic way to grow a collection in parallel.",
        "anti_patterns": "The anti-pattern is the same as for `collect()`: manually locking and extending a shared collection from multiple threads, which leads to poor performance. `par_extend` is the high-level, efficient solution to this problem.",
        "alternate_patterns": "An alternative would be to `.collect()` the new items into a temporary collection and then use the sequential `.extend()` to add them to the main collection. However, `par_extend()` is generally more direct and can be more efficient as it's a single, optimized operation."
      }
    ],
    "order_and_indexing_patterns": [
      {
        "pattern_name": "enumerate for Order-Preserving Indexed Processing",
        "code_template": "use rayon::prelude::*;\n\nlet data = vec![\"a\", \"b\", \"c\"];\nlet indexed_data: Vec<(usize, &str)> = data.par_iter().enumerate().map(|(i, v)| (i, *v)).collect();\nassert_eq!(indexed_data, vec![(0, \"a\"), (1, \"b\"), (2, \"c\")]);",
        "usage_context": "The primary idiom for accessing an element's original position during parallel processing. It pairs each item from an `IndexedParallelIterator` (like from a slice or Vec) with its original index. This is essential for algorithms that depend on an element's position. When combined with `collect()`, it ensures the final output is correctly ordered, leading to low bugs by making order explicit and reliable.",
        "anti_patterns": "Assuming that a `for_each` loop on an enumerated iterator will execute its side effects in order. While `enumerate` provides the correct index for each item, the work-stealing scheduler means the `for_each` closure will run in a non-deterministic sequence. Order is preserved for collection, not for side-effect execution.",
        "alternate_patterns": "Manually creating an iterator of indices `(0..len).into_par_iter()` and zipping it with the data iterator. `enumerate` is a more direct and readable abstraction for this common task."
      },
      {
        "pattern_name": "find_first (Deterministic) vs. find_any (Non-Deterministic)",
        "code_template": "use rayon::prelude::*;\n\nlet a = [1, 2, 3, 3];\n// Deterministic: Guaranteed to find the first '3' at index 2.\nassert_eq!(a.par_iter().position_first(|&x| x == 3), Some(2));\n\n// Non-Deterministic: May find the '3' at index 2 or 3.\nlet any_pos = a.par_iter().position_any(|&x| x == 3).unwrap();\nassert!(any_pos == 2 || any_pos == 3);",
        "usage_context": "This pattern highlights the trade-off between correctness and performance in parallel searches. Use `find_first` (or `position_first`) when you need the *guaranteed first* element in sequential order. This is crucial for correctness in order-sensitive algorithms. Use `find_any` (or `position_any`) when *any* matching element is acceptable and you want the fastest possible result, as it allows for early exit as soon as any thread finds a match.",
        "anti_patterns": "The most common and critical anti-pattern is using `find_any` while assuming it will return the first element. This leads to non-deterministic, flaky tests and subtle bugs that are hard to reproduce. Always use `find_first` if determinism is required.",
        "alternate_patterns": "For `find_first`, using the `by_exponential_blocks()` adaptor can improve performance by biasing the search towards the beginning of the iterator. For finding all matches, use `filter().collect()` or the `positions()` method on `IndexedParallelIterator`."
      },
      {
        "pattern_name": "zip/zip_eq for Parallel Element-wise Operations",
        "code_template": "use rayon::prelude::*;\n\nlet a = vec![1, 2, 3];\nlet b = vec![4, 5, 6];\nlet zipped: Vec<(i32, i32)> = a.par_iter().zip_eq(b.par_iter()).map(|(&x, &y)| (x, y)).collect();\nassert_eq!(zipped, vec![(1, 4), (2, 5), (3, 6)]);",
        "usage_context": "For combining two or more parallel iterators to perform element-wise operations in parallel (e.g., vector addition, dot products). The pairing is done based on the original sequence, preserving the relative order of both iterators. `zip_eq` is a variant that panics if the iterators have different lengths, providing a compile-time-like safety check at runtime and leading to low bugs by enforcing invariants.",
        "anti_patterns": "Using `zip` when the iterators are expected to have the same length but not verifying it. This can lead to silent data loss if one iterator is shorter, as `zip` will simply stop when the shorter iterator ends. Using `zip_eq` is the safer, more idiomatic alternative in this context.",
        "alternate_patterns": "Manually iterating with `enumerate()` and accessing elements from multiple slices by index. `zip` is a much cleaner and less error-prone abstraction for this task."
      }
    ],
    "interoperability_patterns": [
      {
        "pattern_name": "par_bridge()",
        "code_template": "use std::fs::File;\nuse std::io::{self, BufRead, BufReader};\nuse rayon::prelude::*;\n\nfn process_lines_in_parallel(filename: &str) -> io::Result<usize> {\n    let file = File::open(filename)?;\n    let reader = BufReader::new(file);\n\n    // The sequential `lines()` iterator is bridged to a parallel one.\n    let count = reader.lines()\n        .filter_map(Result::ok) // Filter out I/O errors\n        .par_bridge() // Convert to ParallelIterator\n        .filter(|line| line.contains(\"ERROR\"))\n        .count();\n\n    Ok(count)\n}",
        "usage_context": "This pattern is used to convert any sequential `Iterator` into a `ParallelIterator`, enabling parallel processing of items from sources that are inherently sequential and cannot be easily collected or split. It is highly efficient for consuming data from sources like file I/O (e.g., `BufReader::lines()`), network sockets, or channels (`std::sync::mpsc::Receiver`). The bridge works by pulling items one-by-one from the source under a `Mutex`, allowing multiple threads to consume and process them concurrently. This is the idiomatic way to introduce parallelism when the data source itself is not a parallel-friendly collection like a `Vec`.",
        "anti_patterns": "The primary anti-pattern is using `par_bridge()` when a direct parallel iterator (like `par_iter()` on a `Vec`) is available, as the bridge's `Mutex` can become a performance bottleneck if the producer is slower than the parallel consumers. Another critical anti-pattern is using it with an underlying iterator whose `next()` method calls back into Rayon, which can lead to deadlocks if the thread pool is saturated. Furthermore, `par_bridge()` does not preserve the original order of the iterator, so relying on side-effect order is a bug. Using it with a fast producer and slow consumers can also lead to high memory usage if results are collected without backpressure.",
        "alternate_patterns": "The most common alternative is to first collect all items from the sequential iterator into a `Vec` and then call `.par_iter()` on the vector; this is often more performant if memory allows. For managing producer/consumer speed mismatches, introducing a bounded channel (e.g., `std::sync::mpsc::sync_channel`) provides backpressure. If the data source can be logically divided (e.g., a large file), using `par_chunks` on a memory-mapped file or reading chunks manually can be more efficient than a line-by-line bridge."
      },
      {
        "pattern_name": "zip() / zip_eq()",
        "code_template": "use rayon::prelude::*;\n\nlet vec1 = vec![1, 2, 3, 4, 5];\nlet vec2 = vec![6, 7, 8, 9, 10];\n\n// Zipping two parallel iterators for element-wise computation.\nlet dot_product: i32 = vec1.par_iter()\n                            .zip(vec2.par_iter())\n                            .map(|(&x, &y)| x * y)\n                            .sum();\n\nassert_eq!(dot_product, 130);",
        "usage_context": "The `zip` pattern is used for performing element-wise computations across two or more parallel iterators. It is highly efficient for tasks like vector arithmetic (dot products, additions) or comparative analysis on multiple slices or vectors. The operation preserves the relative order of elements from both iterators, ensuring that `vec1[i]` is always paired with `vec2[i]`. For `IndexedParallelIterator` sources, this provides strong ordering guarantees, leading to low-bug, predictable code. The `zip_eq` variant is used when it is a logical requirement that both iterators have the same length, as it will panic if they do not.",
        "anti_patterns": "A significant anti-pattern is relying on `zip` with an implicit assumption that both iterators have the same length. If the lengths differ, `zip` will silently stop as soon as the shorter iterator is exhausted, which can lead to incorrect results or lost data without any warning. Using `zip` when `zip_eq` is more appropriate from a correctness standpoint is a common source of bugs.",
        "alternate_patterns": "To guard against the mismatched length anti-pattern, an alternative is to add an explicit `assert_eq!(iter1.len(), iter2.len())` before the `zip` operation to fail fast and make the equal-length requirement clear. For cases where a panic is desired on length mismatch, using `zip_eq` is the direct and idiomatic alternative to `zip`."
      }
    ],
    "state_management_patterns": [
      {
        "pattern_name": "fold-then-reduce",
        "code_template": "use rayon::prelude::*;\nuse std::collections::HashMap;\n\nlet data = vec![1, 2, 2, 3, 3, 3, 4, 4, 4, 4];\n\n// Build a frequency map (histogram) in parallel without locks.\nlet freqs: HashMap<i32, usize> = data.par_iter()\n    // 1. FOLD: Each thread creates a local HashMap and accumulates counts for its portion of the data.\n    .fold(|| HashMap::new(), |mut acc, &x| {\n        *acc.entry(x).or_insert(0) += 1;\n        acc\n    })\n    // 2. REDUCE: The local HashMaps from each thread are merged into a single final map.\n    .reduce_with(|mut m1, m2| {\n        for (k, v) in m2 {\n            *m1.entry(k).or_default() += v;\n        }\n        m1\n    })\n    .unwrap_or_default();",
        "usage_context": "This is the most idiomatic and highly efficient pattern in Rayon for aggregation tasks that build state, such as creating histograms, summing values into a larger type, or building a collection. The pattern works by giving each parallel thread its own local accumulator (e.g., a `HashMap` or a `String`). Each thread 'folds' its portion of the input data into its local state. Once all threads are done, their local results are 'reduced' (merged) into a single final result. This completely avoids the use of locks (like `Mutex`) in the hot path, eliminating contention and allowing the computation to scale almost linearly with the number of cores. This leads to both high efficiency and low-bug code, as it sidesteps the complexities and potential deadlocks of manual locking.",
        "anti_patterns": "The primary anti-pattern is attempting to solve the same problem by using a single shared data structure protected by a lock (e.g., `Arc<Mutex<HashMap<...>>>`) and having each thread acquire the lock for every single item it processes. This serializes the execution, as threads spend most of their time waiting for the lock, completely negating the benefits of parallelism and often resulting in code that is significantly slower than its sequential counterpart. This is frequently referred to as 'killing parallelism'.",
        "alternate_patterns": "For very simple aggregations, methods like `.sum()` or `.count()` are higher-level abstractions that use this pattern internally. For more complex scenarios where the state is not easily mergeable or requires more fine-grained control, an alternative is to use `rayon::scope` to manually create a per-thread data structure (e.g., a `Vec` of accumulators, one for each thread) and have each spawned task work on its designated slot, followed by a final manual merge step after the scope completes."
      },
      {
        "pattern_name": "Arc<Mutex<T>> / Atomics",
        "code_template": "use std::sync::atomic::{AtomicUsize, Ordering};\nuse std::sync::Arc;\nuse rayon::prelude::*;\n\n// Use an atomic for a simple, shared counter when fold-reduce is not suitable.\nlet counter = Arc::new(AtomicUsize::new(0));\n\n(0..10_000).into_par_iter().for_each_with(counter.clone(), |c, _| {\n    // fetch_add is an atomic operation, faster than a Mutex for simple increments.\n    c.fetch_add(1, Ordering::Relaxed);\n});\n\nlet final_count = counter.load(Ordering::SeqCst);\nassert_eq!(final_count, 10_000);",
        "usage_context": "This pattern should be used only when shared mutable state is unavoidable and the 'fold-then-reduce' pattern is not applicable. This can occur with complex state that cannot be easily merged or when interacting with external resources. Atomics (`AtomicUsize`, `AtomicBool`, etc.) are the preferred choice for simple, primitive types like counters, as they are generally more performant than mutexes. For more complex data structures (e.g., a cache that needs to be updated), `Arc<Mutex<T>>` (for exclusive access) or `Arc<RwLock<T>>` (for read-heavy workloads) must be used. This pattern ensures correctness and prevents data races, but it introduces the potential for performance bottlenecks due to contention.",
        "anti_patterns": "The most severe anti-pattern is acquiring a lock for every single element in a hot loop (e.g., inside `par_iter().for_each(...)`). This introduces extreme contention and overhead, often making the parallel code slower than a sequential version. Another anti-pattern is holding a lock for a long duration (coarse-grained locking), which blocks other threads and serializes execution. Relying on the order of operations on the shared state is also incorrect, as Rayon's work-stealing scheduler is non-deterministic.",
        "alternate_patterns": "The primary and strongly preferred alternative is the 'fold-then-reduce' pattern, which avoids locks entirely. If locking is necessary, a 'batched lock acquisition' pattern can mitigate the overhead: process a chunk of items locally into a temporary structure, then acquire the lock only once to merge the batch results into the shared state. This significantly reduces the frequency of lock acquisitions and contention."
      }
    ],
    "configuration_and_tuning_patterns": [
      {
        "pattern_name": "ThreadPoolBuilder (Global Configuration)",
        "code_template": "// At the start of your main function.\nrayon::ThreadPoolBuilder::new()\n    .num_threads(8) // Set a specific number of threads.\n    .stack_size(4 * 1024 * 1024) // Set stack size for each thread.\n    .build_global()\n    .expect(\"Failed to build the global Rayon thread pool.\");",
        "usage_context": "This pattern is used to configure the global Rayon thread pool for the entire application. It should be called once at program startup (e.g., in `main`). It provides high efficiency by allowing you to tailor the pool to the specific hardware and workload, such as limiting concurrency to avoid oversubscribing the CPU, increasing stack size to prevent overflows in deeply recursive parallel tasks, or setting a custom panic handler for robust error handling. This leads to predictable performance and resource usage.",
        "anti_patterns": "Calling `build_global()` more than once during the application's lifetime is an anti-pattern; it will return an error on subsequent calls. Configuring the pool with an incorrect number of threads (e.g., far more threads than CPU cores) can lead to performance degradation due to excessive context switching.",
        "alternate_patterns": "The simplest alternative for controlling the thread count is to set the `RAYON_NUM_THREADS` environment variable. This is often sufficient for simple configuration and is useful in scripting or CI environments. If no configuration is provided, Rayon defaults to using a number of threads equal to the number of logical CPUs, which is a reasonable default for many CPU-bound workloads."
      },
      {
        "pattern_name": "ThreadPoolBuilder (Per-Task Custom Pool)",
        "code_template": "let custom_pool = rayon::ThreadPoolBuilder::new()\n    .num_threads(2)\n    .build()\n    .expect(\"Failed to build a custom pool.\");\n\n// Run a specific parallel computation within the custom pool.\ncustom_pool.install(|| {\n    let data = vec![1, 2, 3, 4, 5, 6, 7, 8];\n    let sum: i32 = data.par_iter().sum();\n    println!(\"Sum computed in custom pool: {}\", sum);\n});",
        "usage_context": "This pattern is used to isolate specific workloads or limit their concurrency without affecting the global thread pool. It is highly effective for building robust systems with different priority tasks (e.g., a high-priority pool for user requests and a low-priority pool for background jobs). It is also the primary idiom for writing reliable, non-flaky tests, as it isolates each test's parallel work. This leads to both high efficiency (by preventing resource starvation) and low bugs (by making tests reproducible).",
        "anti_patterns": "A major anti-pattern is creating many short-lived custom pools, for example, one for every small task. The overhead of creating and tearing down a thread pool is significant, and this practice will severely degrade performance. Another anti-pattern is nesting pools (creating a pool from within a thread of another pool), which can lead to thread oversubscription and deadlocks.",
        "alternate_patterns": "For most simple applications, using the default global pool is sufficient. In asynchronous contexts like Tokio, the idiomatic pattern is not to create a custom Rayon pool but to offload the blocking Rayon work to Tokio's dedicated blocking thread pool via `tokio::task::spawn_blocking`."
      },
      {
        "pattern_name": "Granularity Tuning with `with_min_len()`",
        "code_template": "use rayon::prelude::*;\n\nlet mut data: Vec<i32> = (0..1_000_000).collect();\n\n// Ensure each parallel job processes at least 1000 items.\ndata.par_iter_mut()\n    .with_min_len(1000)\n    .for_each(|item| {\n        // Simulate a heavy computation\n        *item *= 2;\n    });",
        "usage_context": "The `with_min_len()` adaptor is an idiom for performance tuning on `IndexedParallelIterator`s. It is used when the work per item is computationally expensive. By setting a minimum length, you prevent Rayon from splitting the work into excessively small jobs. This ensures that each parallel task has a substantial amount of work, which amortizes the overhead of task scheduling and work-stealing, leading to higher efficiency.",
        "anti_patterns": "Using this with a value that is too large can hinder load balancing, as it may leave some threads idle if the work cannot be split finely enough. It is not effective for iterators that are not indexed, as the length cannot be known in advance.",
        "alternate_patterns": "An alternative is to use `par_chunks()` or `par_chunks_mut()` to manually create coarser-grained tasks. This provides explicit control over chunk size. For very complex, non-uniform workloads, manually splitting the work with `rayon::join` or `rayon::scope` can offer more fine-grained control than a simple length hint."
      },
      {
        "pattern_name": "Explicit Chunking with `par_chunks()`",
        "code_template": "use rayon::prelude::*;\n\nlet mut array = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n\n// Process the slice in mutable chunks of size 3 in parallel.\narray.par_chunks_mut(3).for_each(|chunk| {\n    // This closure runs in parallel for each chunk.\n    chunk.reverse();\n});\n\nassert_eq!(array, [2, 1, 0, 5, 4, 3, 8, 7, 6, 9]);",
        "usage_context": "This pattern is idiomatic for processing large, contiguous blocks of data, such as in image processing, scientific computing, or matrix operations. It provides a form of coarse-grained parallelism that is often more efficient than per-element parallelism. By processing a chunk at a time, it reduces scheduling overhead and can significantly improve cache locality, as the data within a chunk is processed by a single thread. This leads to high efficiency.",
        "anti_patterns": "The primary anti-pattern is using a very small `chunk_size`. This defeats the purpose of chunking and reintroduces the overhead of managing an excessive number of tiny parallel tasks, which can make performance worse than a simple `par_iter()`. Also, one must be careful not to introduce aliasing of shared mutable state across different chunks.",
        "alternate_patterns": "For more dynamic control over splitting, `with_min_len()` can be used. For non-slice data, one can use iterator adaptors like `itertools::Itertools::chunks` combined with `par_bridge()` to achieve a similar effect. For dividing work into a few very large, distinct pieces, `rayon::scope` is a suitable alternative."
      }
    ],
    "platform_specific_patterns_wasm": [
      {
        "pattern_name": "Enabling Multithreading with wasm-bindgen-rayon",
        "code_template": "1. In Cargo.toml:\n[dependencies]\nrayon = \"1.11\"\nwasm-bindgen = \"0.2\"\nwasm-bindgen-rayon = \"1.2\"\n\n2. In Rust code (e.g., lib.rs):\nuse wasm_bindgen::prelude::*;\n// Re-export the thread pool initialization function.\npub use wasm_bindgen_rayon::init_thread_pool;\n\n#[wasm_bindgen]\npub fn my_parallel_func(input: &[i32]) -> i32 {\n    input.par_iter().map(|n| n * n).sum()\n}\n\n3. In JavaScript:\nimport init, { initThreadPool, my_parallel_func } from './pkg/index.js';\n\nasync function run() {\n    await init(); // Initialize the Wasm module\n    // Initialize Rayon's thread pool with browser's Web Workers\n    await initThreadPool(navigator.hardwareConcurrency);\n    // Now parallel functions can be called\n    const result = my_parallel_func(new Int32Array([1, 2, 3, 4]));\n}\nrun();",
        "usage_context": "This is the fundamental pattern to unlock true multithreading for Rayon in a browser environment. By default, Rayon on the `wasm32-unknown-unknown` target falls back to sequential execution. This pattern uses the `wasm-bindgen-rayon` adapter to bridge Rayon's thread spawning mechanism to the browser's Web Worker API. It is essential for achieving high efficiency in CPU-bound computations within Wasm. This setup requires a nightly Rust toolchain and specific build flags (`RUSTFLAGS='-C target-feature=+atomics,+bulk-memory,+mutable-globals'`).",
        "anti_patterns": "Expecting any parallel speedup without this setup. Rayon will compile and run, but it will be single-threaded. Another anti-pattern is blocking the main browser thread; long-running synchronous Rayon computations must be offloaded to a worker. Using the `--target bundler` with `wasm-pack` is also an anti-pattern as it's unsupported by `wasm-bindgen-rayon` which requires `--target web`.",
        "alternate_patterns": "The default behavior is a sequential fallback; no setup is needed, but there is no parallelism. For complex applications, a more robust alternative is to instantiate the entire Wasm module and its Rayon pool inside a dedicated Web Worker, communicating with it from the main thread via a library like Comlink to ensure the UI thread is never blocked."
      },
      {
        "pattern_name": "Configuring Cross-Origin Isolation for SharedArrayBuffer",
        "code_template": "On the web server hosting the application, configure the following HTTP headers for the main HTML document:\n\nCross-Origin-Opener-Policy: same-origin\nCross-Origin-Embedder-Policy: require-corp",
        "usage_context": "This pattern is a mandatory prerequisite for enabling WebAssembly threads in modern browsers. Wasm threads rely on `SharedArrayBuffer` to share memory between workers. For security reasons (to mitigate Spectre-like vulnerabilities), browsers only enable `SharedArrayBuffer` on pages that are in a 'cross-origin isolated' state. Applying these headers correctly ensures the feature is available, which is critical for low-bug deployment as it prevents runtime errors related to unavailable browser APIs.",
        "anti_patterns": "Attempting to initialize or use the Wasm thread pool on a page that is not cross-origin isolated. This will fail, and the application will either error out or fall back to single-threaded execution, negating any performance benefits of parallelism.",
        "alternate_patterns": "There is no direct alternative for enabling multithreading. The only other option is to forgo parallelism and use a single-threaded Wasm build, which does not require these headers."
      },
      {
        "pattern_name": "Sequential Fallback for Compatibility",
        "code_template": "// In JavaScript, use a feature detection library\nimport { threads } from 'wasm-feature-detect';\n\nasync function loadWasm() {\n  if (await threads()) {\n    // Browser supports Wasm threads\n    console.log('Loading multithreaded version.');\n    const wasm = await import('./pkg-with-threads/index.js');\n    await wasm.default();\n    await wasm.initThreadPool(navigator.hardwareConcurrency);\n    return wasm;\n  } else {\n    // Fallback to single-threaded version\n    console.log('Loading single-threaded version.');\n    const wasm = await import('./pkg-without-threads/index.js');\n    await wasm.default();\n    return wasm;\n  }\n}\n\nconst myApp = await loadWasm();\nmyApp.run_computation();",
        "usage_context": "This pattern is used to build robust, production-grade applications that can run in a wide range of environments, including older browsers or configurations where WebAssembly threads or `SharedArrayBuffer` are not supported. It involves creating two separate builds of the Wasm module (one with threads, one without) and using JavaScript feature detection to dynamically load the appropriate one. This leads to low bugs by gracefully handling environmental limitations instead of failing.",
        "anti_patterns": "Shipping only a multithreaded build of the application. This will cause the application to fail to load or run in browsers that do not support Wasm threads, leading to a poor user experience.",
        "alternate_patterns": "The main alternative is to ship only a single-threaded build. This maximizes compatibility at the cost of sacrificing performance in capable environments."
      }
    ],
    "testing_and_reproducibility_patterns": [
      {
        "pattern_name": "Per-Test Custom Thread Pool",
        "code_template": "#[test]\nfn my_isolated_parallel_test() {\n    // Create a dedicated pool with a fixed number of threads for this test.\n    let pool = rayon::ThreadPoolBuilder::new()\n        .num_threads(4)\n        .build()\n        .unwrap();\n\n    // Use `install` to run code within this specific pool.\n    // Any Rayon operations inside this closure will use `pool`.\n    pool.install(|| {\n        let sum: i32 = (0..100).into_par_iter().sum();\n        assert_eq!(sum, 4950);\n    });\n}",
        "usage_context": "This is the most critical idiom for writing reliable and reproducible tests for Rayon-based code. It ensures that each test runs in an isolated environment with a known number of threads, preventing interference from other tests that may be running concurrently (e.g., in CI). This isolation eliminates a major source of flakiness caused by contention for the shared global thread pool, leading to low-bug, deterministic test suites.",
        "anti_patterns": "The primary anti-pattern is relying on the ambient global thread pool for tests. The global pool is shared state, and its availability and performance can be affected by other tests, leading to unpredictable timing, resource contention, and flaky test failures that are difficult to debug.",
        "alternate_patterns": "For maximum determinism, an alternative is to run the test in a single-threaded mode by creating a pool with `.num_threads(1)`. Another approach is to configure the global pool for the entire test run using the `RAYON_NUM_THREADS` environment variable, though this provides less isolation than the per-test pool pattern."
      },
      {
        "pattern_name": "Single-Threaded Mode for Debugging",
        "code_template": "// Option 1: Via environment variable for the whole test run\n// $ RAYON_NUM_THREADS=1 cargo test\n\n// Option 2: Programmatically for a single test\n#[test]\nfn my_deterministic_test() {\n    let pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\n    pool.install(|| {\n        // This code will run sequentially.\n        let v: Vec<_> = (0..4).into_par_iter().map(|i| i).collect();\n        assert_eq!(v, vec![0, 1, 2, 3]);\n    });\n}",
        "usage_context": "This pattern is used to force Rayon's execution into a single thread, making the behavior of parallel code deterministic and sequential. It is an invaluable tool for debugging suspected logical race conditions or other concurrency-related bugs. By removing the non-determinism of the work-stealing scheduler, it allows developers to trace the execution path predictably, leading to faster bug identification and resolution.",
        "anti_patterns": "An anti-pattern is using single-threaded mode to simply make a flaky test pass without understanding the underlying concurrency bug. This masks the problem, which will still exist when the code is run in a multi-threaded production environment.",
        "alternate_patterns": "Instead of forcing single-threaded execution, one can use other determinism-oriented patterns, such as replacing `find_any` with `find_first`, or collecting results and sorting them before assertion to ensure a predictable order."
      },
      {
        "pattern_name": "Deterministic Search and Predicates",
        "code_template": "use rayon::prelude::*;\n\nlet data = vec![1, 5, 2, 4, 3, 3];\n\n// Use `position_first` to get a deterministic result.\nlet first_three = data.par_iter().position_first(|&&x| x == 3);\nassert_eq!(first_three, Some(4));\n\n// DO NOT use `position_any` in a test asserting a specific index,\n// as it could return Some(4) or Some(5) non-deterministically.\n// let any_three = data.par_iter().position_any(|&&x| x == 3);",
        "usage_context": "When testing search functionality, it is crucial to use deterministic methods to avoid flaky tests. Methods like `find_first`, `position_first`, `find_last`, and `position_last` guarantee they will return the same element (or index) as their sequential counterparts, regardless of parallel execution order. This ensures that test assertions against specific values or positions are reliable and reproducible, leading to a low-bug test suite.",
        "anti_patterns": "A common and critical anti-pattern is using non-deterministic methods like `find_any` or `position_any` in a correctness test. These methods prioritize performance by returning the first match found by any thread, which can vary between runs. Using them in an assertion that expects a specific outcome will inevitably lead to flaky tests.",
        "alternate_patterns": "If the goal is simply to test that *any* valid item is found, `find_any` can be used, but the assertion must be flexible (e.g., `assert!(result.is_some())` or `assert!(valid_results.contains(&result.unwrap()))`). For ordered data, another alternative is to `collect()` the results and then use a standard `binary_search`."
      },
      {
        "pattern_name": "Ordered Side-Effects (Collect-Then-Act)",
        "code_template": "use rayon::prelude::*;\n\nlet data = vec![1, 2, 3, 4];\n\n// 1. Perform parallel computation and collect results.\n// `collect()` on an IndexedParallelIterator preserves order.\nlet results: Vec<String> = data.par_iter()\n    .map(|&i| format!(\"Computed value {}\", i * i))\n    .collect();\n\n// 2. Perform assertions or side-effects on the ordered results.\nassert_eq!(results, vec![\n    \"Computed value 1\",\n    \"Computed value 4\",\n    \"Computed value 9\",\n    \"Computed value 16\",\n]);",
        "usage_context": "This pattern is used in tests that need to verify outputs that depend on the original sequence order. The parallel, CPU-bound work is performed first using methods like `map`. The `collect()` method then efficiently reassembles the results into a `Vec` that preserves the original order. Finally, the test performs assertions on this ordered collection. This separates the non-deterministic parallel computation from the deterministic verification, leading to robust and reliable tests.",
        "anti_patterns": "The anti-pattern is to perform ordered assertions or have ordered side-effects (like printing or logging) directly inside a parallel closure like `for_each`. The execution order is not guaranteed, so such tests will be inherently flaky.",
        "alternate_patterns": "For streaming ordered results without collecting everything first (e.g., in a benchmark that logs progress), a more complex pattern involving `enumerate()` to tag items with their index and a separate consumer thread to reorder them from a channel can be used. However, for most test cases, 'collect-then-act' is simpler and sufficient."
      }
    ],
    "demonstrated_pipelines_from_rayon_demo": [
      {
        "demo_name": "N-body Simulation",
        "illustrated_pattern": "Toggling between sequential and parallel execution for an embarrassingly parallel numeric kernel.",
        "code_template_concept": "The demo uses a command-line flag (`--mode seq` vs. `--mode par`) to switch between different execution functions. This conceptually represents converting a sequential loop like `for body in &bodies { compute_forces(body); }` into a parallel one: `bodies.par_iter().for_each(|body| compute_forces(body));`. The demo also includes a `parreduce` mode, suggesting a `fold/reduce` pattern for aggregating results in parallel.",
        "usage_context": "This pattern is ideal for embarrassingly parallel numeric kernels, where the computation for each element in a collection (e.g., a celestial body) is independent of the others within the same time step. This is a classic high-efficiency use case for Rayon, as the work can be easily divided among CPU cores with minimal synchronization.",
        "anti_patterns_avoided": "The N-body problem is computationally intensive, ensuring that the work per item is substantial enough to overcome the overhead of parallelization. This avoids the common anti-pattern of parallelizing tiny, memory-bound kernels where the setup cost would dominate and lead to a slowdown.",
        "alternate_patterns_shown": "The demo showcases multiple parallel strategies for the same problem: a direct parallel iterator (`par`) and a map-reduce style aggregation (`parreduce`). This illustrates that even for a single problem, different Rayon APIs can be applied depending on the specific aggregation needs, offering flexibility in implementation."
      },
      {
        "demo_name": "Game of Life",
        "illustrated_pattern": "Comparing different parallel iterator creation methods (`into_par_iter` vs. `par_bridge`) for a grid-based computation.",
        "code_template_concept": "The `Board` struct contains distinct methods for benchmarking. The `parallel_next_generation` method uses `(0..self.len()).into_par_iter().map(...)`, which is the canonical way to parallelize a loop over an indexed collection. The `par_bridge_next_generation` method uses `(0..self.len()).par_bridge().map(...)`, demonstrating the use of the `par_bridge` adapter for iterators that might not be directly convertible.",
        "usage_context": "This pipeline is used for grid-based cellular automata where the next state of each cell is computed independently based on its local neighborhood. This is another example of an embarrassingly parallel problem where Rayon provides significant efficiency gains by processing different parts of the grid concurrently.",
        "anti_patterns_avoided": "By using `.collect()` to gather the results of the `map` operation into a new grid, the demo avoids the major anti-pattern of using a shared lock (`Mutex`) to update a single grid structure from multiple threads. Such locking would serialize execution and destroy parallelism.",
        "alternate_patterns_shown": "The demo explicitly includes and benchmarks `par_bridge()` as an alternative to `into_par_iter()`. This highlights `par_bridge` as a flexible, general-purpose tool for applying parallelism to any standard `Iterator`, even if it's less performant than a direct parallel iterator on a collection that can be efficiently split."
      },
      {
        "demo_name": "Parallel Matrix Multiplication",
        "illustrated_pattern": "Recursive divide-and-conquer parallelism using `rayon::join` and optimizing for cache locality.",
        "code_template_concept": "The core pattern is the recursive splitting of matrix operations using `rayon::join`, often abstracted into helper functions like `join4` or `join8` to spawn multiple sub-tasks. A conceptual snippet is `rayon::join(|| recursive_op(sub_matrix_1), || recursive_op(sub_matrix_2));`. The demo also shows zipping parallel iterators for element-wise operations: `dest.par_iter_mut().zip(src.par_iter()).for_each(|(d, s)| *d += *s);`.",
        "usage_context": "This pattern is essential for CPU-bound, recursive algorithms like Strassen's matrix multiplication. `rayon::join` is highly efficient for these balanced, divide-and-conquer problems as it has very low overhead and integrates seamlessly with Rayon's work-stealing scheduler.",
        "anti_patterns_avoided": "The implementation defines constants like `MULT_CHUNK` and `LINEAR_CHUNK` to set a threshold for subproblem size. Below this threshold, the algorithm switches from parallel recursion to a sequential base case. This is a critical guardrail that avoids the anti-pattern of parallelizing tiny matrix blocks, where the overhead of task creation would lead to a performance loss.",
        "alternate_patterns_shown": "The demo includes a `matmulz` variant that uses Z-order curve traversal. This is an advanced pattern that goes beyond simple parallelism to optimize for cache locality. By arranging data access to follow a Z-order curve, it increases the probability that data needed for computation is already in the CPU cache, demonstrating that data layout can be as important as parallelism for performance."
      }
    ]
  },
  "outputBasis": [
    {
      "field": "divide_and_conquer_patterns",
      "citations": [
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```\ntrait Joiner {\n    /// True if this is parallel mode, false otherwise. fn is_parallel() -> bool;\n    \n    /// Either calls `rayon::join` or just invokes `oper_a(); oper_b();`.\nfn join<A,R_A,B,R_B>(oper_a: A, oper_b: B) -> (R_A, R_B)\n        where A: FnOnce() -> R_A + Send, B: FnOnce() -> R_B + Send;\n}\n```"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "pub fn join<A, B, RA, RB>(oper_a: A, oper_b: B) -> (RA, RB)\n\nwhere\n    A: FnOnce () -> RA + Send ,\n    B: FnOnce () -> RB + Send ,\n    RA: Send ,\n    RB: Send ,",
            "This example uses join to perform a quick-sort (note this is not a\nparticularly optimized implementation: if you **actually** want to\nsort for real, you should prefer [the `par_sort` method](../rayon/slice/trait.ParallelSliceMut.html.par_sort) offered\nby Rayon). ",
            "       let mid = partition(v);",
            "       let (lo, hi) = v.split_at_mut(mid);"
          ]
        }
      ],
      "reasoning": "Key excerpts present direct guidance on divide-and-conquer using Rayons join primitive. A concrete example shows the two halves of a problem being solved in parallel by invoking rayon::join on two recursive calls, which matches the requested HQ idiom of a code template for a divide-and-conquer pattern. The following excerpt explicitly describes two closures that may run in parallel, and the example demonstrates parallel quicksort, a classic divide-and-conquer algorithm, using join to execute the left and right halves concurrently. The code snippet outlines the recursive structure and clear base-case fallback when the input is small, which is the exact structure youd want in a HQ idiomatic pattern. Another excerpt reinforces the same pattern by illustrating a quicksort implementation using join and partitioning, including the idea that closures may execute in parallel and that the implementation employs a work-stealing style, which is central to Rayons efficiency for parallel divide-and-conquer workloads. A separate example reinforces the same idiom with a succinct parallel sort demonstration and emphasizes the minimal overhead and potential for parallel execution when there are idle cores. Additional excerpts describe the conceptual model of join as a core primitive for divide-and-conquer and provide high-level guidance on using join instead of thread spawning, further supporting the patterns role as the canonical idiom for HQ divide-and-conquer in Rayon. In sum, these excerpts together map to the requested field value by providing both a concrete code template and the underlying rationale for using join to implement parallel divide-and-conquer patterns, with emphasis on two recursive branches, work-stealing scheduling, and a small sequential fallback for tiny problems.",
      "confidence": "high"
    },
    {
      "field": "parallel_iterator_patterns",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "- A canonical idiom is to replace a normal iterator with a parallel one by calling par_iter() on the collection and then applying map-like or reduce-like operations. A typical code template shows reading from a slice in parallel, converting iterative processing into a par_iter() flow, for example converting iter() to par_iter() and performing map and sum to compute a result. This demonstrates the standard pattern for turning a normal iteration into a data-parallel operation without mutating the source, leveraging Rayon's work-stealing scheduler to balance load and reduce bugs from data races. This pattern is explicitly framed as the direct parallel analog of iter(), illustrating when to apply it (CPU-bound, data-parallel workloads) and its efficiency characteristics, reinforcing it as a primary idiom for transforming existing code with minimal semantic changes. The content emphasizes that this is high-value for performance and safety because it integrates with Rusts borrow-checking guarantees while distributing work across threads.",
      "confidence": "high"
    },
    {
      "field": "testing_and_reproducibility_patterns",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        },
        {
          "title": "rayon-core/src/thread_pool/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-core/src/thread_pool/mod.rs",
          "excerpts": [
            "pub fn current\\_num\\_threads(&self) -> usize {\nself.registry.num\\_threads(",
            "pub fn install(&self, op: OP) -> R\nwhere\nOP: FnOnce() -> R + Send,\nR: Send,\n{\nself.registry.in\\_worker(|\\_, \\_| op())\n",
            "o\n/// keep busy while the `op` completes in its target pool, similar to\n/// calling [`ThreadPool::yield\\_now()`] in a loop. Therefore, it may\n/// potentially schedule other tasks to run on the current thread in the\n/// meantime. For example\n///\n/// ```ignore-wasm\n/// # use rayon\\_core as rayon;\n/// fn main() {\n/// rayon::ThreadPoolBuilder::new().num\\_threads(1).build\\_global().unwrap();\n/// let pool = rayon\\_core::ThreadPoolBuilder::default().build().unwrap();\n/// let do\\_it = || {\n/// print!(\"one \");\n/// pool.install(||{});\n/// print!(\"two \");\n/// };\n/// rayon::join(|| do\\_it(), || do\\_it());\n/// }\n/// ```\n///\n/// Since we configured just one thread in the global pool, one might\n/// expect `do\\_it()` to run sequentially, producing:\n///\n/// ```ascii\n/// one two one two\n/// ```\n///\n/// However each call to `install()` yields implicitly, allowing rayon to\n/// run multiple instances of `do\\_it()` concurrently on the single, global\n/// thread. The following output would be equally valid:"
          ]
        },
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            " fn par_bridge (self) -> IterBridge <Self>;",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Iterator items are pulled by \\`next()\\` one at a time, synchronized from each thread that is\n22 /// ready for work, so this may become a bottleneck if the serial iterator can't keep up with the\n23 /// para"
          ]
        }
      ],
      "reasoning": "- The target pattern set includes explicit strategies for making Rayon usage deterministic in tests, such as using a dedicated per-test thread pool and isolating test execution from the global pool. Excerpts describing creating a dedicated ThreadPool via ThreadPoolBuilder, then running test code with pool.install(...) illustrate exactly how to create per-test isolation and deterministic execution: these passages show how to configure a small, separate pool and run code inside it, which directly supports the Per-Test Custom Thread Pool pattern and the broader goal of test determinism. They also show that code inside the pool uses Rayons APIs while the outer test remains isolated, aligning with the Per-test isolation for reproducible tests concept. Additionally, the excerpts describe using a single-threaded mode for debugging (via environment or pool configuration), which is a core alternative pattern for deterministic testing. This directly supports the Single-Threaded Mode for Debugging pattern by demonstrating how to configure a pool with a single thread and run work inside it to achieve determinism. The excerpts also discuss the general mechanism Rayon uses to manage thread pools (install, global vs. local pools), which underpins all per-test reproducibility strategies and helps explain why relying solely on a global pool can lead to flaky tests. They also touch on ordering considerations when collecting results from parallel iterators (e.g., collect() preserving order) and how to structure tests to validate deterministic order when needed. Taken together, these excerpts provide concrete, actionable guidance for implementing the requested per-test reproducibility idioms and debugging strategies, and they illustrate the correct usage patterns to avoid common pitfalls (e.g., avoiding reliance on ambient global pools in tests).",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm",
      "citations": [
        {
          "title": "Allow setting COOP and COEP headers in Github Pages #13309",
          "url": "https://github.com/orgs/community/discussions/13309",
          "excerpts": [
            "In order to use SharedArrayBuffer and WebAssembly Threads, COOP and COEP headers need to be set, such that the page becomes cross-origin isolated."
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "## Using Rayon\n",
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "This is because the Wasm code needs to take its own object (the `WebAssembly.Module` ) and share it with other threads when spawning them. This object is only accessible from the `--target web` and `--target no-modules` outputs, but we further restrict it to only `--target web` as we also use [JS snippets feature](https://rustwasm.github.io/wasm-bindgen/reference/js-snippets.html) .",
            "The other issue is that the Rust standard library for the WebAssembly target is built without threads support to ensure maximum portability. Since we want standard library to be thread-safe and [`std::sync`](https://doc.rust-lang.org/std/sync/) APIs to work, you'll need to use the nightly compiler toolchain and pass some flags to rebuild the standard library in addition to your own code.",
            "In order to reduce risk of breakages, it's strongly recommended to use a fixed nightly version. This crate was tested with `nightly-2024-08-02` .",
            "\n## Usage with various bundlers",
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Feature detection",
            "```",
            "import { threads } from 'wasm-feature-detect' ;",
            "let wasmPkg ;"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```",
            "```",
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```",
            "```",
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon Scope and spawn documentation",
          "url": "https://docs.rs/rayon/latest/rayon/struct.Scope.html",
          "excerpts": [
            "```",
            "```"
          ]
        },
        {
          "title": "rayon docs: Iteration - ParallelExtend and FromParallelIterator",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "```",
            "```"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        }
      ],
      "reasoning": "The core finegrained field value centers on enabling and using WASM-based multithreading with Rayon via wasm-bindgen-rayon, including the necessary web prerequisites and concrete initialization flows. The top-priority excerpts explicitly identify wasm-bindgen-rayon as the adapter enabling concurrency on the Web with Web Workers and SharedArrayBuffer support, which directly aligns with the requested pattern. Following excerpts provide concrete steps or code templates for initializing the thread pool from JavaScript (init_thread_pool), and for exposing the thread pool initialization function in the wasm module, which are essential for turning on parallelism in a WASM context. Additional excerpts describe enabling SharedArrayBuffer and cross-origin isolation headers, which are prerequisite security configurations for WASM threads in browsers; these map to the anti-patterns and prerequisites described in the field value. Further excerpts illustrate alternative or fallback approaches (e.g., loading a non-threaded build when threads are not available) and broader WASM-Thread/Amdahl considerations, which match the described alternates and risk considerations. Taken together, these excerpts directly support the field value by providing the exact components (adapter, initialization, prerequisites, and fallback options) that comprise the requested WASM/Rayon pattern set.\n",
      "confidence": "high"
    },
    {
      "field": "parallel_slice_processing_patterns",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>",
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>",
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            "fn par_rchunks(&self, chunk_size: usize) -> RChunks<'_, T> { ... }",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length."
          ]
        }
      ],
      "reasoning": "Directly relevant excerpts describe concrete, idiomatic patterns for parallel slice processing in Rayon. One pattern is using parallel slicing where a mutable slice is divided into non-overlapping chunks in parallel using par_chunks, par_chunks_mut or related APIs. This pattern is ideal for in-place transformations on blocks of data, such as reversing each chunk (par_chunks_mut) or performing block-wise updates, which avoids data races because each chunk is disjoint and processed in parallel. The passages explicitly show code templates that illustrate transforming a mutable slice by chunking it into non-overlapping pieces and applying an operation per chunk, followed by an assertion to verify the in-place modification. This aligns with the field values emphasis on in-place parallel slice processing patterns (par_chunks_mut) that yield low-bug, high-efficiency code when operating on blocks of data without shared mutable state across chunks. A second pattern is creating overlapping windows with par_windows, which enables safe parallel computation over local neighborhoods (e.g., moving-window operations) by producing overlapping sub-slices that are processed by separate workers. The excerpts provide a concrete example of collecting overlapping windows in parallel, which supports the use-case where neighborhood information is needed while preserving safety guarantees. A third pattern is using par_split to partition a slice by a separator into subslices that are then processed in parallel; this is highly efficient for data streams or delimited records and demonstrates safe, parallel per-subslice processing. The documentation passages quote and exemplify these patterns clearly, including cautions about correctly sizing work units and avoiding excessive fragmentation that would degrade performance. In addition, several excerpts discuss the broader context of parallel slice processing (ParallelSlice, par_rchunks, par_windows, par_chunks) and how they relate to safe, concurrent data processing, which reinforces the relevance of these exact idioms for the finegrained field value. The excerpts explicitly connect the pattern names (par_chunks, par_windows, par_split) to practical templates and usage contexts, supporting the fields classification of idiomatic parallel slice patterns and their alternates and anti-patterns. ",
      "confidence": "high"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "pub fn matmulz(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "let ((r1, r2), (r3, r4)) = rayon::join(|| rayon::join(f1, f2), || rayon::join(f3, f4));",
            "matmul_strassen(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (m1, m2, m3, m4, m5, m6, m7, _) = join8(",
            "|| strassen_add2_mul(a11, a22, b11, b22),",
            "|| strassen_add_mul(a21, a22, b11),",
            "|| strassen_sub_mul(b12, b22, a11),",
            " .zip(src.par_iter())",
            " .for_each(|(d, s)| *d += *s);",
            "fn rcopy(src: &[f32], dest: &mut [f32]) {",
            "if dest.len() <= LINEAR_CHUNK {",
            "dest.copy_from_slice(src);",
            "return;",
            "}",
            "rayon::join(|| rcopy(s1, d1), || rcopy(s2, d2));"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        }
      ],
      "reasoning": "The most relevant excerpts describe the Rayon-demo repositorys structure and specific demos. They show the demos main entry point listing available benchmarks (matmul, mergesort, nbody, quicksort, sieve, life, etc.), which directly aligns with the field values focus on demonstrated pipelines from the Rayon demo. Concrete code lines illustrate how a binary or multi-mode demo switches between sequential and parallel execution (e.g., using par_iter for core computations and par_bridge for iterator-to-parallel bridging), which matches the fields emphasis on idiomatic patterns and code templates for showing various parallel strategies in the Rayon demo context. Additional excerpts present the matmul and life/demo implementations, including specific parallel constructs (e.g., join-like composition, parallel iterators over slices, and parallel aggregation patterns) that demonstrate the use of parallel pipelines in a controlled demo environment. These parts together connect the fields description of demonstrated pipelines to tangible code and orchestration in the Rayon-demo project, including explicit references to N-body-like workflows, grid-based Life simulations, and matrix multiplication patterns that are typical showcase patterns for illustrating rayon-based parallelism. The reasoning combines evidence about the repository structure, the list of demos, and the exact code motifs (par_iter, par_bridge, join-like patterns, and par_reduce via fold) shown across these excerpts to support the field value as a concrete set of demonstrated pipelines in Rayons demo suite.",
      "confidence": "high"
    },
    {
      "field": "structured_parallelism_patterns",
      "citations": [
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack.",
            "Panics\n\nIf a panic occurs, either in the closure given to `scope()` or in\nany of the spawned jobs, that panic will be propagated and the\ncall to `scope()` will panic. If multiple panics occurs, it is\nnon-deterministic which of their panic values will propagate. Regardless, once a task is spawned using `scope.spawn()` , it will\nexecute, even if the spawning task should later panic",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:\n\n```\npub fn join<A,B,RA,RB>(oper_a: A, oper_b: B) -> (RA, RB)\n    where A: FnOnce() -> RA + Send,\n          B: FnOnce() -> RB + Send,\n          RA: Send,\n          RB: Send,\n{\n    let mut result_a: Option<RA> = None;\n    let mut result_b: Option<RB> = None;\n    rayon::scope(|s| {\n        s.spawn(|_| result_a = Some(oper_a()));\n        s.spawn(|_| result_b = Some(oper_b()));\n    });\n    (result_a.unwrap(), result_b.unwrap())\n}\n```\n",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned.",
            "pub fn scope<'scope, OP, R>(op: OP) -> R",
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "The closure given to `scope()` executes in the Rayon thread pool,\nas do those given to `spawn()` . This means that you cant access\nthread-local variables (well, you can, but they may have\nunexpected values).",
            "For an alternate approach, consider [`scope_fifo()`](fn.scope_fifo.html \"fn rayon::scope\\_fifo\") instead",
            "o reference `bad` we must\ntake ownership of it. One way to do this is to detach the closure\nfrom the surrounding stack frame, using the `move` keyword. This\nwill cause it to take ownership of _all_ the variables it touches,\nin this case including both `ok` _and_ `bad",
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "Task execution potentially starts as soon as `spawn()` is called. The task will end sometime before `scope()` returns. Note that the _closure_ given to scope may return much earlier.",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned. So in this example, absent any stealing, we can\nexpect `s.2` to execute before `s.1` , and `t.2` before `t.1` . Other\nthreads always steal from the other end of the deque, like FIFO\norder.",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:"
          ]
        },
        {
          "title": "Rust Rayon ThreadPool: 'Cannot borrow as mutable, as it is a ...",
          "url": "https://stackoverflow.com/questions/78479584/rust-rayon-threadpool-cannot-borrow-as-mutable-as-it-is-a-captured-variable-i",
          "excerpts": [
            "Chapter 4.2 of the Rust Book says that you can't have multiple mutable references to a variable, which is essentially what each thread would be getting."
          ]
        }
      ],
      "reasoning": "- An explicit statement describes scope as a fork-join scope and explains that it invokes the closure with a reference to s and that tasks spawned inside a scope will complete before the scope returns. This directly addresses the idea of a structured parallelism pattern where spawned tasks borrow stack data and must complete before the parent scope exits. It also contrasts scope with join as a more flexible primitive, which is central to the HQ pattern of structured parallelism: using scope for many tasks while join handles two tasks efficiently. - Further excerpts emphasize that scope is a flexible building block that allows spawning multiple tasks and that it blocks until all spawned tasks finish, which is exactly the lifetimes-safe coordination pattern the field value highlights. - There are cautions and guidance that prefer join or parallel iterators when possible, highlighting a trade-off between scopes heap allocation and joins stack-based execution, which aligns with the described anti-patterns and alternate patterns in the field value (favoring simpler constructs like join for two tasks, or par_iter for data-parallel workloads). - Several excerpts reinforce the lifetime safety guarantees: references to the scopes relation to borrow checks, and warnings that thread-local data may be inaccessible inside the spawned closures, which is essential to understanding safe borrowing in structured parallelism. - Additional excerpts discuss scope_fifo as an alternative ordering mechanism and compare it to scope, helping to frame when different scoped patterns are preferable, which aligns with the fields expectation of exploring alternate patterns. - Collectively, these excerpts establish a cohesive view: scope enables safe, structured parallelism with many tasks that may borrow local data, but may incur heap allocation and different performance characteristics compared to join or par_iter-based approaches. This directly supports the field values focus on HQ idiomatic patterns for structured parallelism, including code templates and alternatives.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "9    /// of equal elements.",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst"
          ]
        }
      ],
      "reasoning": "The most relevant excerpts directly describe the parallel sorting idioms and their trade-offs. The first excerpt explains the par_sort-family approach and its relation to stability and performance, which aligns with a pattern focused on Maximum Performance Sorting via par_sort_unstable. The second excerpt covers a scenario with expensive key extractions and the usefulness of a cached-key variant, which corresponds to a pattern like par_sort_by_cached_key for Expensive Key Extractions. The next excerpts detail sorting with a key extraction function in parallel, including the behavior and trade-offs of par_sort_by_key and its cached-key variant, capturing the guidance needed for a Stable Parallel Sorting idiom and the performance considerations around stability and memory. The final excerpt reinforces the caching variant and its performance benefits, tying together the recommended patterns and their contexts. Taken together, these excerpts map cleanly to the finegrained values components: the code templates for par_sort_unstable (and related variants), the contexts in which to use each pattern, anti-patterns (e.g., unnecessary use when sorting small arrays or when stability is required but not provided by unstable sorts), and the alternatives (par_sort_by_cached_key, par_sort_by_key, or sequential sorts when appropriate).",
      "confidence": "high"
    },
    {
      "field": "interoperability_patterns",
      "citations": [
        {
          "title": "Parallel stream processing with Rayon",
          "url": "https://morestina.net/1432/parallel-stream-processing-with-rayon",
          "excerpts": [
            "`par_bridge()` method defined on iterators with the corresponding [trait](https://docs.rs/rayon/latest/rayon/prelude/trait.ParallelBridge.html) . The method adapts an ordinary iterator into a parallel one, employing [clever design](https://github.com/rayon-rs/rayon/pull/550) to take individual items from the iterator and balance them between Rayons threads. Most importantly, it implements `ParallelIterator` , which means you can use the adapter exactly as you would use the value returned by `par_iter()` on a collection."
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "use rayon::iter::ParallelBridge;",
            "let rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "Rayon isn't any faster than loop despite 16x more CPU usage : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/1cra4i8/rayon_isnt_any_faster_than_loop_despite_16x_more/",
          "excerpts": [
            "I have made a prime number calculator and I don't get the speed increase from rayon I'd expect. Here is the simple code behind it.",
            "Along the same lines as you - I'm thinking they might get more of a benefit by batching then parallelizing work over each batch."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt states that par_bridge converts a sequential iterator into a parallel iterator, explicitly describing the bridging of an ordinary Iterator into a ParallelIterator and highlighting its use for parallel processing when the source is not already a parallel collection. This aligns exactly with the first pattern in the field value. Additional excerpts define the ParallelBridge trait, and show how par_bridge is invoked and what it returns, reinforcing the concept of bridging. Several excerpts also illustrate how such a bridged parallel iterator can then be consumed (e.g., collecting into a Vec) or used in tandem with other parallel operations, which supports the idea of using par_bridge in practical code templates. The field values second pattern involves using zip or zip_eq to pair elements across parallel iterators. Excerpts describing zip and zip_eq in the parallel context explicitly demonstrate combining two parallel iterators and performing elementwise computations (e.g., dot products), which directly supports the second pattern. The quotes show that zip operates on parallel iterators to produce paired elements, preserving or requiring equal lengths in the zip_eq variant, which matches the described usage. Taken together, these excerpts substantiate both the par_bridge idiom and the parallel zip pattern as idiomatic Rust Rayon usage. The ordering places direct par_bridge definitions and examples first, followed by concrete zip/zip_eq examples as they pertain to combining parallel sources, then more general ParallelIterator docs which provide context but are slightly less targeted to the exact patterns.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>",
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Clarify rust rayon nested thread pool worker numbers - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76919721/clarify-rust-rayon-nested-thread-pool-worker-numbers",
          "excerpts": [
            "I have tried to use rayon 's parallel iterators in a nested way. As a global pool would have a fixed number of threads, I tend to create an outer-pool in main.",
            "vec!\n[1, 2, 3, 4].into_par_iter().map(|inner| stress(outer * 10 + inner)).collect(",
            "})"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "})",
            "})"
          ]
        },
        {
          "title": "GitHub Issue: Performance of par_bridge (#685)",
          "url": "https://github.com/rayon-rs/rayon/issues/685",
          "excerpts": [
            "})"
          ]
        },
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "Multiple Thread Pools",
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); "
          ]
        }
      ],
      "reasoning": "The target field represents patterns for configuring and tuning Rayon for performance and reliability. Direct guidance appears in excerpts describing how to build and configure thread pools (both global and per-pool) and how to tune work granularity. Text that shows constructing a ThreadPool with specific thread counts (ThreadPoolBuilder usage) directly supports the value, by illustrating how to tailor concurrency to hardware and workload. Statements about building a global pool and using install/build_global demonstrate how to initialize and reuse a configured pool, which is central to this field. The presence of environment-based controls (e.g., RAYON_NUM_THREADS) and notes about limits and defaults reinforces the themes of configuring concurrency and understanding trade-offs between parallelism and overhead. Discussions of per-thread pools, scoped installs, and warnings about nested or repeated initializations further illustrate anti-patterns and best practices for avoiding misconfigurations, which is essential to the fields guidance on safe, efficient usage. Specific lines show: creating a custom pool with a fixed number of threads, and the global pool setup via build_global; the maximum thread count and current thread count controls; how to install a pool and run code within it; and guidance about using environment variables for simpler setups. These excerpts collectively establish the core patterns for configuring and tuning Rayon for performance and reliability, including when to use a global pool vs. a custom pool, the effects of thread counts, and how to adjust workload granularity to improve efficiency. The most relevant parts provide concrete code templates and explanations on ThreadPoolBuilder usage, global pool initialization, and environment-based controls, which map directly to the requested field value. The less direct, but still relevant, items cover related tuning knobs (with_min_len, with_max_len, and par_chunks) and general guidance about avoiding over-subscription and specifying correct pool usage to prevent deadlocks or contention. This combination supports the fields aims: practical patterns for configuring concurrency, including cautions and alternatives to optimize performance while staying robust.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns",
      "citations": [
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "nd\") ,\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. ",
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.",
            "<Self>\n\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.\nThis means that if two threads are used there will be **no** speedup **at\nall** . `by_exponential_blocks` on the other hand will start with the leftmost range from 0\nto `p` (threads number), continue with p to 3p, the 3p to 7p\n\nEach subrange is treated in parallel, while all subranges are treated sequentially. We therefore ensure a logarithmic number of blocks (and overhead) while guaranteeing\nwe stop at the first block containing the searched data. [Source](../../src/rayon/iter/mod.rs.html)\n",
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```",
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_last](.position_last) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.\n# [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 3 ), Some ( 3 ));\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 100 ), None );\n```\n",
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Collects the results of the iterator into the specified vector. The vector is always truncated before execution begins. If possible, reusing the vector across ..."
          ]
        }
      ],
      "reasoning": "- The enumerate pattern is directly shown in an excerpt titled Enumerate in rayon::iter - Rust - Docs.rs, which states that Enumerate is an iterator that returns the current count along with the element and is created by enumerate, aligning data with its original index in a parallel context. This confirms how to produce index-aware parallel results, a core part of ordering-aware patterns. - The zip_eq example excerpt clarifies how to pair two parallel iterators of equal length, enforcing invariant length equality and producing element-wise pairs, which is essential for maintaining aligned, ordered results when combining sequences in parallel. - The Position-related excerpts discuss position_any, position_first, and related functionality on IndexedParallelIterator, which directly address deterministic versus non-deterministic ordering concerns in parallel searches and index-based queries. They explain how to obtain either the first matching index (deterministic) or any matching index (non-deterministic), which is central to deciding when ordering guarantees must be preserved and when they can be relaxed for performance. - Additional excerpts show that position_first and position_last are available as methods, and that there are concrete examples demonstrating usage, further reinforcing the practical viability of ordering-aware patterns in real code. - The remaining references to general parallel iteration, by_exponential_blocks, and other non-specific ordering constructs provide helpful context but are not as directly tied to the precise field values focus on index-aware enumeration, deterministic/ nondeterministic position queries, and explicit element-wise pairing. - Taken together, the most relevant excerpts provide explicit code and explanations for enumerate, position_first/position_any, and zip_eq, which maps cleanly to the field values three pattern elements. They collectively support the field values claim that these are HQ idiomatic patterns for Rust-Rayon ordering/indexing in parallel pipelines, and show low-bug, high-reliability usage when ordering is important.",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns",
      "citations": [
        {
          "title": "FoldWith in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.FoldWith.html",
          "excerpts": [
            "The argument `identity` should be a closure that can produce\nidentity value which may be inserted into the sequence as\nneeded to create opportunities for parallel execution.",
            "\n ID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "\n            ",
            "\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpts describe the core idioms and cautions for combining a mapping step with a reduction in a parallel context. One excerpt explains fold, reduce, and sum in parallel iterators, and emphasizes that the reduction may not have a deterministic order and requires an identity, with sum existing as a concise specialization. This directly supports the finegrained field value by illustrating the canonical map-then-reduce pattern and the expectations about associativity and identity elements. Additional excerpts discuss the parallel-fold-with patterns and how to compose a local accumulator per thread and then merge with reduce_with, which is a central technique for building aggregated results like histograms without locking shared state. This underpins the anti-patterns of using shared Arc<Mutex<T>> accumulators and the need to avoid non-associative reductions, which are explicitly cautioned in the excerpts. The anti-patterns discussed (using mutex-protected shared accumulators inside a parallel loop, or reductions that are not associative) map directly to the negatives the field value warns against. Alternatives provided include using sum for simple numeric reductions and using fold/reduce for more complex aggregations, which aligns with the alternate patterns part of the field value. The cited excerpts together give a cohesive view of idiomatic map-reduce usage in Rayon and the conditions under which it remains correct and efficient.",
      "confidence": "high"
    },
    {
      "field": "parallel_collection_building_patterns",
      "citations": [
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "```\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```",
            "\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon::prelude::*;\n```\n",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "rayon::iter::FromParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "Collects (key, value) pairs from a parallel iterator into a hashmap. If multiple pairs correspond to the same key, then the ones produced earlier in the..."
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O."
          ]
        }
      ],
      "reasoning": "The idiomatic approach to constructing a new collection from a parallel iterator is to use collect() in conjunction with FromParallelIterator, which is directly demonstrated in the documentation and code examples. The collection-building flow is typically: import the Rayon prelude so you have access to the parallel iterator traits, then convert the parallel iterator into a Vec or other collection with collect(), which leverages the FromParallelIterator implementations. This is presented as drop-dead simple in the docs, and it preserves ordering for ordered targets like Vec when the underlying parallel iterator supports it. The accompanying code shows transforming a parallel iterator into a Vec via collect(), which directly supports the collect() pattern in your field value and aligns with a high-level idiom for building a collection from a parallel computation. In addition, the same documents show how a collection can be extended using par_extend(), i.e., extending an existing collection with elements drawn from a parallel iterator. This is described as the parallel analogue of extend for growing a collection and is touted as a high-throughput, locking-free approach, which avoids the common anti-pattern of synchronizing a shared container with a mutex inside a parallel closure. To complete the picture, other excerpts discuss the Prelude and the general behavior of FromParallelIterator and ParallelExtend, which are the enabling traits that make both collect and par_extend ergonomic and safe patterns in Rayon. For ordering considerations, there are notes that the parallel collect retains the original order when collecting into a container that preserves order, while in some cases order can be non-deterministic depending on the operation and data structure. This supports the idea that collect() into a Vec will preserve input order for typical ranges and slices, whereas more complex nested or non-indexed patterns may introduce nondeterminism if not carefully controlled. The alternative pattern provided in the excerpts indicates that when FromParallelIterator is not available for a type, a fold/reduce pattern is used to emulate the collection behavior, which aligns with the stated need for alternates when direct collect() isnt feasible. In sum, the excerpts consistently support the two targeted patterns (collect via FromParallelIterator and par_extend via ParallelExtend) as the primary idioms for building and extending collections from Rayons parallel iterators, with clear guidance on when to prefer these over ad-hoc locking or non-idiomatic approaches, and with caveats around ordering depending on the container and operation.",
      "confidence": "medium"
    },
    {
      "field": "platform_specific_patterns_wasm.2",
      "citations": [
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "## Feature detection",
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]"
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a pattern where an application detects environment capabilities and provides a fallback path: if WebAssembly threads are supported, load and initialize a multithreaded module; otherwise, load a single-threaded build and proceed. The most directly supportive excerpts describe the practical outcome of this approach: a generated JavaScript layer exports an initThreadPool function to prepare workers, which is the mechanism enabling the multithreaded path, while a companion note explains that WebAssembly threads use a pool of Workers and are initialized before main computation to enable multithreaded operations. These excerpts illustrate the exact template of conditional loading, the pattern of two builds (with and without threads), and the use of feature detection to choose between them, which together map to the described pattern name and template in the field value. Additional excerpts discuss how threads are provided under wasm-bindgen-rayon and how bundlers detect or enable thread support, reinforcing the context of environment-aware threading and the separation of concerns between supported environments and degraded but functional single-threaded paths. Taken together, these excerpts substantiate the concept of a Sequential Fallback for Compatibility by showing: (a) the existence of a function to initialize a thread pool, (b) the use of WebAssembly threads via Workers, (c) the role of feature detection to select between multithreaded and single-threaded builds, and (d) the practical implications of running in environments with or without thread support.",
      "confidence": "high"
    },
    {
      "field": "divide_and_conquer_patterns.0",
      "citations": [
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "This example uses join to perform a quick-sort (note this is not a\nparticularly optimized implementation: if you **actually** want to\nsort for real, you should prefer [the `par_sort` method](../rayon/slice/trait.ParallelSliceMut.html.par_sort) offered\nby Rayon). ",
            "       let (lo, hi) = v.split_at_mut(mid);",
            "       let mid = partition(v);",
            "pub fn join<A, B, RA, RB>(oper_a: A, oper_b: B) -> (RA, RB)\n\nwhere\n    A: FnOnce () -> RA + Send ,\n    B: FnOnce () -> RB + Send ,\n    RA: Send ,\n    RB: Send ,"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```\ntrait Joiner {\n    /// True if this is parallel mode, false otherwise. fn is_parallel() -> bool;\n    \n    /// Either calls `rayon::join` or just invokes `oper_a(); oper_b();`.\nfn join<A,R_A,B,R_B>(oper_a: A, oper_b: B) -> (R_A, R_B)\n        where A: FnOnce() -> R_A + Send, B: FnOnce() -> R_B + Send;\n}\n```"
          ]
        }
      ],
      "reasoning": "The finegrained field value focuses on the idiomatic pattern rayon::join for divide-and-conquer parallelism, including a concrete code template for a parallel quick-sort and a partition helper. The most directly relevant excerpt demonstrates using join to perform a quick-sort, explicitly tying the join pattern to a concrete parallel sorting example and mentioning the intended use as a quick-sort implementation. This aligns with the code_template portion of the field value, showing how the two recursive branches are launched in parallel and how the base case uses a sequential fallback. Other highly relevant excerpts provide concrete API and signature details for the join function, including the required FnOnce closures and Send bounds, which underpin the idiomatic pattern. Additional excerpts illustrate how the slice is partitioned and split for parallel processing, matching the references to a partition function and the split_at_mut step found in the code template. Collectively, these excerpts corroborate the code structure, usage context, and low-overhead, data-race-free parallelism emphasized by the field value. The remaining excerpt adds broader context about performance considerations and anti-patterns, which further support the contextual understanding of when and how to apply this idiomatic pattern, though they are slightly less central to the exact code-template focus.",
      "confidence": "high"
    },
    {
      "field": "testing_and_reproducibility_patterns.0",
      "citations": [
        {
          "title": "rayon-core/src/thread_pool/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-core/src/thread_pool/mod.rs",
          "excerpts": [
            "o\n/// keep busy while the `op` completes in its target pool, similar to\n/// calling [`ThreadPool::yield\\_now()`] in a loop. Therefore, it may\n/// potentially schedule other tasks to run on the current thread in the\n/// meantime. For example\n///\n/// ```ignore-wasm\n/// # use rayon\\_core as rayon;\n/// fn main() {\n/// rayon::ThreadPoolBuilder::new().num\\_threads(1).build\\_global().unwrap();\n/// let pool = rayon\\_core::ThreadPoolBuilder::default().build().unwrap();\n/// let do\\_it = || {\n/// print!(\"one \");\n/// pool.install(||{});\n/// print!(\"two \");\n/// };\n/// rayon::join(|| do\\_it(), || do\\_it());\n/// }\n/// ```\n///\n/// Since we configured just one thread in the global pool, one might\n/// expect `do\\_it()` to run sequentially, producing:\n///\n/// ```ascii\n/// one two one two\n/// ```\n///\n/// However each call to `install()` yields implicitly, allowing rayon to\n/// run multiple instances of `do\\_it()` concurrently on the single, global\n/// thread. The following output would be equally valid:",
            "pub fn install(&self, op: OP) -> R\nwhere\nOP: FnOnce() -> R + Send,\nR: Send,\n{\nself.registry.in\\_worker(|\\_, \\_| op())\n",
            "pub fn current\\_num\\_threads(&self) -> usize {\nself.registry.num\\_threads("
          ]
        },
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        }
      ],
      "reasoning": "The per-test custom thread pool idiom relies on constructing a dedicated Rayon ThreadPool with a fixed number of threads and then executing the test code inside that pool. The excerpts show concrete usage of a pool builder to set a specific number of threads and then use pool.install to run a closure within that pool. This directly maps to the core parts of the idiom: (a) creating a pool with a defined thread count, and (b) riding code execution within that pool to ensure isolation and determinism in tests. One excerpt demonstrates a code example building a pool with four threads and installing a test workload inside it, which mirrors the exact code pattern described in the fine-grained value. Another excerpt reinforces the concept by showing the pool usage function and its effect on scope of execution, clarifying how operations inside the pool remain isolated from the global pool. A third excerpt discusses querying or interacting with thread pool state (such as the current number of threads) which provides supporting context about fixed-thread environments, reinforcing why per-test pools yield determinism. A fourth excerpt delves into broader scope utilities and parallel constructs, offering ancillary context that helps understand how Rayon handles task execution and isolation, though it does not explicitly present the per-test pool pattern itself.",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.1",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel..."
          ]
        }
      ],
      "reasoning": "The provided excerpts collectively establish the core context for the idiom of parallel iteration in Rayon. The most directly relevant bits describe how to enable and use parallel iterators: changing a normal iterator to a parallel one and pulling in the necessary traits via the Rayon prelude. This is foundational to understanding the par_iter_mut pattern, since enabling the mutable parallel iteration requires bringing in the appropriate traits and understanding how parallel iterators are intended to replace sequential iterations. The excerpts also reinforce the safety guarantees of Rayon (data-race freedom) and the general behavior that parallel code tends to produce the same results as sequential code when correctly constrained, which supports evaluating the correctness and safety of in-place parallel mutation patterns. Additionally, the excerpts contrast high-level concepts of data-parallelism and the role of the prelude, which helps situate the par_iter_mut pattern within Rayons design. The anti-pattern and alternate-pattern ideas are implied by the discussion of when parallelization is appropriate (e.g., overhead for tiny workloads, and the existence of non-mutable parallel patterns like par_iter for read-only scenarios). The quotes from the excerpts that emphasize converting sequential iterators to parallel ones, and the explicit mention of bringing parallel iterator APIs into scope via the prelude, directly support understanding and validating the par_iter_mut usage pattern and its ecosystem within Rayon.",
      "confidence": "high"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.0",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        }
      ],
      "reasoning": "The field value centers on an N-body style simulation with an explicit pattern of toggling between sequential and parallel execution for an embarrassingly parallel numeric kernel, including references to parallel iteration and a reduction-style parallel pattern. The most directly pertinent information is that the repository provides a Rayon-demo benchmark suite and that one of the benchmarks is nbody described as a physics simulation of multiple bodies attracting and repelling one another. This aligns with the notion of an N-body workload being run under different parallel strategies via a command-line interface, which directly supports the described pattern of switching between sequential and parallel execution and mentions a parallel approach (par) and a potential reduction-style pattern (parreduce). Supporting detail from the same set of excerpts shows a CLI dispatching to multiple benchmarks (including nbody), reinforcing that the repository demonstrates distinct execution strategies in practice. Less direct but contextually relevant are the matmul benchmarks, which imply broader parallel benchmarking in the same project, but they do not directly illustrate the N-body sequential-vs-parallel toggle feature described in the field value.",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.0",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The core fine-grained field centers on the idiomatic parallel iteration pattern using par_iter() in Rayon, including a concrete code template that substitutes a standard iterator with a parallel one and maps over elements for a computation that can be reduced via sum. The strongest support comes from excerpts that show concrete code using input.par_iter() and a par_iter()-based transformation (mapping elements and summing), which directly evidences the exact pattern in question. Additional excerpts demonstrate how to bring the parallel-iterator APIs into scope with the prelude import, which is necessary for enabling the pattern in real code. Other excerpts discuss Rayons design goals like data-race freedom and the general description of Rayon as a data-parallelism library, which provide essential context confirming why par_iter() is considered idiomatic for safe parallel iteration and under what conditions it is beneficial or not (anti-patterns). Together, these excerpts collectively validate the existence, usage, and constraints of the par_iter() pattern: the code template shows the concrete usage, the prelude excerpts show how to access the trait methods, and the contextual excerpts clarify when par_iter() is advantageous versus when simpler sequential iteration or other patterns should be used.",
      "confidence": "high"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.2",
      "citations": [
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "rayon::join(|| rcopy(s1, d1), || rcopy(s2, d2));",
            "pub fn matmulz(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "let ((r1, r2), (r3, r4)) = rayon::join(|| rayon::join(f1, f2), || rayon::join(f3, f4));",
            "matmul_strassen(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "|| strassen_add2_mul(a11, a22, b11, b22),",
            "|| strassen_add_mul(a21, a22, b11),",
            "|| strassen_sub_mul(b12, b22, a11),",
            " .zip(src.par_iter())",
            " .for_each(|(d, s)| *d += *s);",
            "fn rcopy(src: &[f32], dest: &mut [f32]) {",
            "if dest.len() <= LINEAR_CHUNK {",
            "dest.copy_from_slice(src);",
            "return;",
            "}",
            "let (m1, m2, m3, m4, m5, m6, m7, _) = join8(",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a demonstrated pattern for Parallel Matrix Multiplication within the Rayon demo: a recursive divide-and-conquer approach using rayon::join to spawn sub-tasks, with attention to cache locality and avoiding parallelization of tiny blocks, plus an alternate pattern using a Z-order traversal for data locality. The most directly relevant excerpts are those that show the core usage of rayon::join for coordinating parallel sub-computations, the presence of helper patterns like join4/join8, and the parallel-zip operation that combines destination and source slices. Additional excerpts illustrate the matrix multiplication variants and how subproblems are split and managed, including threshold-based switching to sequential execution and the introduction of a cache-friendly data layout variant (Z-order). Together, these excerpts corroborate the described pattern: recursive parallel decomposition with explicit task spawning via rayon::join, guarded subproblem sizing to avoid overhead, and optional data-layout optimizations to improve locality. The excerpts also show auxiliary code (e.g., rcopy, par_iter_zip, and Strassen-like compositions) that align with the broader theme of parallel matrix operations and performance-focused patterns demonstrated in the Rayon demo.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.0",
      "citations": [
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "This is because the Wasm code needs to take its own object (the `WebAssembly.Module` ) and share it with other threads when spawning them. This object is only accessible from the `--target web` and `--target no-modules` outputs, but we further restrict it to only `--target web` as we also use [JS snippets feature](https://rustwasm.github.io/wasm-bindgen/reference/js-snippets.html) .",
            "## Using Rayon\n",
            "## Feature detection",
            "import { threads } from 'wasm-feature-detect' ;",
            "The other issue is that the Rust standard library for the WebAssembly target is built without threads support to ensure maximum portability. Since we want standard library to be thread-safe and [`std::sync`](https://doc.rust-lang.org/std/sync/) APIs to work, you'll need to use the nightly compiler toolchain and pass some flags to rebuild the standard library in addition to your own code.",
            "In order to reduce risk of breakages, it's strongly recommended to use a fixed nightly version. This crate was tested with `nightly-2024-08-02` .",
            "```",
            "\n## Usage with various bundlers",
            "let wasmPkg ;"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        },
        {
          "title": "Allow setting COOP and COEP headers in Github Pages #13309",
          "url": "https://github.com/orgs/community/discussions/13309",
          "excerpts": [
            "In order to use SharedArrayBuffer and WebAssembly Threads, COOP and COEP headers need to be set, such that the page becomes cross-origin isolated."
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```",
            "```",
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```",
            "```",
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon Scope and spawn documentation",
          "url": "https://docs.rs/rayon/latest/rayon/struct.Scope.html",
          "excerpts": [
            "```",
            "```"
          ]
        },
        {
          "title": "rayon docs: Iteration - ParallelExtend and FromParallelIterator",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "```",
            "```"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "```",
            "```"
          ]
        }
      ],
      "reasoning": "The most directly relevant information comes from excerpts that explicitly discuss wasm_bindgen_rayon and its role in bridging Rayons threading model to WebAssembly, as well as excerpts showing how to initialize and expose a thread pool to the browser. The following excerpts align with the finegrained field value by describing the core pattern: enabling multithreading for Rayon in a browser environment through the wasm-bindgen-rayon adapter, which is the fundamental mechanism referenced in the field value. It is also important to connect these technical details to practical usage, including how the thread pool is initialized in JavaScript and how the thread pool is exposed to the Wasm module, since the field value includes code templates showing the Cargo.toml, Rust code, and JavaScript usage for initThreadPool. Additionally, excerpts that mention the challenges, caveats, and anti-patterns provide context for when this pattern is appropriate or not, supporting the anti-pattern and alternate patterns parts of the field value. The most relevant items directly state the adapters purpose and its browser/WebAssembly usage, the mechanism to expose a thread pool, and the requirement to initialize the thread pool before parallel work. The next set of excerpts provide practical notes on the browser/WebWorker integration, including how WebAssembly threads use Web Workers and the necessary JS glue, which reinforces the context for multithreading in Wasm. Subsequent excerpts describe usage patterns and caveats, including the need for a nightly toolchain and specific build flags, and warnings about anti-patterns (like assuming parallel speedups without proper setup) and alternatives (offloading to a worker or using a dedicated Web Worker with a messaging layer). Direct quotes and paraphrased details from the excerpts illustrate the concrete steps (Cargo.toml dependencies, Rust code to re-export init_thread_pool, and JavaScript init usage) that underpin the field values template. Collectively these excerpts map to the field values components: (a) code template and dependencies (Rust/Cargo and wasm_bindgen_ray on), (b) usage context describing browser multithreading with Wasm, (c) explicit initThreadPool usage in JS, (d) anti-patterns and alternates for broader guidance.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.1",
      "citations": [
        {
          "title": "Allow setting COOP and COEP headers in Github Pages #13309",
          "url": "https://github.com/orgs/community/discussions/13309",
          "excerpts": [
            "In order to use SharedArrayBuffer and WebAssembly Threads, COOP and COEP headers need to be set, such that the page becomes cross-origin isolated."
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Using Rayon\n",
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        }
      ],
      "reasoning": "The finegrained field value hinges on enabling cross-origin isolation to allow WebAssembly threads by providing SharedArrayBuffer support. The most directly relevant excerpt states that cross-origin isolation is achieved by setting the Cross-Origin-Opener-Policy and Cross-Origin-Embedder-Policy headers for the main HTML document, which is exactly the practical configuration described in the field value. This establishes the prerequisite security condition that enables multithreading in the browser, aligning with the need for low-bug deployments and preventing runtime errors due to unavailable browser APIs. Additional excerpts discuss using WebAssembly threads with wasm-bindgen-rayon and related tooling, including how the thread pool is initialized and how threads are managed, which provides context on the implementation of multithreading once the isolation prerequisites are met, but do not replace the core requirement identified in the first excerpt. These corroborate the broader pattern of enabling and configuring threading in Wasm ecosystems, showing practical steps like initializing thread pools and using wasm-bindgen-rayon, which complements the primary headers-based prerequisite by illustrating how the threading feature is utilized in code after isolation is established.",
      "confidence": "medium"
    },
    {
      "field": "parallel_slice_processing_patterns.0",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>",
            "fn par_rchunks(&self, chunk_size: usize) -> RChunks<'_, T> { ... }",
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length.",
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n"
          ]
        }
      ],
      "reasoning": "The target field value describes processing a mutable slice in parallel by dividing it into non-overlapping, mutable chunks in a way that guarantees no data races between chunks. Excerpts that discuss chunk-based parallel constructs are therefore directly relevant. The discussion of par_chunks shows a function that splits a slice into non-overlapping sub-slices for parallel processing, which aligns with the core idea of non-overlapping mutable chunks used in in-place parallel work. The mention of par_chunks_exact further reinforces the idea of controlling chunk boundaries in a parallel context, which is part of the broader pattern of chunked parallel execution. The mention of par_rchunks introduces the idea of handling chunks in a reverse or alternative chunking form, still within the same family of parallel chunking APIs, which informs alternatives and trade-offs in how to partition work. Other excerpts discuss par_windows and par_split, which, while not the exact mutating chunk pattern, illustrate related parallel-slice capabilities and how data can be processed in parallel segments or segments separated by conditions, providing broader context for when and how chunk-based parallel patterns are used. Taken together, these excerpts support understanding the general approach of parallel chunking and mutability in Rayon, as well as practical considerations like exact chunk sizes and non-overlapping guarantees. However, none of the excerpts provide an explicit par_chunks_mut example, which means the precise code template, usage context, anti-patterns, and explicit alternates for par_chunks_mut are not directly evidenced and must be inferred from related APIs and guidance.",
      "confidence": "low"
    },
    {
      "field": "parallel_slice_processing_patterns.2",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length."
          ]
        }
      ],
      "reasoning": "The field value describes a parallel split pattern where a slice is divided into subslices using a separator predicate, and each subslice is processed in parallel. The most relevant excerpt provides an exact code template and example demonstrating this: it shows constructing a parallel iterator that splits a slice on a predicate (|x| *x == 0), then maps each resulting sub-slice to a product and collects the results, including an assertion of the expected output. This directly matches the described code_template, usage_context, and the idea of processing subslices in parallel for efficient computation. The excerpt also contains a forward-looking description of splitting by a separator and processing in parallel, reinforcing the patterns semantics. The second relevant excerpt explicitly states that the operation yields a parallel iterator over subslices separated by elements that match the separator, which confirms the core mechanism of the pattern and aligns with the described usage and anti-pattern concerns (e.g., potential overhead if too many tiny subslices). Together, these excerpts corroborate the field value's components: the parallel split by a separator, the code template, the usage context for processing subslices in parallel, and the potential alternative (or anti-patterns) implied by the surrounding discussion.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.0",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explicitly references instability in a parallel sort, mentioning that the sort is unstable (may reorder equal elements) and in-place, and notes its O(n log n) complexity and performance emphasis. This directly aligns with the described par_sort_unstable pattern and its emphasis on maximum performance with no stability guarantees. The next item discusses a parallel sort with a key extraction function and notes that it might not preserve order, which also touches on instability and ordering guarantees relevant to the unstable variant. Further excerpts describe sorting the slice in parallel with a comparator and note stability in that context, providing necessary contrast to the unstable pattern and reinforcing the distinction between stable and unstable parallel sorts. Additional excerpts discuss a general parallel sort (par_sort) and its characteristics in the same family of functions, which helps situate the unstable variant within the broader parallel sorting landscape. A fragment focusing on the notion of equal elements reinforces the concept that stability concerns are central to deciding when an order should be preserved, though it is less directly about the unstable variant itself. Collectively, these excerpts support the field value by detailing the in-place, parallel, unstable sorting approach, its lack of stability guarantees, and its performance characteristics, while also contrasting it with stable alternatives.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.1",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "9    /// of equal elements.",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T"
          ]
        }
      ],
      "reasoning": "The target field value centers on a stable parallel sorting pattern in a Rust context using Rayon. Excerpts that explicitly claim stability or discuss the preservation of order for equal elements directly support this claim. One excerpt states that the parallel sort is stable (i.e., does not reorder equal elements), which directly corroborates the notion of a stable parallel pattern. Other excerpts describe that the parallel sort may not preserve order in some variants or when using key extraction, which aligns with the contrast between stable par_sort and unstable variants. Collectively, these excerpts map to the concept of a stable parallel sorting pattern, its typical code shape, and the related anti-patterns and alternates (e.g., using an unstable variant or a different sorting approach). The remaining excerpts provide context about the general parallel sorting function and related helpers, reinforcing the overall landscape but are slightly less central to the exact notion of stability for the finegrained field. Directly quoted elements such as the claim of stability, the note about potential non-preservation of order in some variants, and mentions of unstable sorting variants are the strongest connectors, with the code shape and comparator/key-based sorting further supporting the intended template and usage context.",
      "confidence": "high"
    },
    {
      "field": "interoperability_patterns.1",
      "citations": [
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a pattern name corresponding to zipping two parallel iterators (zip / zip_eq) and provides a code template that demonstrates element-wise computation using par_iter and zip. It also notes that the zip operation yields an iterator of paired elements and discusses the difference between zip and zip_eq depending on length guarantees. The most supportive information in the excerpts is a direct statement that Zip is an iterator that zips up two sequences into a single iterator of pairs, created by the zip() method on an IndexedParallelIterator, which aligns with the described pattern name and its behavior. This excerpt directly corroborates the core concept of zipping two parallel iterators to form element-wise computations, which is central to the fine-grained field value. The other excerpts discuss related parallel-iteration utilities (like ParallelBridge) that are tangential to the exact zip-based interoperability pattern and do not provide explicit confirmation about zip() behavior or the zip_eq variant, making them less relevant to the specific field value.",
      "confidence": "medium"
    },
    {
      "field": "interoperability_patterns.0",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "let rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "use rayon::iter::ParallelBridge;"
          ]
        },
        {
          "title": "Parallel stream processing with Rayon",
          "url": "https://morestina.net/1432/parallel-stream-processing-with-rayon",
          "excerpts": [
            "`par_bridge()` method defined on iterators with the corresponding [trait](https://docs.rs/rayon/latest/rayon/prelude/trait.ParallelBridge.html) . The method adapts an ordinary iterator into a parallel one, employing [clever design](https://github.com/rayon-rs/rayon/pull/550) to take individual items from the iterator and balance them between Rayons threads. Most importantly, it implements `ParallelIterator` , which means you can use the adapter exactly as you would use the value returned by `par_iter()` on a collection."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        }
      ],
      "reasoning": "The core concept in the finegrained field value is the conversion of a sequential Iterator into a ParallelIterator using a bridge (par_bridge), which is described as creating a bridge from a sequential iterator to a parallel one by distributing items across a thread pool. Excerpts that directly state or exemplify this conversion and its mechanics are therefore the most relevant. The excerpt explicitly defining the conversion as a bridge and describing its distribution of items across Rayon s thread pool is the closest match to the field value. Excerpts that discuss the ParallelBridge trait, the fact that it adapts an ordinary iterator into a parallel one, and that the bridge enables parallel processing of otherwise sequential sources (including notes about buffering and potential ordering implications) directly support the field values template and usage context. Additional excerpts show concrete usage (code examples) and the surrounding documentation that clarifies when this bridge is advantageous or not, which aligns with the fields description of use cases (file I/O, channels) and the anti-patterns (using par_bridge when a direct par_iter on a collection is available, potential deadlocks, and non-preservation of order). The excerpts that mention the lack of guaranteed ordering and the performance considerations underpin the anti-pattern and alternate-pattern sections of the field value. Contextual excerpts that discuss general benefits of parallelizing via a bridge and scenarios where its useful (e.g., difficult-to-parallelize iterators like channels) further reinforce the overall interoperability pattern captured in the field value. Overall, the most supportive content centers on the explicit definition of par_bridge as a bridge from sequential to parallel, followed by concrete usage and implications, with supplementary guidance on performance and alternatives providing broader context.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The requested fine-grained field value corresponds to explicit fallible/error-handling patterns in Rayon. The most relevant excerpts directly name a fallible parallel primitive: a try_for_each method that enables early exit on errors in a parallel-for-each, which matches the Pattern 1 description of an idiom where side effects (like I/O) are aborted early upon error. The next most relevant excerpts discuss fallible aggregation primitives: try_fold, followed by try_reduce, and a variant try_reduce_with. These describe how to perform per-thread fallible accumulation and then merge results, which aligns with Pattern 2 in the field value. A closely related excerpt covers try_reduce_with explicitly, tying together per-item fallibility with a final reduction, further supporting Pattern 2. There are excerpts that touch on collecting results in a fallible/reporting-friendly way (Pattern 3), which provides useful context for error reporting in parallel processing but is slightly more peripheral to the named methods. Taken together, the excerpts support the three patterns described in the field value, with the strongest alignment to the specific try_for_each and try_fold/try_reduce family patterns, and a supportive link to error-reporting collection patterns.",
      "confidence": "high"
    },
    {
      "field": "structured_parallelism_patterns.0",
      "citations": [
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack.",
            "The closure given to `scope()` executes in the Rayon thread pool,\nas do those given to `spawn()` . This means that you cant access\nthread-local variables (well, you can, but they may have\nunexpected values).",
            "Task execution potentially starts as soon as `spawn()` is called. The task will end sometime before `scope()` returns. Note that the _closure_ given to scope may return much earlier.",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned. So in this example, absent any stealing, we can\nexpect `s.2` to execute before `s.1` , and `t.2` before `t.1` . Other\nthreads always steal from the other end of the deque, like FIFO\norder.",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:\n\n```\npub fn join<A,B,RA,RB>(oper_a: A, oper_b: B) -> (RA, RB)\n    where A: FnOnce() -> RA + Send,\n          B: FnOnce() -> RB + Send,\n          RA: Send,\n          RB: Send,\n{\n    let mut result_a: Option<RA> = None;\n    let mut result_b: Option<RB> = None;\n    rayon::scope(|s| {\n        s.spawn(|_| result_a = Some(oper_a()));\n        s.spawn(|_| result_b = Some(oper_b()));\n    });\n    (result_a.unwrap(), result_b.unwrap())\n}\n```\n",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned.",
            "For an alternate approach, consider [`scope_fifo()`](fn.scope_fifo.html \"fn rayon::scope\\_fifo\") instead",
            "Panics\n\nIf a panic occurs, either in the closure given to `scope()` or in\nany of the spawned jobs, that panic will be propagated and the\ncall to `scope()` will panic. If multiple panics occurs, it is\nnon-deterministic which of their panic values will propagate. Regardless, once a task is spawned using `scope.spawn()` , it will\nexecute, even if the spawning task should later panic",
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "pub fn scope<'scope, OP, R>(op: OP) -> R",
            "o reference `bad` we must\ntake ownership of it. One way to do this is to detach the closure\nfrom the surrounding stack frame, using the `move` keyword. This\nwill cause it to take ownership of _all_ the variables it touches,\nin this case including both `ok` _and_ `bad"
          ]
        },
        {
          "title": "Rust Rayon ThreadPool: 'Cannot borrow as mutable, as it is a ...",
          "url": "https://stackoverflow.com/questions/78479584/rust-rayon-threadpool-cannot-borrow-as-mutable-as-it-is-a-captured-variable-i",
          "excerpts": [
            "Chapter 4.2 of the Rust Book says that you can't have multiple mutable references to a variable, which is essentially what each thread would be getting."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes the idiomatic pattern rayon::scope as a structured parallelism primitive, with notes that it creates a fork-join scope, allows spawning tasks that may borrow from the local stack, and guarantees completion before scope returns. It also notes trade-offs around heap allocation vs stack usage, and contrasts this with alternatives like rayon::join. The most directly relevant excerpts explicitly define scope as a fork-join scope that is invoked with a closure, where spawned tasks may run asynchronously and the scope blocks until all spawned tasks complete. This establishes the core semantics that the field value relies on: a scope creates a context to spawn multiple tasks, guarantees completion of those tasks before returning, and enables safe borrowing from the local stack. Additional excerpts reinforce that the closure executes within the Rayon thread pool, so borrowing from the parent stack must be careful (e.g., avoiding non-static references), and that execution order of spawns is not guaranteed, which directly informs the anti-patterns and usage guidelines in the field value. Further support comes from comparisons to join, showing when to prefer join or parallel iterators for efficiency, and from notes about when tasks start and end relative to scope return, which aligns with the example code where the template guarantees results only after all tasks finish. The anti-patterns and alternatives described in related excerpts (preferring join when possible, or suggesting scope_fifo as an alternative) also map to the provided anti-patterns and alternate patterns fields. Taken together, these excerpts collectively substantiate the field values claim about the purpose, guarantees, and practical usage of rayon::scope for structured parallelism, its borrowing rules within a scoped context, and how it compares to other patterns like rayon::join. The most relevant details are the explicit description of scope as a fork-join scope, the guarantee of completion, and the caveats around borrowing and heap vs stack considerations, which form the backbone of the provided code template and usage context.",
      "confidence": "medium"
    },
    {
      "field": "parallel_slice_processing_patterns.1",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>",
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length.",
            "fn par_rchunks(&self, chunk_size: usize) -> RChunks<'_, T> { ... }",
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>"
          ]
        }
      ],
      "reasoning": "The fine-grained field value refers to the par_windows idiom for creating overlapping windows over a slice via a parallel iterator. The most relevant content explicitly defines and showcases par_windows: it states that the method returns a parallel iterator over all contiguous windows of a given length, with examples showing constructing windows from a slice and asserting the resulting windowed vectors. This directly confirms the code template and the overlapping nature required by the pattern. Additional excerpts provide the function signature and further description of par_windows, reinforcing its behavior and usage. While other excerpts discuss related parallel-slicing utilities (such as non-overlapping par_chunks) and related methods, they are less directly aligned with the par_windows pattern and its overlapping semantics. Taken together, these excerpts substantiate the pattern name, its core behavior (overlapping windows), the typical code template, and an example of usage in Rust with Rayon, which supports the described field value and its intended usage context.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.2",
      "citations": [
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        }
      ],
      "reasoning": "The fine-grained field value centers on an idiomatic pattern for parallel element-wise operations using zip and its safe variant zip_eq. An excerpt stating that Zip is an iterator that zips up two sequences into a single iterator directly supports the core idea of pairing elements from two inputs in parallel. This establishes the fundamental idiom of combining parallel iterators in a way that preserves corresponding positions, which is essential for element-wise operations like vector addition or dot products. The accompanying excerpt indicating a concrete file location for the Zip implementation (zip.rs) reinforces that this is the canonical Rayon construct for this pattern, further validating that this is the idiomatic approach in this ecosystem. Collectively, these excerpts support the claim that the idiomatic pattern for parallel element-wise operations relies on zip to pair corresponding elements from two inputs in a structured, order-preserving way, with a safer alternative (zip_eq) when length invariants must be enforced. The excerpts do not discuss other unrelated parallel iterator utilities, so they do not provide evidence against this specific idiom, and they do not contradict the safety/invariants aspects mentioned in the fine-grained field value. The relation to the anti-pattern and alternate patterns is contextual and supported by the provided explanation that zip_eq enforces invariants and that manually indexing would be a less clean alternative, which aligns with the anti-pattern and alternate-pattern notes in the field value.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.1",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it.",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>"
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        },
        {
          "title": "Clarify rust rayon nested thread pool worker numbers - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76919721/clarify-rust-rayon-nested-thread-pool-worker-numbers",
          "excerpts": [
            "I have tried to use rayon 's parallel iterators in a nested way. As a global pool would have a fixed number of threads, I tend to create an outer-pool in main.",
            "vec!\n[1, 2, 3, 4].into_par_iter().map(|inner| stress(outer * 10 + inner)).collect(",
            "})"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "})",
            "})"
          ]
        },
        {
          "title": "GitHub Issue: Performance of par_bridge (#685)",
          "url": "https://github.com/rayon-rs/rayon/issues/685",
          "excerpts": [
            "})"
          ]
        },
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); ",
            "Multiple Thread Pools"
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        }
      ],
      "reasoning": "The core of the fine-grained field value is a pattern named ThreadPoolBuilder (Per-Task Custom Pool) that demonstrates constructing a dedicated thread pool, running a specific parallel computation within it, and the associated usage context, anti-patterns, and alternatives. The most directly relevant excerpts explicitly state that ThreadPoolBuilder is used to create a new ThreadPool or to configure the global rayon thread pool, and they describe how a custom pool is built (with num_threads) and used (via install to run a parallel operation). Additional excerpts explain the rationale for per-task or per-work isolation to improve robustness and performance, including isolating workloads and improving test reproducibility. They also discuss anti-patterns such as creating many short-lived pools or nesting pools, which directly relate to the anti-pattern field. Some excerpts place ThreadPoolBuilder in the broader context of thread pool configuration (including global pool behavior and maximum thread counts). Others discuss related patterns like using the default global pool or offloading blocking work to other runtimes, which provides an alternate pattern for comparison. The more distant excerpts cover general ThreadPool capabilities (e.g., ThreadPool docs, the concept of a pool, and configuration options like stack size or names) which still support the field value by giving necessary background. Taken together, the excerpts that describe building and using a per-task custom pool, the install/run pattern inside that pool, and the identified anti-patterns provide the strongest, most direct support for the fine-grained field value, followed by excerpts that broaden the context with related patterns and cautions.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            " );\n```\n\n### `fn [fold](.fold) <T, ID, F>(self, identity: ID, fold_op: F) -> [Fold](struct.Fold.html \"struct rayon::iter::Fold\") <Self, ID, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nParallel fold is similar to sequential fold except that the\nsequence of items may be subdivided before it is\nfolded. Consider a list of numbers like `22 3 77 89 46` . If\nyou used sequential fold to add them ( `fold(0, |a,b| a+b)` ,\nyou would wind up first adding 0 + 22, then 22 + 3, then 25 +\n77, and so forth.\nThe **parallel fold** works similarly except\nthat it first breaks up your list into sublists, and hence\ninstead of yielding up a single sum at the end, it yields up\nmultiple sums. The number of results is nondeterministic, as\nis the point where the breaks occur.",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity.",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity.",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "You can combine `fold` with `reduce` if you want to produce a\nsingle value. This is then roughly equivalent to a map/reduce\ncombination in effect:"
          ]
        },
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "The state-management pattern described favors a per-thread local accumulator that is later merged in a reduce step. Excerpts that state that a parallel fold is followed by a reduce to combine per-thread results directly support the fold-then-reduce pattern. They explain that each thread maintains its own local state during the fold, and then the local results are merged (reduced) into a final result, which eliminates lock contention in the hot loop and scales well with cores. This directly aligns with the intended pattern name and its code template shown in the excerpts, where a local HashMap is built in each thread during fold and then merged by reduce. Additional excerpts emphasize that the final result is obtained by reducing the per-thread accumulators, which reinforces the patterns core concept and its efficiency advantages. The presence of notes about nondeterministic ordering in parallel reductions highlights the need to ensure the operator is associative when using fold/reduce, which is a critical caveat for correctness in this pattern. Excerpts describing per-thread storage and mutex-based sharing illustrate common anti-patterns when shared mutable state is updated inside parallel loops; these excerpts serve as important contrast points to the fold-then-reduce pattern, underscoring why avoiding per-item locking is recommended. The combination of direct fold/reduce guidance and explicit cautions about locking provides a coherent map for implementing high-performance, low-bug state management in rayon-based code, with deterministic ordering considerations handled by choosing appropriate reduction strategies. Overall, the most directly supportive material is the explicit fold-then-reduce narrative and its illustrative code, followed by cautions about using locks and the counterpoints with per-thread storage and mutexes. ",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.1",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        },
        {
          "title": "FoldWith in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.FoldWith.html",
          "excerpts": [
            "The argument `identity` should be a closure that can produce\nidentity value which may be inserted into the sequence as\nneeded to create opportunities for parallel execution.",
            "\n ID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "\n            "
          ]
        }
      ],
      "reasoning": "The most relevant passages directly discuss reduction semantics in Rayon: the concept of reducing a parallel iterator with a combining operation, the need for an identity element, and the behavior of reduce_with as an alternate form. In particular, one excerpt explains that a reduction with an identity and a combining operation is used to compute a sum of squares or other aggregations, highlighting that it requires an identity value and an associative operation to guarantee correct results. This aligns with the fine-grained field value describing a reduction pattern with an identity and a combining operation, and emphasizes the patterns efficiency for parallelization and correctness when the operation is associative. A closely related excerpt elaborates on reduce_with as the same general idea but with a explicitly named operator, reinforcing that there is a variant of reduce that takes a binary operation and that this operation must be associative to maintain determinism in the non-deterministic execution order of a parallel iterator. Another excerpt presents the fold_with and reduce_with constructs, describing how they apply an initial value and a folding function across items, and it clarifies that the reduce-like patterns do not require the initial value to be Sync, and that the folding can be done with an identity and a combining operation, which ties directly to the code template described in the field value. Additional excerpts cover try_reduce and try_reduce_with, illustrating fallible reductions and the behavior when iterators are empty or errors occur, which still fall under the same broad reduce paradigm but with error-handling semantics. The anti-patterns are addressed where non-associative operations can yield incorrect results because the non-deterministic ordering in parallel execution affects accumulation, and providing an incorrect identity can lead to wrong results. Finally, excerpts that propose alternate patterns such as using sum for simple sums, or using fold when the accumulator type differs, or using fold together with reduce to combine different types, provide explicit alternatives to the referenced reduce(identity, op) pattern. Taken together, these excerpts provide strong, multi-faceted support for the field values description of a reduce pattern with identity and op, its correctness constraints, and practical alternatives.",
      "confidence": "high"
    },
    {
      "field": "parallel_collection_building_patterns.0",
      "citations": [
        {
          "title": "rayon::iter::FromParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "Collects (key, value) pairs from a parallel iterator into a hashmap. If multiple pairs correspond to the same key, then the ones produced earlier in the..."
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:",
            "\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon::prelude::*;\n```\n",
            "```\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool."
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        }
      ],
      "reasoning": "The field value centers on the idiomatic pattern of constructing a new collection from a parallel iterator by using collect(), specifically via the FromParallelIterator path. The strongest support comes from an excerpt explicitly mentioning FromParallelIterator in the context of collecting key/value pairs into a hashmap, which demonstrates the collect-based path from a parallel iterator to a concrete collection type. Additional support comes from excerpts describing how Rayon makes it easy to switch sequential iterators to parallel ones by calling par_iter(), highlighting the practical code template where collect would commonly be used to assemble the final collection. Related excerpts reinforce the recommended practice of using collect() to avoid manual shared-state patterns (like Arc<Mutex<Vec<...>>>) and point to alternatives (fold-reduce) when collect() isnt available for a given type, which aligns with the anti-pattern and alternatives portion of the field. Other excerpts discuss bringing the Rayon prelude into scope to enable parallel iterator APIs, and general notes about performance trade-offs when using parallel bridges, which provide essential context about when and why collect-based idioms are preferred. Taken together, these excerpts support the field value by confirming the collect-based idiom as a primary, idiomatic, high-throughput approach for building new collections from parallel iterators, while contrasting it with anti-patterns and providing alternatives when needed.",
      "confidence": "medium"
    },
    {
      "field": "platform_specific_patterns_wasm.2.anti_patterns",
      "citations": [
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Feature detection"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        }
      ],
      "reasoning": "The fine-grained field describes an anti-pattern: shipping only a multithreaded build of the application, which would fail to load or run in browsers that do not support Wasm threads, resulting in poor user experience. The excerpts collectively discuss Wasm threads, Web Workers, and patterns for enabling Rayon-based concurrency in the browser environment. Excerpts that explain that WebAssembly threads rely on Web Workers and that wasm-bindgen-rayon provides the JS glue and Workers support are most relevant, because they establish the context in which a multithreaded build operates and its browser requirements. Excerpts that describe initial pool initialization and thread usage demonstrate the mechanism that would be shipped in a multithreaded build and help explain why such a build could be problematic if browsers lack thread support. Excerpts discussing how concurrency is wired in wasm-bindgen-rayon and the role of SharedArrayBuffer/Web Workers provide additional context about compatibility and potential pitfalls, supporting the notion that shipping a strictly multithreaded build without graceful fallback is an anti-pattern. Overall, the most relevant content highlights the dependence on browser/thread support and the risk of degraded UX when that support is absent, while other excerpts add background on how thread pools and wasm interoperate in this ecosystem.",
      "confidence": "low"
    },
    {
      "field": "parallel_iterator_patterns.2",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts."
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The target pattern involves consuming ownership to enable a parallel computation, which corresponds to the parallel iterator concept in Rayon where ownership and iteration behavior are key decisions. The most directly relevant content shows concrete code where a parallel iterator is used to transform and collect results, illustrating how a parallel iterator is invoked and how ownership can flow through the chain (for example, a function that uses data.into_par_iter() followed by map and collect). The surrounding excerpts reinforce this idea by explaining that Rayon provides a straightforward path to convert sequential iterations into parallel ones via the par_iter APIs, and that importing the appropriate prelude brings in ParallelIterator traits required to access these methods. Other excerpts discuss data-race freedom and the guarantees of parallel execution, which are important context when deciding to use a consuming parallel iterator (to move ownership) versus non-consuming variants (par_iter or par_iter_mut). Taken together, these excerpts support the notion that into_par_iter-like patterns rely on the ownership semantics and the availability of the parallel iteration trait methods, while also highlighting that using consuming patterns when ownership transfer is unnecessary would be an anti-pattern and that non-consuming alternatives exist. The excerpts that discuss the prelude and the general concept of converting to parallel iterators are most directly relevant, followed by those that illustrate concrete parallel-iterator usage and ownership semantics, with data-race guarantees providing supportive context.",
      "confidence": "medium"
    },
    {
      "field": "testing_and_reproducibility_patterns.3",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Iterator items are pulled by \\`next()\\` one at a time, synchronized from each thread that is\n22 /// ready for work, so this may become a bottleneck if the serial iterator can't keep up with the\n23 /// para"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a pattern where a parallel iterator collects results in a way that preserves the original sequence order, followed by assertions on that ordered collection. An excerpt explicitly stating that the resulting iterator is not guaranteed to keep the original order directly challenges the assumption that collect() will preserve order in this parallel context. Another excerpt explains how items are pulled and may be scheduled across threads, which relates to potential non-determinism and ordering. Together, these excerpts are most relevant because they address the core question of whether order is preserved when collecting from a parallel iterator, which underpins the validity of the given code template and its test assertions. Other excerpts touching on thread pools or documentation of parallel concepts provide supportive context but do not directly address ordering guarantees, making them less relevant to this specific finegrained field value.",
      "confidence": "low"
    },
    {
      "field": "parallel_sorting_patterns.2",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The most relevant material directly describes sorting a parallel collection using a key extraction function, which is central to understanding when a cached-key approach would be advantageous: the excerpt notes that the sort is performed in parallel with a key extraction step, implying a potential performance optimization when that key extraction is expensive. This aligns with the field values focus on expensive key extractions and the idea of computing the key once to avoid repeated work across comparisons. Related content discusses stability concerns in parallel sorts and whether the sort preserves the order of equal elements, which informs why a cached-key approach might be preferred (to ensure consistent behavior and minimize recomputation) and highlights anti-patterns that can arise if the key is recomputed, leading to wasted work. Additional excerpts cover the general par_sort family and mention that certain variants are stable or unstable, providing context for when an alternate approach (such as a cached-key pattern) might be chosen over a nave key-per-compare approach. Taken together, these excerpts support understanding of the patterns motivation (expensive key computations, cache-and-sort workflow), its practical implications (stability and performance trade-offs), and the existence of related anti-patterns (recomputing expensive keys).",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.0",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The targeted idiom is a map() in parallel followed by a sum() reduction. The most directly relevant material explains that there is a parallel iterator pattern for summing items, including how sum behaves, its determinism considerations, and how it relates to related reduction patterns. The passages describing the sum operation on a ParallelIterator, and noting how the operation may be non-deterministic if the underlying addition is not strictly associative (as with floating-point types), directly support the idea that map(...).sum() is a concise, efficient idiomatic pattern for numeric aggregation in parallel, while also highlighting caveats and potential anti-patterns. Supporting content about reduce_with, try_reduce, and fold_with provide broader context on alternatives (when you need more control over the accumulation or error handling), which aligns with the alternate patterns part of the field value. Explicit notes that the order of reduction isnt specified for generic sums reinforce the need to consider precision and determinism when using this pattern, which matches the anti-pattern warning for floating-point sums. In short, the excerpts collectively substantiate that map(...).sum() is a concise and efficient parallel pattern, but with important caveats and useful alternatives for more complex reductions.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.3",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>"
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        }
      ],
      "reasoning": "The most relevant content demonstrates the core mechanisms to configure Rayons parallel execution environment: ThreadPoolBuilder is used to create or configure a thread pool, ThreadPool represents user-created pools, and the Configuration struct encapsulates pool settings. These excerpts establish how to explicitly control the parallel execution context (e.g., number of threads, pool setup), which is crucial when implementing idiomatic patterns that rely on predictable parallel granularity and performance, such as explicit chunking. The references to max_num_threads and the guidance that ThreadPoolBuilder can configure the global pool provide concrete knobs that influence how chunked, coarse-grained parallel work would execute, impacting efficiency and potential overhead. The excerpts discussing the ThreadPool constructor with a Configuration object show how to instantiate and validate a tuned runtime, which is the practical foundation for applying high-level idioms like explicit chunking in real code. The excerpt describing that ThreadPoolBuilder is used to create a ThreadPool or configure the global pool explicitly ties together the concept of explicit pattern usage with the concrete configuration API in Rayon. Collectively, these sources support understanding of when and how to apply performance-oriented patterns, even though they do not quote the exact par_chunks example.",
      "confidence": "medium"
    },
    {
      "field": "order_and_indexing_patterns.0",
      "citations": [
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "nd\") ,\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. ",
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []"
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Collects the results of the iterator into the specified vector. The vector is always truncated before execution begins. If possible, reusing the vector across ...",
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_last](.position_last) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.\n# [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 3 ), Some ( 3 ));\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 100 ), None );\n```\n"
          ]
        }
      ],
      "reasoning": "The most relevant excerpt directly describes the exact idiom: it defines an Enumerate construct in rayon that returns the current count with the element, and notes that this struct is created by enumerate() on an IndexedParallelIterator. This directly supports the field value's pattern name and code template, showing how to pair items with their indices in a parallel context and how that relates to preserving order when collecting results. Supporting context is provided by related excerpts that discuss IndexedParallelIterator and index-focused operations: these excerpts define what an indexed parallel iterator is, and explain that such iterators support indexing and can be collected, which aligns with the use of enumerate to attach indices and then collect in order. Additional excerpts about operations that locate or express an order-preserving workflow (e.g., position_first, position_last, and the general concept of indexing in parallel iterators) reinforce the idea that indexing patterns in a parallel setting are meaningful for correctness and determinism, and contrast with non-index-aware patterns. The anti-patterns and alternates are also relevant: enumerating an iterator and then relying on side-effects for order is unsafe, and an alternative is manually zipping a range of indices with data, but enumerate is usually clearer and more idiomatic. Overall, the core claim that enumerate on an IndexedParallelIterator yields (index, value) pairs suitable for ordered collection is well-supported by the strongest excerpt, with additional corroboration from the broader IndexedParallelIterator discussions.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.2.code_template",
      "citations": [
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Feature detection"
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        }
      ],
      "reasoning": "The target field value describes a pattern where JavaScript uses a feature-detection check to decide between a multithreaded Wasm build and a single-threaded fallback. It then loads the appropriate Wasm package and, in the multithreaded path, initializes a thread pool with a call such as initThreadPool, before running computation. Excerpts that discuss creating and reusing a pool of workers for multithreaded Rayon-like workloads are highly supportive, illustrating the concrete mechanism of initializing a thread pool and wiring it into the app lifecycle. Excerpts that describe wasm-bindgen-rayon providing the underlying JS glue and worker management corroborate the integration pattern of concurrency in the browser context. Excerpts that mention similar feature-detection usage and the existence of wasm-threaded versus non-threaded builds further corroborate the conditional loading pattern. Finally, an excerpt that frames the broader context of threads and Wasm in the web and mentions adapters for Rayon-based concurrency helps confirm the intended architectural pattern, even if not detailing the exact init call. Taken together, these excerpts align directly with the described code template: detect support, choose multithreaded or single-threaded path, initialize the thread pool in the multithreaded path, and then proceed with computation. The most directly supportive pieces are those explicitly showing the pool initialization and the conditional loading flow, followed by references to the underlying worker-based concurrency model and to the concurrency adapter ecosystem in this space.\n",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.2",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The most directly relevant content describes the fold_with pattern, which applies a folding operation to an initial accumulator and then merges partial accumulators across threads, matching the idea of having a separate, possibly different, accumulator type in a parallel reduction. The description explicitly shows the signature and semantics of folding with an initial value and a separate fold_op, which mirrors the use of a local accumulator in a parallel aggregation as described in the target pattern. The accompanying notes emphasize that the fold accumulator does not need to be Sync, and that this avoids shared-state locking, aligning with the efficiency and anti-pattern considerations of a high-performance parallel histogram-like operation. This supports the code template and usage context of building a HashMap or similar accumulator via per-thread local accumulators and a final reduction step. The next most relevant excerpt describes reduce_with, which is the analogous reduction step that combines per-thread results, clarifying that the reduction pattern can be called with an operator that combines two items, and that Some/None or Ok/Err handling can be involved, which ties into producing a final single result from per-thread accumulators. This supports the anti-pattern idea of avoiding a lock-based shared accumulator and reinforces the recommended alternate pattern of using a higher-level collect or a simpler reduce when appropriate. Additional excerpts cover the basic reduce and fold constructs and their documentation, which contextualizes how these operations interplay in parallel iterators, including examples of sums and how folding and reducing interact. The presence of try_reduce and try_reduce_with variants provides coverage of fallible reductions, which broadens the applicability of the fold-then-reduce idiom to fallible contexts, further supporting a nuanced view of the patterns robustness. The remaining supportive excerpts elaborate on the broader parallel-iterator API (e.g., additional details about fold_with) and reinforce the central concept of composing per-thread local work with a final merge step, which is precisely the essence of the targeted fine-grained field value. ",
      "confidence": "high"
    },
    {
      "field": "divide_and_conquer_patterns.0.usage_context",
      "citations": [
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```\ntrait Joiner {\n    /// True if this is parallel mode, false otherwise. fn is_parallel() -> bool;\n    \n    /// Either calls `rayon::join` or just invokes `oper_a(); oper_b();`.\nfn join<A,R_A,B,R_B>(oper_a: A, oper_b: B) -> (R_A, R_B)\n        where A: FnOnce() -> R_A + Send, B: FnOnce() -> R_B + Send;\n}\n```"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "pub fn join<A, B, RA, RB>(oper_a: A, oper_b: B) -> (RA, RB)\n\nwhere\n    A: FnOnce () -> RA + Send ,\n    B: FnOnce () -> RB + Send ,\n    RA: Send ,\n    RB: Send ,",
            "This example uses join to perform a quick-sort (note this is not a\nparticularly optimized implementation: if you **actually** want to\nsort for real, you should prefer [the `par_sort` method](../rayon/slice/trait.ParallelSliceMut.html.par_sort) offered\nby Rayon). ",
            "       let (lo, hi) = v.split_at_mut(mid);",
            "       let mid = partition(v);"
          ]
        }
      ],
      "reasoning": "The fine-grained field value identifies the idiomatic divide-and-conquer pattern implemented by the rayon::join function. It emphasizes that a problem can be split into two independent subproblems, enabling potential parallelism and dynamic scheduling, which yields high efficiency and low-bug concurrent code due to Rust's borrow-checking and Send requirements. The most directly relevant excerpt describes the join function and its role in providing a parallel-friendly interface that chooses between parallel execution or sequential fallback, including the constraint that closures must be FnOnce and Send, which underpins safe concurrent execution. The accompanying excerpt further clarifies that, unlike a thread spawn, this pattern allows borrowing from local data with compile-time safety checks, reinforcing the low-bug and data-race-free nature of the pattern. Another excerpt provides the concrete function signature for join, listing the requirements on the closures and the return types, which anchors the practical API usage of this idiom. An example excerpt explicitly notes using join to perform a parallelizable operation (e.g., quick-sort) and contrasts it with opt-in parallelism like par_sort, illustrating the real-world application of the idiom. Additional excerpts discuss surrounding primitives like split_at_mut and partition, which relate to dividing data for subproblems but do not define the idiom itself; they provide contextual scaffolding showing how subproblems might be structured around join usage. Taken together, these sources robustly support the claim that rayon::join represents the canonical divide-and-conquer idiom in Rust for parallelizing independent subproblems with low overhead and safe concurrency.",
      "confidence": "high"
    },
    {
      "field": "divide_and_conquer_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```\ntrait Joiner {\n    /// True if this is parallel mode, false otherwise. fn is_parallel() -> bool;\n    \n    /// Either calls `rayon::join` or just invokes `oper_a(); oper_b();`.\nfn join<A,R_A,B,R_B>(oper_a: A, oper_b: B) -> (R_A, R_B)\n        where A: FnOnce() -> R_A + Send, B: FnOnce() -> R_B + Send;\n}\n```"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "pub fn join<A, B, RA, RB>(oper_a: A, oper_b: B) -> (RA, RB)\n\nwhere\n    A: FnOnce () -> RA + Send ,\n    B: FnOnce () -> RB + Send ,\n    RA: Send ,\n    RB: Send ,",
            "This example uses join to perform a quick-sort (note this is not a\nparticularly optimized implementation: if you **actually** want to\nsort for real, you should prefer [the `par_sort` method](../rayon/slice/trait.ParallelSliceMut.html.par_sort) offered\nby Rayon). ",
            "       let (lo, hi) = v.split_at_mut(mid);",
            "       let mid = partition(v);"
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpts establish rayon::join as a concrete primitive for parallel execution in Rust and provide its signature and behavior. One excerpt introduces the join operator in the context of data parallelism and defines the join function signature, explicitly showing its role in combining two operations to run in parallel and return their results. Another excerpt presents the explicit function signature for join, including its generics and Send bounds, which directly aligns with the concept of a parallel divide-and-conquer primitive named rayon::join. A third excerpt explicitly discusses using join to perform a quick-sort example and notes the recommendation to prefer a specialized parallel sort in real code, which demonstrates practical usage and reinforces the identity of rayon::join as the core pattern. Additional excerpts show code material from the rayon join documentation page, including code fragments that define how to split work and instantiate the join operation, providing further concrete context for how the pattern is applied. Finally, a contextual excerpt references the join function as part of the broader discussion of data parallelism in Rust, linking the concept to the surrounding landscape of parallel patterns, with code snippets illustrating typical usage. Collectively, these excerpts build a coherent picture that rayon::join is the central divide-and-conquer parallel primitive being analyzed, with both its signature and usage demonstrated in practical examples.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.2.alternate_patterns",
      "citations": [
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Feature detection"
          ]
        }
      ],
      "reasoning": "The target field value asserts that the main alternative to the observed pattern is to provide a single-threaded build, trading off performance or compatibility. Excerpts that describe enabling Rayon-based concurrency on the Web with Web Workers and the wasm-bindgen-rayon setup illustrate the existence of a multi-threaded approach and its ecosystem, which is directly relevant to understanding why an alternative (single-threaded) might be considered. Excerpts that discuss building demos or the general relevance of threads on WebAssembly provide context for why single-threaded builds could be preferred in some environments. However, none of the excerpts explicitly state the exact alternate as described in the field value. The most supportive content is where concurrency is foregrounded (threads, thread pools, and wasm-bindgen-rayon integration), which underpins the notion that a non-threaded alternative exists and would be used for compatibility or simplicity. Other excerpts discuss detection, integration details, and caveats around threading in WASM, which further contextualize why an alternate (non-threaded) approach would be a valid pattern to consider.",
      "confidence": "low"
    },
    {
      "field": "configuration_and_tuning_patterns.0",
      "citations": [
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); ",
            "Multiple Thread Pools"
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it.",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>"
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ...",
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "Clarify rust rayon nested thread pool worker numbers - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76919721/clarify-rust-rayon-nested-thread-pool-worker-numbers",
          "excerpts": [
            "I have tried to use rayon 's parallel iterators in a nested way. As a global pool would have a fixed number of threads, I tend to create an outer-pool in main.",
            "vec!\n[1, 2, 3, 4].into_par_iter().map(|inner| stress(outer * 10 + inner)).collect(",
            "})"
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "})",
            "})"
          ]
        },
        {
          "title": "GitHub Issue: Performance of par_bridge (#685)",
          "url": "https://github.com/rayon-rs/rayon/issues/685",
          "excerpts": [
            "})"
          ]
        }
      ],
      "reasoning": "The most relevant content directly demonstrates how to configure Rayons thread pool using a ThreadPoolBuilder, including multi-pool scenarios and explicitly setting parameters like the number of threads and stack size. The top excerpt shows a composite example of creating a global thread pool with explicit settings such as num_threads and stack_size, followed by build_global, which aligns with the field values code_template and usage context. The next excerpt reinforces that ThreadPoolBuilder is used to create or configure the global pool and gives a concrete example with a large thread count, which directly supports the patterns core concept. Another excerpt explicitly notes that ThreadPoolBuilder can specify number and names of threads, which matches the fields focus on configuration details. Additional excerpts discuss ThreadPool usage in Rayon and how a builder returns a usable configuration object, which supports understanding of initialization flow. Excerpts discussing environment-variable-based configuration (RAYON_NUM_THREADS) and stack-size considerations provide complementary evidence for the alternate pattern and performance considerations described in the field value. Excerpts about anti-patterns (e.g., calling build_global multiple times) appear in the field value but are only partially supported by surrounding content; they are mentioned as a caution in the field value but are not strongly evidenced as an explicit rule in the excerpts themselves, so they contribute but with lower direct support. Overall, the collected excerpts coherently map to the idea of a ThreadPoolBuilder-based global configuration pattern, including number of threads, stack size, and build_global usage, with supplemental notes on alternatives and cautions.",
      "confidence": "medium"
    },
    {
      "field": "parallel_collection_building_patterns.1",
      "citations": [
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        }
      ],
      "reasoning": "The target field value describes a specific idiomatic parallel-collection pattern: par_extend from the ParallelExtend trait, which extends an existing collection with items from a parallel iterator. The excerpt that discusses extending a hash map with items from a parallel iterator directly supports the existence and purpose of par_extend, including the trait method signature context. The surrounding context in that excerpt confirms its about extending an existing collection via a parallel iterator, which matches the described code template and usage. Additionally, the excerpt that explains how Rayon makes it easy to convert sequential iterators into parallel ones and shows a concrete example with par_iter supports the broader usage context in which par_extend operates, reinforcing that this pattern is the idiomatic, high-throughput alternative to manual locking. Importantly, there is explicit mention of the anti-pattern: manually locking and extending a shared collection from multiple threads, which aligns with the anti-pattern described in the field value. The excerpt also provides an alternative approach: collect into a temporary collection and then extend, which matches the alternate-pattern described. Taken together, these excerpts directly support the par_extend pattern name, its code template usage, its contextual purpose, the anti-pattern, and the suggested alternative, with clear, specific connections to the field value.",
      "confidence": "high"
    },
    {
      "field": "testing_and_reproducibility_patterns.0.code_template",
      "citations": [
        {
          "title": "rayon-core/src/thread_pool/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-core/src/thread_pool/mod.rs",
          "excerpts": [
            "o\n/// keep busy while the `op` completes in its target pool, similar to\n/// calling [`ThreadPool::yield\\_now()`] in a loop. Therefore, it may\n/// potentially schedule other tasks to run on the current thread in the\n/// meantime. For example\n///\n/// ```ignore-wasm\n/// # use rayon\\_core as rayon;\n/// fn main() {\n/// rayon::ThreadPoolBuilder::new().num\\_threads(1).build\\_global().unwrap();\n/// let pool = rayon\\_core::ThreadPoolBuilder::default().build().unwrap();\n/// let do\\_it = || {\n/// print!(\"one \");\n/// pool.install(||{});\n/// print!(\"two \");\n/// };\n/// rayon::join(|| do\\_it(), || do\\_it());\n/// }\n/// ```\n///\n/// Since we configured just one thread in the global pool, one might\n/// expect `do\\_it()` to run sequentially, producing:\n///\n/// ```ascii\n/// one two one two\n/// ```\n///\n/// However each call to `install()` yields implicitly, allowing rayon to\n/// run multiple instances of `do\\_it()` concurrently on the single, global\n/// thread. The following output would be equally valid:",
            "pub fn install(&self, op: OP) -> R\nwhere\nOP: FnOnce() -> R + Send,\nR: Send,\n{\nself.registry.in\\_worker(|\\_, \\_| op())\n",
            "pub fn current\\_num\\_threads(&self) -> usize {\nself.registry.num\\_threads("
          ]
        },
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        }
      ],
      "reasoning": "The code template in question shows creating a dedicated pool with a fixed number of threads via a builder (ThreadPoolBuilder), and then running code inside that pool using the install method. One excerpt provides a concrete example where a pool is created and installed, including a pattern where pool.install is used to run a closure, which is central to the templates approach of isolating work within a specific pool. It also demonstrates a typical usage of ThreadPoolBuilder and the install call, aligning exactly with the idea of a test that uses a dedicated pool. The same excerpt also shows how a closure inside pool.install can perform parallel work, reinforcing the templates goal of running Rayon operations within that dedicated pool. Another excerpt defines the install API, showing the signature and constraints, which directly supports the code templates mechanism of executing a closure inside the pool. While additional excerpts mention related threading utilities (e.g., current_num_threads) and broader constructs (scope), they are less directly tied to the exact code template pattern of creating a pool with a fixed number of threads and using install to execute code within it. Taken together, these excerpts provide clear evidence for both the pool construction pattern and the install usage that together form the requested idiomatic code template for an isolated parallel test.",
      "confidence": "high"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.0.usage_context",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        }
      ],
      "reasoning": "The target claim describes a pattern that is ideal for embarrassingly parallel numeric kernels where work for each element is independent, highlighting high efficiency when using Rayon for dividing work across CPU cores with minimal synchronization. The most directly supportive content notes a collection of benchmarks for Rayon, including Parallel mergesort, which is a textbook data-parallel pattern emblematic of embarrassingly parallel workloads. This demonstrates that Rayon is used to express parallelism across independent tasks, aligning with the described high-efficiency pattern. The other excerpt shows a main routine that dispatches among several benchmarks, illustrating practical organization of parallel tasks and workload selection, which reinforces the context in which data-parallel patterns (like independent element processing) can be deployed in Rayon. Together, these excerpts support the idea that Rayon enables high-efficiency, embarrassingly parallel patterns by providing parallel benchmarks and workload orchestration that leverage independent work across cores.",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.1.code_template",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The target code template demonstrates importing the Rayon prelude and applying a parallel iterator to mutate a slice in place, using a pattern like data.par_iter_mut().for_each(...) to update each element. Excerpts that show importing the Rayon prelude (use rayon::prelude::*;) establish the necessary context for bringing ParallelIterator traits into scope, which is a foundational step for using par_iter, par_iter_mut, and for_each. Excerpts that illustrate converting a sequential iterator to a parallel one by switching iter() to par_iter() (and similarly showing par_iter() usage) directly support the idea of replacing standard iteration with a parallel variant. A concrete example that uses par_iter (and optionally par_iter_mut) plus an operation inside for_each or a map-like chain demonstrates the exact idiom of applying a parallel operation to each element, which aligns with the provided code template that mutates elements in place. Additional excerpts discussing data-race freedom and the guarantees of Rayon provide essential context for why this idiom is considered idiomatic and safe in this ecosystem, reinforcing the rationale behind choosing par_iter_mut().for_each for in-place updates. Collectively, the most relevant passages directly illustrate the prelude import, the par_iter/par_iter_mut usage, and the for_each-like operation that updates each element, matching the structure and intent of the target code template. Less direct excerpts offer supportive context about data-race guarantees and the broader Rayon design, but do not showcase the exact code pattern as clearly as the top excerpts.",
      "confidence": "medium"
    },
    {
      "field": "testing_and_reproducibility_patterns.0.usage_context",
      "citations": [
        {
          "title": "rayon-core/src/thread_pool/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-core/src/thread_pool/mod.rs",
          "excerpts": [
            "o\n/// keep busy while the `op` completes in its target pool, similar to\n/// calling [`ThreadPool::yield\\_now()`] in a loop. Therefore, it may\n/// potentially schedule other tasks to run on the current thread in the\n/// meantime. For example\n///\n/// ```ignore-wasm\n/// # use rayon\\_core as rayon;\n/// fn main() {\n/// rayon::ThreadPoolBuilder::new().num\\_threads(1).build\\_global().unwrap();\n/// let pool = rayon\\_core::ThreadPoolBuilder::default().build().unwrap();\n/// let do\\_it = || {\n/// print!(\"one \");\n/// pool.install(||{});\n/// print!(\"two \");\n/// };\n/// rayon::join(|| do\\_it(), || do\\_it());\n/// }\n/// ```\n///\n/// Since we configured just one thread in the global pool, one might\n/// expect `do\\_it()` to run sequentially, producing:\n///\n/// ```ascii\n/// one two one two\n/// ```\n///\n/// However each call to `install()` yields implicitly, allowing rayon to\n/// run multiple instances of `do\\_it()` concurrently on the single, global\n/// thread. The following output would be equally valid:",
            "pub fn install(&self, op: OP) -> R\nwhere\nOP: FnOnce() -> R + Send,\nR: Send,\n{\nself.registry.in\\_worker(|\\_, \\_| op())\n",
            "pub fn current\\_num\\_threads(&self) -> usize {\nself.registry.num\\_threads("
          ]
        },
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        }
      ],
      "reasoning": "The finegrained field value discusses an idiom for writing reliable and reproducible tests in Rayon-based code, emphasizing isolation, a known number of threads, and avoidance of interference from concurrently running tests (e.g., in CI). The most relevant excerpts are those that illustrate explicit control over the thread pool and how tasks are scheduled in a way that can influence determinism and isolation. The first excerpt directly demonstrates configuring the global thread pool with a fixed number of threads (num_threads(1)), then building a pool and running code with install/join semantics to show how concurrency can be exercised within a controlled single-threaded environment. This aligns with the idea of ensuring a known thread count to achieve reproducible test behavior and reduced flakiness. The second excerpt provides a function that exposes the current number of threads, which is useful for validating and enforcing the isolation and determinism claimed in the fine-grained field value. The third excerpt documents a mechanism (scope) that allows spawning multiple tasks within a controlled scope and waiting for their completion, which is relevant to understanding how tasks may be structured to preserve isolation and determinism during tests. The fourth excerpt describes the broader fork-join style and its impact on performance and flexibility but still relates to how tasks are managed and synchronized, which can influence reproducibility in tests when designing test patterns around Rayon usage.",
      "confidence": "medium"
    },
    {
      "field": "divide_and_conquer_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```\ntrait Joiner {\n    /// True if this is parallel mode, false otherwise. fn is_parallel() -> bool;\n    \n    /// Either calls `rayon::join` or just invokes `oper_a(); oper_b();`.\nfn join<A,R_A,B,R_B>(oper_a: A, oper_b: B) -> (R_A, R_B)\n        where A: FnOnce() -> R_A + Send, B: FnOnce() -> R_B + Send;\n}\n```"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "pub fn join<A, B, RA, RB>(oper_a: A, oper_b: B) -> (RA, RB)\n\nwhere\n    A: FnOnce () -> RA + Send ,\n    B: FnOnce () -> RB + Send ,\n    RA: Send ,\n    RB: Send ,",
            "This example uses join to perform a quick-sort (note this is not a\nparticularly optimized implementation: if you **actually** want to\nsort for real, you should prefer [the `par_sort` method](../rayon/slice/trait.ParallelSliceMut.html.par_sort) offered\nby Rayon). ",
            "       let (lo, hi) = v.split_at_mut(mid);",
            "       let mid = partition(v);"
          ]
        }
      ],
      "reasoning": "The field value describes several alternate or higher-level patterns that arise in Rayon-based divide-and-conquer: a flexible scope for spawning multiple tasks, a higher-level parallel iterator built on top of join (par_iter), practical fallbacks like using a sequential algorithm for tiny subproblems (slice::sort_unstable), and a macro-based solution for many-way joins (join_many!). Excerpt content that discusses the join API and its role in enabling parallel execution directly supports understanding how to compose these patterns around a core primitive, since join is the fundamental building block for forming a parallel computation. The mention of a quick-sort example that explicitly notes the preferred par_sort method illustrates how a higher-level idiom leverages primitives like join/building blocks to achieve parallelism, which helps connect the idea that par_iter and other abstractions sit atop join. The more detailed API description of join, including constraints on FnOnce, Send, and the return types, reinforces how the join primitive is used to compose parallel work and implies how higher-level patterns (par_iter, scope, and alternate strategies) fit around it. The remaining excerpts provide practical code context around split/join concepts, further grounding the idea that these higher-level patterns arise from how join operates, even though they dont spell out each alternate pattern explicitly. Overall, these excerpts collectively support the notion of alternate patterns in Rayon by illustrating the primitive (join) and the surrounding higher-level constructs and practical fallbacks, though explicit statements about scope, par_iter, sort_unstable fallback, and join_many are not individually present in a single excerpt.\n",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The fine-grained field value asserts a specific guidance on when to use sequential iteration versus parallel constructs (and mentions using a batching parallel pattern via par_chunks) as an alternate pattern. The excerpts collectively show several related ideas: switching from sequential to parallel iteration via par_iter is a straightforward pattern to achieve parallelism and maintain correctness, and importing the Rayon prelude makes the necessary ParallelIterator traits readily available. The excerpts also emphasize two key supporting themes: (a) parallel iterators can preserve the same results as sequential code once the code compiles, providing a safe, predictable parallelization approach, and (b) Rayon is lightweight and designed to minimize data races, which underpins when and why one would choose a parallel pattern over a sequential one. Taken together, these excerpts support the general concept of using parallel iteration as the primary idiomatic pattern and using the prelude to enable it, and they provide context for when a parallel approach is beneficial. However, there is no explicit mention of a batching pattern like par_chunks within these excerpts, so the specific claimed use of par_chunks as an alternate pattern is not directly supported by the provided text. The strongest support is for the broader claim that converting sequential iterators to parallel (via par_iter) is a common, idiomatic, low-bug approach, and the prelude is the recommended way to enable those parallel APIs. The data-race freedom and deterministic behavior when code compiles further reinforce when such a parallel pattern is appropriate.",
      "confidence": "medium"
    },
    {
      "field": "order_and_indexing_patterns.1",
      "citations": [
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```"
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "<Self>\n\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.\nThis means that if two threads are used there will be **no** speedup **at\nall** . `by_exponential_blocks` on the other hand will start with the leftmost range from 0\nto `p` (threads number), continue with p to 3p, the 3p to 7p\n\nEach subrange is treated in parallel, while all subranges are treated sequentially. We therefore ensure a logarithmic number of blocks (and overhead) while guaranteeing\nwe stop at the first block containing the searched data. [Source](../../src/rayon/iter/mod.rs.html)\n",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice."
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on a comparative pattern: deterministic first-match (find_first/position_first) versus non-deterministic any-match (find_any/position_any). The most directly relevant content states that the sequentially first matching item is sought and its index is returned, and that once a match is found in the first/guaranteed-first pattern, attempts to the right are stopped, while non-deterministic any-match may not be the first and processing may stop once a match is found. This provides the core architectural decision: determinism and ordering vs early exit and performance trade-offs. Additional excerpts explicitly discuss that for the non-deterministic approach, you may use any matching element and that early exit is possible, which aligns with the field values comparison. A facilitator pattern is described where an adaptor can bias the search toward the beginning to improve performance, which complements the first-match pattern by optimizing for the determinate path. The combination of these excerpts supports the field values claim about the trade-offs and recommended usage contexts between find_first/position_first (deterministic, first element) and find_any/position_any (non-deterministic, any matching element). While related content discusses last-position variations, those are supplementary context and do not directly contradict the primary focus on first vs any semantics.",
      "confidence": "high"
    },
    {
      "field": "divide_and_conquer_patterns.0.code_template",
      "citations": [
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "This example uses join to perform a quick-sort (note this is not a\nparticularly optimized implementation: if you **actually** want to\nsort for real, you should prefer [the `par_sort` method](../rayon/slice/trait.ParallelSliceMut.html.par_sort) offered\nby Rayon). ",
            "       let (lo, hi) = v.split_at_mut(mid);",
            "       let mid = partition(v);",
            "pub fn join<A, B, RA, RB>(oper_a: A, oper_b: B) -> (RA, RB)\n\nwhere\n    A: FnOnce () -> RA + Send ,\n    B: FnOnce () -> RB + Send ,\n    RA: Send ,\n    RB: Send ,"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "```\ntrait Joiner {\n    /// True if this is parallel mode, false otherwise. fn is_parallel() -> bool;\n    \n    /// Either calls `rayon::join` or just invokes `oper_a(); oper_b();`.\nfn join<A,R_A,B,R_B>(oper_a: A, oper_b: B) -> (R_A, R_B)\n        where A: FnOnce() -> R_A + Send, B: FnOnce() -> R_B + Send;\n}\n```"
          ]
        }
      ],
      "reasoning": "The fine-grained field value depicts a divide-and-conquer sort implemented in Rust with Rayon: a quick_sort function that branches on a SEQUENTIAL_THRESHOLD, partitions the slice, splits it into two halves, and then recursively sorts both halves in parallel using rayon::join. The excerpt describing a quick-sort example explicitly notes a non-optimized quick-sort that uses a partition function and then splits the vector, followed by a parallel invocation of two recursive quick_sort calls on the resulting halves. This matches the core control flow and structure of the requested code_template: a threshold-based switch to sequential sort for small slices, a partition step, a split of the mutable slice, and a parallel join to process the two halves. Additional excerpts mention the partition function and how the join operation is defined and used, which aligns with the templates reliance on a join mechanism to execute two recursive branches in parallel. Specifically, the excerpts provide details such as using a partition(v) to determine a pivot index, splitting with v.split_at_mut(mid) to obtain two mutable subslices, and invoking rayon::join to run quick_sort on both halves. They also show the signature style of the join operation (oper_a, oper_b or FnOnce-based closures) and the Send/partial order constraints, which underpin the safe parallel execution in the template. Taken together, these excerpts corroborate the essential elements of the divide-and-conquer pattern: a threshold-based decision, a partition step, a split into lo/hi parts, and a parallel recursive sort on each part facilitated by rayon::join.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.2.usage_context",
      "citations": [
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]"
          ]
        }
      ],
      "reasoning": "The field value describes a pattern to ensure robust production-grade behavior across a range of environments by maintaining two builds of the Wasm module and using JavaScript feature detection to load the appropriate one. The most relevant excerpt explicitly states that wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly, mentioning the use of Web Workers and SharedArrayBuffer support, which directly relates to environmental capabilities and constraints. It reveals concerns about environment support (Web Workers, SharedArrayBuffer) that would motivate a dual-build or feature-detection strategy to avoid failures in older environments. A closely related excerpt notes that WebAssembly threads use Web Workers and that the necessary JS code for Workers is provided internally, highlighting cross-environment considerations and compatibility with different bundlers, which aligns with the gist of handling varying environments. Other excerpts discuss thread pools and examples but do not address the explicit two-build pattern or feature-detection strategy, making them less directly supportive of the stated usage context. Overall, the two most relevant excerpts provide direct insight into environment-related constraints and cross-environment support for wasm-threaded concurrency, which underpin the proposed robust pattern in the field value.",
      "confidence": "medium"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.2.demo_name",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n"
          ]
        }
      ],
      "reasoning": "The target field value is the descriptive name of a demo, specifically the matmul benchmark described as Parallel Matrix Multiplication. Among the excerpts, only the entry describing the matmul benchmark includes the exact phrase that matches this description in the benchmark listing. This shows a direct alignment between the field value and the content of the excerpt, supporting the idea that the demonstrated_pipelines_from_rayon_demo.2.demo_name refers to the matmul demo with its parallel matrix multiplication description. Other excerpts mention matmul in code fragments or function definitions without providing the demo naming or its descriptive label, which makes them less relevant to the exact field value in question.",
      "confidence": "high"
    },
    {
      "field": "parallel_iterator_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes switching from a standard sequential mutable iteration to a parallel or batched approach, such as using a parallel iterator variant for large workloads or a batched parallel pattern for efficiency. Several excerpts directly discuss converting a sequential workflow into a parallel one by switching to parallel iterators, which aligns with the notion of an alternate pattern to sequential mutating patterns. One excerpt explicitly says that you can convert a typical sequential iteration into parallel execution by changing a call from iter() to par_iter(), and Rayon handles the rest, illustrating the core idea of an idiomatic alternate pattern that reduces boilerplate and error-prone parallelism wiring. Another excerpt emphasizes that Rayon is a data-parallelism library designed to make it easy to transform sequential computations into parallel ones, which supports the concept of alternate parallel patterns as a general approach. Additional excerpts discuss bringing the necessary ParallelIterator traits into scope via the Rayon prelude, which is a practical detail of adopting parallel patterns and their ergonomics. There is also content highlighting that Rayon's APIs guarantee data-race freedom, which is a key consideration when choosing parallel or batched patterns as safe alternates to naive sequential mutations. While none of the excerpts explicitly name iter_mut or par_chunks_mut, the presence of guidance on converting to parallel iterators, the role of preludes for enabling those patterns, and the safety guarantees all map to the broader idea of selected alternate idiomatic patterns for parallel processing in Rust. The most directly relevant elementsthe instruction to simply convert to a parallel iterator to achieve parallelism and the emphasis on data-parallelism as a straightforward patternsupport the general notion of adopting alternate parallel patterns over sequential mutations in Rust.",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.0.code_template",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel..."
          ]
        }
      ],
      "reasoning": "The field value is a concrete Rust code template demonstrating converting a sequential iter into a parallel one by using a parallel iterator and a map operation to compute sums. The most directly relevant content is the exact snippet that shows importing the rayon prelude and the specific transformation: 'use rayon :: prelude :: * ;' followed by 'input.par_iter()' and 'map(|&i| i * i)' then 'sum()'. This directly supports the notion of a parallel iterator pattern using the rayon prelude and the par_iter-based transformation. Additional excerpts reinforce this pattern by describing how to bring the parallel iterator traits into scope with the rayon prelude and by explaining that Rayon makes it easy to convert sequential computations to parallel and guarantees data-race freedom. These excerpts corroborate the context and usage pattern shown in the code template, such as enabling parallel iterators via the prelude and the general idea that converting .iter() to .par_iter() is standard practice for achieving parallel execution. Taken together, these excerpts establish that the code template is a canonical example of the parallel iterator idiom in Rayon and show how the surrounding imports and concepts enable its use. The direct snippet uniquely demonstrates the exact template, while the surrounding excerpts provide necessary context for its correct application (prelude import, turning sequential iteration into parallel, and data-race safety guarantees).",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.2.pattern_name",
      "citations": [
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Feature detection"
          ]
        }
      ],
      "reasoning": "The field value signals a platform-specific pattern name for WASM-related compatibility, suggesting a strategy that perhaps falls back to a sequential path for compatibility in certain environments. The most relevant excerpts are those that describe WASM concurrency patterns and how Rayon or related tooling enable or manage concurrency on the Web. One excerpt explains that wasm-bindgen-rayon is an adapter to enable Rayon-based concurrency on the Web using Web Workers and SharedArrayBuffer support, which directly ties to a WASM-specific concurrency pattern in the browser environment. Another excerpt describes a WASM example involving threads and a parallel computation, which shows concrete WASM threading patterns and the interplay with JavaScript and thread pools. Additional excerpts discuss initializing a thread pool and the general mechanism of using workers for multithreaded operations in Rayon on WASM, which are foundational to any platform-specific concurrency strategy and could conceptually relate to how aSequential fallback would be orchestrated for compatibility. A broader excerpt notes that WebAssembly threads use Web Workers and that certain tooling provides the required JS code for those workers, further tying into platform-specific concurrency handling. Finally, one excerpt discusses idioms and caveats around WASM-based examples, highlighting the complexities of managing threads in this environment. Although these excerpts collectively illuminate WASM-centric concurrency patterns, none explicitly confirm a pattern named Sequential Fallback for Compatibility. Their evidence supports the general context of platform-specific concurrency approaches in WASM rather than this exact named pattern. ",
      "confidence": "low"
    },
    {
      "field": "parallel_iterator_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n"
          ]
        }
      ],
      "reasoning": "The targeted field value is the explicit pattern par_iter() used in Rust with Rayon to convert a sequential iteration into a parallel one. The most relevant excerpt directly demonstrates this pattern: it shows a code snippet where a sequential operation like input.par_iter() is transformed to a parallel version by calling par_iter() and then using map and sum. This directly corroborates the field value as the concrete idiom for parallel iteration provided by Rayon. The second highly relevant excerpt describes the general practice of turning foo.iter() into foo.par_iter() and states that Rayon can do the rest, which directly aligns with the specified pattern name and its usage in practice. Together, these excerpts provide direct, explicit evidence of the par_iter() idiom and how it is intended to be used. Excerpts that discuss the prelude, data-race guarantees, or higher-level descriptions of Rayon s parallelism provide supportive context but do not directly show the exact idiomatic pattern name, so they are less relevant to the specific field value.",
      "confidence": "high"
    },
    {
      "field": "parallel_iterator_patterns.1.usage_context",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The field value describes a parallel iterator pattern specifically used for mutating elements in a collection in parallel, akin to a parallel mutable iteration, and asserts that this approach is highly efficient, with safety enforced by the borrow checker to prevent data races. The most directly relevant excerpt demonstrates a concrete example of transforming a sequential iteration into a parallel one using a parallel iterator, illustrating the core pattern of applying a parallel map over input to perform computations (even though the exact in-place mutation isnt shown, the pattern of parallel iteration and potential for element-wise updates is demonstrated). This supports the notion that this kind of parallel iteration can be used to apply per-element operations in parallel and is commonly used via par_iter.\n\nAdditionally, excerpts that emphasize Rayons data-race freedom and the safety guarantees of its APIs provide evidence for the claimed low-bug design philosophy when using parallel iterators. These excerpts describe that if code compiles, it typically behaves the same as before and that data-race freedom is guaranteed in parallel iterators, which aligns with the safety claim in the field value.\n\nOther excerpts introduce the idea of bringing parallel iterator traits into scope with the prelude and general descriptions of Rayon as a data-parallelism library, which contextualize the usage pattern but are less about the specific in-place mutation scenario. They still reinforce that the pattern relies on a safe parallel API and that the transformation from sequential to parallel code is a common idiom within Rayons ecosystem.\n",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.0.usage_context",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The target field describes the most common Rayon pattern as the direct parallel equivalent of the standard iterator, namely using parallel immutable iteration via par_iter to process read-only data with automatic work-stealing and safety guarantees. Excerpt 0 directly shows transforming a standard iterator to a parallel form with par_iter and performing a map and sum, which is a concrete instantiation of the pattern. Excerpt 1 explicitly states that converting sequential iterators to parallel ones is typically done by changing foo.iter() to foo.par_iter(), with Rayon handling the rest, which precisely articulates the usage pattern. Excerpt 2 reinforces the need to bring in the parallel-iterator capabilities via the Rayon prelude (use rayon::prelude::*), which is the idiomatic way to enable the pattern in modules. Excerpt 3 further emphasizes that the Rayon prelude imports the ParallelIterator traits, enabling easy access to the necessary methods, aligning with the patterns implementation details. Excerpt 4 describes Rayon as a data-parallelism library designed to convert sequential computations into parallel ones and to define general methods for parallel iterators, which provides the conceptual foundation for why this pattern is common and effective. Excerpts 5 reiterate the importance of the prelude and trait availability in enabling the pattern. Excerpts 6, 7, and 8 discuss data-race freedom and safety guarantees that come with Rayons parallel iteration constructs, supporting the claim that this usage pattern leads to safer concurrent execution once the code compiles. Taken together, these excerpts map the concrete usage of par_iter as the core pattern, the idiomatic enablement via the prelude, and the safety guarantees that make this the preferred approach for read-only data processing in parallel.",
      "confidence": "high"
    },
    {
      "field": "parallel_iterator_patterns.1.pattern_name",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The most directly relevant content concerns how to enable and use parallel iterators in Rayon, which is semantically closest to the target pattern par_iter_mut(). The first excerpt demonstrates converting a sequential computation to a parallel one by switching to a parallel iterator method, which is a foundational idea behind mutating-parallel patterns. The second excerpt reinforces the idea that transforming a regular iterator into a parallel one is a common, simple operation, which is highly aligned with the general concept of mutable parallel iteration. The third excerpt explains how bringing the appropriate traits into scope via the Rayon prelude is essential to access parallel iterator APIs, which is a prerequisite for any mutating or non-mutating parallel pattern. The remaining excerpts expand on the guarantees and behavior of Rayons parallel iterators (e.g., data-race freedom) and broader documentation about Rayon as a data-parallelism library, which provide important contextual constraints and expectations when reasoning about any par_iter_mut() usage, including safety and correctness considerations. Although none of the excerpts explicitly show par_iter_mut(), they collectively establish the operational semantics, prerequisites (traits in scope), and safety guarantees around parallel iterators that would govern how a par_iter_mut() pattern would behave in Rust. When selecting content to support the finegrained field value, the direct discussions of par_iter-like usage and the mechanics of enabling parallel iterators (via foo.par_iter()) are the strongest anchors; discussions that focus on the broader behavior of parallel iterators and data-race guarantees supply necessary safety context for evaluating a mutable parallel pattern.",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        }
      ],
      "reasoning": "The field value discusses inefficiency of par_iter on tiny workloads due to overhead, and mentions anti-patterns related to dependencies or aliasing between elements mutated in parallel, as well as misuse for I/O-bound work. Several excerpts directly describe how to turn sequential code into parallel code using par_iter, which provides the operational context for when the idiom is used or avoided. For example, an excerpt shows a simple pattern to switch to parallel iteration by replacing a sequential iterator with par_iter and letting the Rayon framework handle the rest, which is the explicit mechanism that could lead to overhead if used inappropriately. Another excerpt emphasizes bringing the parallel iterator traits into scope via the prelude, illustrating typical usage patterns that readers might treat as defaults, which could be misapplied in suboptimal workloads. Additional excerpts describe Rayon as a data-parallelism library that makes it easy to convert sequential computations into parallel ones and guarantees data-race freedom; while these are positive attributes, they set the stage for potential anti-patterns if misapplied (e.g., assuming parallel always yields gains or neglecting workload characteristics). Finally, excerpts that discuss data-race freedom and the absence of some parallel bugs help contextualize the limits of safety guarantees and where anti-patterns could emerge if one relies on parallelism for I/O-bounded tasks or unnecessary concurrency. Taken together, these excerpts are most relevant to the field value insofar as they outline the practical usage patterns around par_iter and the caveats that could constitute anti-patterns, even if they do not explicitly label every anti-pattern. The content most tightly aligned with the field value is the direct guidance on turning to par_iter in simple usage (which risks overhead in small workloads) and the emphasis on proper scope of traits (prelude) and safety guarantees, all of which underpin anti-pattern risk when applied without regard to workload characteristics.",
      "confidence": "low"
    },
    {
      "field": "testing_and_reproducibility_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "rayon-core/src/thread_pool/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-core/src/thread_pool/mod.rs",
          "excerpts": [
            "o\n/// keep busy while the `op` completes in its target pool, similar to\n/// calling [`ThreadPool::yield\\_now()`] in a loop. Therefore, it may\n/// potentially schedule other tasks to run on the current thread in the\n/// meantime. For example\n///\n/// ```ignore-wasm\n/// # use rayon\\_core as rayon;\n/// fn main() {\n/// rayon::ThreadPoolBuilder::new().num\\_threads(1).build\\_global().unwrap();\n/// let pool = rayon\\_core::ThreadPoolBuilder::default().build().unwrap();\n/// let do\\_it = || {\n/// print!(\"one \");\n/// pool.install(||{});\n/// print!(\"two \");\n/// };\n/// rayon::join(|| do\\_it(), || do\\_it());\n/// }\n/// ```\n///\n/// Since we configured just one thread in the global pool, one might\n/// expect `do\\_it()` to run sequentially, producing:\n///\n/// ```ascii\n/// one two one two\n/// ```\n///\n/// However each call to `install()` yields implicitly, allowing rayon to\n/// run multiple instances of `do\\_it()` concurrently on the single, global\n/// thread. The following output would be equally valid:",
            "pub fn install(&self, op: OP) -> R\nwhere\nOP: FnOnce() -> R + Send,\nR: Send,\n{\nself.registry.in\\_worker(|\\_, \\_| op())\n",
            "pub fn current\\_num\\_threads(&self) -> usize {\nself.registry.num\\_threads("
          ]
        },
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        }
      ],
      "reasoning": "The most relevant material directly discusses a global thread pool and how tasks interact with it. One excerpt shows constructing a global ThreadPool and using it to execute work across threads, including a scenario where a single-threaded pool is configured yet multiple tasks are run concurrently via install. This highlights how a global/shared pool can influence task execution and timing, which is precisely the kind of shared-state behavior that makes tests prone to timing variability and flaky outcomes when tests depend on ambient pools. Another excerpt explicitly exposes operations around the global pool, including building and using a global pool and invoking operations that can schedule work concurrently. This further underscores the risk that tests relying on a pre-existing or shared pool face resource contention and non-deterministic timing due to global state. A third excerpt discusses querying the number of threads and interacting with a pool, which reiterates that the pools configuration and state (such as the number of threads) is a shared resource that can vary across test runs and environments, contributing to unpredictability in tests if relied upon unconditionally. A fourth excerpt describes a flexible scope construct for spawning tasks and notes the performance price and heap-allocation costs associated with that flexibility; while this does not directly mention tests or an anti-pattern, it elaborates on concurrency mechanisms and their cost, which can compound the difficulties of tests that depend on a global pool, reinforcing why relying on ambient pools is risky in testing contexts.",
      "confidence": "medium"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.0.demo_name",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n",
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n"
          ]
        }
      ],
      "reasoning": "The field value refers to an N-body Simulation. The second excerpt shows the dispatch logic for the Rayon demo where, among the benchmarks, there is a dedicated branch for the 'nbody' bench. This establishes a concrete linkage between the code that names the benchmark and the N-body simulation task. The first excerpt explicitly lists benchmarks, including 'nbody: A physics simulation of multiple bodies attracting and repelling one another,' which directly describes the N-body simulation concept and its purpose within the benchmark suite. Together, these two excerpts connect the field value to both the code-level handling of an 'nbody' benchmark and the descriptive label provided in the benchmark catalog, confirming that the N-body Simulation is indeed part of the demonstrated Rayon demo suite.",
      "confidence": "high"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.0.illustrated_pattern",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        }
      ],
      "reasoning": "The finegrained value describes a pattern of toggling between sequential and parallel execution for an embarrassingly parallel numeric kernel. The excerpts describe a Rayon demo suite focused on benchmarks that explicitly exercise parallel computations (e.g., parallel matrix multiplication, parallel mergesort, and other benchmarks) and how to run these benchmarks. This aligns with the notion of exploring when and how to run code in parallel versus sequentially within the same workload, as the excerpts enumerate benchmarks and a dispatch mechanism for running different parallelizable tasks. Although the excerpts do not verbatim state a toggle mechanism between sequential and parallel modes, they demonstrate a context in which the same kernel or set of tasks can be executed in parallel to measure performance, which is the core idea behind toggling between sequential and parallel execution in an embarrassingly parallel setting. The presence of a suite of parallel benchmarks and a main entry that selects among different parallelizable tasks provides direct contextual support for understanding patterns around switching modes of execution in this domain.",
      "confidence": "medium"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.2.anti_patterns_avoided",
      "citations": [
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "if dest.len() <= LINEAR_CHUNK {",
            "dest.copy_from_slice(src);"
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a pattern where constants like MULT_CHUNK and LINEAR_CHUNK establish a subproblem size threshold, below which the algorithm uses a sequential base case to prevent the overhead of parallelization on tiny blocks. The most directly relevant excerpt shows a conditional branch that checks if the destination length is less than or equal to LINEAR_CHUNK and, in that base case, copies data with a simple, sequential operation. This provides concrete evidence of the threshold mechanism and the base-case behavior intended to avoid the anti-pattern of parallelizing very small tasks. The accompanying snippet confirms the intended action in the base case (copy_from_slice on a small input), which reinforces the idea that small subproblems are not run in parallel and are handled sequentially. Together, these elements demonstrate the guardrail concept described in the fine-grained field value. The other excerpts illustrate parallel constructs (joins and par_iter usage) but do not themselves demonstrate the specific threshold-based guardrail, so they are less directly supportive.",
      "confidence": "high"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.0.anti_patterns_avoided",
      "citations": [
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on the idea that the N-body workload is sufficiently computationally intensive to justify parallel execution and to avoid the anti-pattern of parallelizing tiny, memory-bound kernels where setup costs dominate. The excerpts explicitly identify N-body as one of the benchmarks in the Rayon demo, which signals that N-body is treated as a representative, compute-heavy workload within the Rayon ecosystem. This supports the notion that N-body is used to exercise substantial per-item work, aligning with the idea that such tasks are appropriate for parallelization because their computation outweighs overhead. However, the excerpts do not contain explicit statements about anti-patterns being avoided or about overhead considerations; they merely list the benchmark and show how benchmarks are selected. Therefore, the support for the exact anti-pattern claim is indirect and not fully explicit, resulting in partial support for the finegrained field value.",
      "confidence": "low"
    },
    {
      "field": "testing_and_reproducibility_patterns.0.pattern_name",
      "citations": [
        {
          "title": "rayon-core/src/thread_pool/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-core/src/thread_pool/mod.rs",
          "excerpts": [
            "o\n/// keep busy while the `op` completes in its target pool, similar to\n/// calling [`ThreadPool::yield\\_now()`] in a loop. Therefore, it may\n/// potentially schedule other tasks to run on the current thread in the\n/// meantime. For example\n///\n/// ```ignore-wasm\n/// # use rayon\\_core as rayon;\n/// fn main() {\n/// rayon::ThreadPoolBuilder::new().num\\_threads(1).build\\_global().unwrap();\n/// let pool = rayon\\_core::ThreadPoolBuilder::default().build().unwrap();\n/// let do\\_it = || {\n/// print!(\"one \");\n/// pool.install(||{});\n/// print!(\"two \");\n/// };\n/// rayon::join(|| do\\_it(), || do\\_it());\n/// }\n/// ```\n///\n/// Since we configured just one thread in the global pool, one might\n/// expect `do\\_it()` to run sequentially, producing:\n///\n/// ```ascii\n/// one two one two\n/// ```\n///\n/// However each call to `install()` yields implicitly, allowing rayon to\n/// run multiple instances of `do\\_it()` concurrently on the single, global\n/// thread. The following output would be equally valid:",
            "pub fn install(&self, op: OP) -> R\nwhere\nOP: FnOnce() -> R + Send,\nR: Send,\n{\nself.registry.in\\_worker(|\\_, \\_| op())\n",
            "pub fn current\\_num\\_threads(&self) -> usize {\nself.registry.num\\_threads("
          ]
        },
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        }
      ],
      "reasoning": "The target pattern concerns creating or using a customized thread pool on a per-test basis. The most directly relevant material shows a code example where a ThreadPoolBuilder is used to configure the number of threads (num_threads(1)) and then build and use a global pool for running code, which aligns with the idea of tailoring a pool for a specific testing scenario. This demonstrates the mechanism of per-test pool customization and usage within the test flow. The other excerpts discuss the install method, retrieving the current number of threads, and a scope-based pattern for spawning tasks. While these are related to thread pools and task execution, they do not directly demonstrate a per-test customized pool setup in the same explicit way as configuring a pool with a specific thread count for a test case. They provide context on how pools operate or how tasks are dispatched, which supports understanding the broader pattern but is less directly about a per-test custom pool instance. Taken together, the excerpts support the existence and mechanics of per-test pool customization, with the strongest alignment to per-test thread pool configuration and usage shown in the first excerpt, and supplementary context from the others.",
      "confidence": "medium"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.2.illustrated_pattern",
      "citations": [
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "let ((r1, r2), (r3, r4)) = rayon::join(|| rayon::join(f1, f2), || rayon::join(f3, f4));",
            "rayon::join(|| rcopy(s1, d1), || rcopy(s2, d2));",
            "let (m1, m2, m3, m4, m5, m6, m7, _) = join8(",
            "dest.copy_from_slice(src);",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "matmul_strassen(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "if dest.len() <= LINEAR_CHUNK {",
            "pub fn matmulz(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "|| strassen_add_mul(a21, a22, b11),",
            "|| strassen_sub_mul(b12, b22, a11),",
            " .for_each(|(d, s)| *d += *s);",
            "fn rcopy(src: &[f32], dest: &mut [f32]) {",
            "|| strassen_add2_mul(a11, a22, b11, b22),",
            " .zip(src.par_iter())",
            "return;",
            "}",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        }
      ],
      "reasoning": "The fine-grained field value points to a pattern of recursive divide-and-conquer parallelism implemented with rayon::join, with an eye toward cache locality. The most directly supportive evidence shows a nested join structure that captures a recursive division of work: a join that itself invokes another join, effectively creating a tree of parallel tasks. This directly matches the described recursive divide-and-conquer pattern and demonstrates how work is split and recombined in a way that can improve locality by structuring work into smaller, cache-friendly chunks. Additional excerpts illustrate similar divide-and-conquer strategies using join to combine smaller parallel tasks, including partitioning inputs into quarters and applying multiple parallel subcomputations. Together, these excerpts establish both the recursive parallelism mechanism (join-based composition) and the locality-oriented data partitioning (quarter_chunks, chunk-based copies) that support the finegrained field value. Other excerpts provide broader usage examples of Rayon components or different algorithms, which supply necessary context but do not address the core pattern as directly.",
      "confidence": "high"
    },
    {
      "field": "parallel_slice_processing_patterns.0.usage_context",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length.",
            "fn par_rchunks(&self, chunk_size: usize) -> RChunks<'_, T> { ... }"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes an idiomatic parallel processing pattern for a mutable slice that divides the data into non-overlapping, mutable chunks, emphasizing high efficiency and low bugs due to absence of data races. The most relevant content directly states that a parallel iterator processes at most a given chunk_size elements at a time and that the chunks do not overlap, which aligns precisely with the described pattern. Supporting evidence includes direct API descriptions for chunk-based parallel processing, such as the chunking helpers that produce non-overlapping partitions (par_chunks and par_chunks_exact), and general guidance on non-overlapping chunking (the API that returns an iterator over at most chunk_size elements with no overlap). Additional excerpts reference similar non-overlapping chunking behavior, reinforcing the pattern as idiomatic for parallel slice processing in Rust. Excerpts describing overlapping windows or separators are less relevant because they describe patterns that do overlap, which contradicts the non-overlapping requirement of the finegrained field value.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.0.usage_context",
      "citations": [
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`",
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon."
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "The other issue is that the Rust standard library for the WebAssembly target is built without threads support to ensure maximum portability. Since we want standard library to be thread-safe and [`std::sync`](https://doc.rust-lang.org/std/sync/) APIs to work, you'll need to use the nightly compiler toolchain and pass some flags to rebuild the standard library in addition to your own code.",
            "In order to reduce risk of breakages, it's strongly recommended to use a fixed nightly version. This crate was tested with `nightly-2024-08-02` ."
          ]
        }
      ],
      "reasoning": "The field value asserts that the core pattern to enable true multithreading for Rayon in a browser environment relies on the wasm-bindgen-rayon adapter to connect Rayons threading model to the browsers Web Worker API, and that achieving this requires a nightly Rust toolchain with specific build flags. The most relevant information first establishes wasm-bindgen-rayon as an adapter enabling concurrency on the Web using Web Workers and SharedArrayBuffer support, which directly supports the claimed fundamental pattern and its browser context. Additional, highly relevant content shows that there is an explicit thread pool concept (init_thread_pool/initThreadPool) that must be prepared before use, including exposing an async initThreadPool function after module instantiation to initialize the thread pool and reuse it for threaded operations, which aligns with the notion of bridging thread spawning to the browser. Supporting the exact tooling requirements, another excerpt discusses the need to build the standard library for Wasm with threads support and using nightly toolchains with flags to ensure thread safety, matching the claim about nightly toolchain and build flags. The excerpts mentioning a fixed nightly version provide concrete guidance consistent with requiring a specific nightly release for compatibility. Finally, an example snippet demonstrates initializing the thread pool with a browser-derived concurrency value, illustrating practical usage of the thread pool pattern in the browser environment. Taken together, these excerpts coherently support the field values emphasis on a fundamental browser-oriented multithreading pattern via wasm-bindgen-rayon, the thread pool mechanism, and the nightly/build prerequisites.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.0.pattern_name",
      "citations": [
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "This is because the Wasm code needs to take its own object (the `WebAssembly.Module` ) and share it with other threads when spawning them. This object is only accessible from the `--target web` and `--target no-modules` outputs, but we further restrict it to only `--target web` as we also use [JS snippets feature](https://rustwasm.github.io/wasm-bindgen/reference/js-snippets.html) ."
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`",
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon."
          ]
        }
      ],
      "reasoning": "The field value corresponds to a pattern of enabling multithreading specifically using the wasm-bindgen-rayon integration. Excerpts that discuss exposing or invoking an initialization path to prepare a thread pool directly support this pattern, as they describe how to set up and ready the threading environment for Rayon in a wasm context. One excerpt explicitly shows an example where an async initThreadPool function is exposed in the generated JavaScript and should be invoked after module instantiation to prepare the thread pool before calling other library functions, which is a concrete mechanism for enabling multithreading with this tooling. Another excerpt notes that wasm-bindgen-rayon serves as an adapter for enabling Rayon-based concurrency on the Web with Web Workers and shared memory, which articulates the overarching approach of enabling multithreading via this pattern. A third excerpt demonstrates usage of the pattern by discussing how the init_thread_pool or initThreadPool is used, including code snippets illustrating how to wire up a thread pool and progress from normal single-threaded execution to multithreaded execution with Rayon in a wasm environment. Additional excerpts discuss the necessary integration points, such as how the WebAssembly thread pool is created and reused across operations, which reinforces the architectural pattern of enabling multithreading through a dedicated thread pool managed by wasm-bindgen-rayon. A further excerpt describes that WebAssembly threads rely on Web Workers to instantiate other threads with the same module and memory, highlighting the environmental prerequisites and mechanisms (Web Workers) that underpin the multithreading pattern in this setup. Collectively, these excerpts map directly to the concept of enabling multithreading via wasm-bindgen-rayon by detailing initialization pathways, worker/thread pool creation, and the surrounding WebAssembly/Web Worker integration that makes the pattern operational.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.0.code_template",
      "citations": [
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "This is because the Wasm code needs to take its own object (the `WebAssembly.Module` ) and share it with other threads when spawning them. This object is only accessible from the `--target web` and `--target no-modules` outputs, but we further restrict it to only `--target web` as we also use [JS snippets feature](https://rustwasm.github.io/wasm-bindgen/reference/js-snippets.html) ."
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`",
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon."
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt directly shows the exact API surface and usage pattern that matches the fine-grained field value. It documents exporting the thread pool initializer from the wasm-bindgen-rayon crate and indicates invoking it immediately after module instantiation to prepare the thread pool before parallel library functions are used. This aligns with the templates inclusion of a re-exported init_thread_pool in Rust and a JavaScript sequence that initializes the WebAssembly module and then calls initThreadPool, positioning it as the primary evidence for the field. The next excerpt corroborates the pattern by presenting concrete code illustrating the use of the initThreadPool function from the JavaScript side after getting the wasm module, which complements the Rust-side re-export shown previously and reinforces the exact initialization workflow described in the field value. The excerpt that introduces wasm-bindgen-rayon as an adapter for Rayon-based concurrency on the Web with Web Workers provides essential context that this pattern exists within, but it is slightly broader and not tied to the exact code template; it supports why this pattern is used. Additional excerpts discuss how to use Rayon with WebAssembly threads and provide usage examples that include initThreadPool and the general idea of a thread pool in this WASM context, further supporting the templates intent, though they may be less explicit about the exact function names. Collectively these excerpts map onto the templates sequence: declare dependencies for Rayon and wasm-bindgen-rayon, Rust code re-exporting init_thread_pool, and JavaScript-side initialization with initThreadPool, including the initialization order and the parallel function call flow.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.1.usage_context",
      "citations": [
        {
          "title": "Allow setting COOP and COEP headers in Github Pages #13309",
          "url": "https://github.com/orgs/community/discussions/13309",
          "excerpts": [
            "In order to use SharedArrayBuffer and WebAssembly Threads, COOP and COEP headers need to be set, such that the page becomes cross-origin isolated."
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Using Rayon\n"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        }
      ],
      "reasoning": "The targeted fine-grained field value describes a critical prerequisite for enabling WebAssembly threads: ensuring the browser exposes SharedArrayBuffer by placing the page in a cross-origin isolated state, which is achieved by correctly applying COOP and COEP headers. The most directly supportive content is a passage explaining that SharedArrayBuffer and WebAssembly Threads require headers to be set so the page becomes cross-origin isolated, tying directly to the need for those headers to enable the feature and prevent runtime issues when threads are used. Additional context comes from references that discuss how WebAssembly threads are built on top of Web Workers and that a thread pool may be initialized, which is relevant to the practical deployment of Wasm threads and their runtime environment. The excerpts about wasm-bindgen-rayon and initThreadPool provide concrete examples of how to prepare and expose thread pools in the browser environment, which supports the broader context of enabling and using WebAssembly threads, though they are slightly more about implementation details than prerequisites. Other excerpts discuss the general use and caveats of Rayon with Wasm, which help situate the pattern within pragmatic usage but do not directly state prerequisites for SharedArrayBuffer; they nonetheless corroborate that thread-based patterns are central in this domain.",
      "confidence": "medium"
    },
    {
      "field": "platform_specific_patterns_wasm.1.pattern_name",
      "citations": [
        {
          "title": "Allow setting COOP and COEP headers in Github Pages #13309",
          "url": "https://github.com/orgs/community/discussions/13309",
          "excerpts": [
            "In order to use SharedArrayBuffer and WebAssembly Threads, COOP and COEP headers need to be set, such that the page becomes cross-origin isolated."
          ]
        }
      ],
      "reasoning": "To achieve cross-origin isolation needed for SharedArrayBuffer usage, the configuration must enable the appropriate HTTP security headers that enforce cross-origin isolation. The excerpt states explicitly that setting COOP and COEP headers is required so that the page becomes cross-origin isolated, which directly aligns with the need to configure cross-origin isolation for SharedArrayBuffer as described in the fine-grained field value. Other excerpts discuss thread pools and wasm-related threading details but do not provide information about the HTTP header configuration required for cross-origin isolation, which is the core of the requested field value.",
      "confidence": "high"
    },
    {
      "field": "parallel_slice_processing_patterns.2.code_template",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length."
          ]
        }
      ],
      "reasoning": "The first excerpt presents a concrete example of using a parallel iterator to split a slice into subslices at separators (par_split), then computing the product of each subslice and collecting the results. This directly aligns with the field values pattern: splitting a slice into sub-slices using a predicate, mapping each to a product, and collecting. The code template in the field value corresponds to this exact usage scenario, including the demonstration of the final assertion that verifies the grouped products. The second excerpt discusses the behavior of chunk-based processing (parallels to non-overlapping chunks of a given size) and notes that the last chunk may be shorter if the total element count isnt divisible by the chunk size. While this is related to parallel slice processing, it does not present the same par_split-based idiomatic pattern or the exact sub-slice product computation shown in the field value. It provides contextual background about how parallel iteration can structure work in chunks, which helps frame the broader family of idiomatic patterns in rayon, but it is less directly connected to the specific par_split-based template in the field value.",
      "confidence": "high"
    },
    {
      "field": "parallel_slice_processing_patterns.2.usage_context",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explicitly demonstrates splitting a collection into subslices using a separator predicate (par_split) and then processing those subslices in parallel, which matches the described finegrained field value. It also provides concrete example code showing a delimiter-based split and parallel processing of the resulting subslices, reinforcing the exact pattern sought. The second excerpt discusses producing non-overlapping chunks of a fixed size, which is a related parallel-slicing concept but does not describe splitting by a separator predicate or processing the resulting subslices; it thus provides contextual information about parallel slicing behavior but does not directly confirm the precise splitting-by-separator pattern in question. Together, these excerpts corroborate the general domain (parallel processing over partitions of a slice) but only the first fully aligns with the specified splitting-by-separator pattern. ",
      "confidence": "medium"
    },
    {
      "field": "platform_specific_patterns_wasm.0.anti_patterns",
      "citations": [
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "This is because the Wasm code needs to take its own object (the `WebAssembly.Module` ) and share it with other threads when spawning them. This object is only accessible from the `--target web` and `--target no-modules` outputs, but we further restrict it to only `--target web` as we also use [JS snippets feature](https://rustwasm.github.io/wasm-bindgen/reference/js-snippets.html) .",
            "The other issue is that the Rust standard library for the WebAssembly target is built without threads support to ensure maximum portability. Since we want standard library to be thread-safe and [`std::sync`](https://doc.rust-lang.org/std/sync/) APIs to work, you'll need to use the nightly compiler toolchain and pass some flags to rebuild the standard library in addition to your own code.",
            "## Using Rayon\n"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        }
      ],
      "reasoning": "To support the stated anti-patterns, the most relevant excerpts describe how to properly initialize and use a thread pool with wasm-bindgen-rayon, and what configurations are required to enable multithreading in a web context. A direct note about exposing an asynchronous initialization function that prepares the thread pool before invoking library code demonstrates that skipping this step would prevent parallelism and could result in single-threaded execution. Descriptions showing how the thread pool is created and reused across lifetime of the program reinforce that without a proper thread pool setup, parallel speedups are not realized. Mentions of the need to configure the target (web) and to understand bundler differences provide context for why using bundler-target configurations is considered an anti-pattern in this setting. Collectively, these excerpts connect to the anti-pattern of expecting parallel speedups without proper thread pool initialization and correct target usage, as well as the risk of blocking the main thread without moving work to workers.",
      "confidence": "medium"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.2.usage_context",
      "citations": [
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "matmul_strassen(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "let ((r1, r2), (r3, r4)) = rayon::join(|| rayon::join(f1, f2), || rayon::join(f3, f4));",
            "rayon::join(|| rcopy(s1, d1), || rcopy(s2, d2));",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "let (m1, m2, m3, m4, m5, m6, m7, _) = join8(",
            "if dest.len() <= LINEAR_CHUNK {",
            "dest.copy_from_slice(src);",
            "fn rcopy(src: &[f32], dest: &mut [f32]) {"
          ]
        },
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        }
      ],
      "reasoning": "The idea that rayon::join is a key primitive for CPU-bound, divide-and-conquer algorithms is evidenced by code that explicitly uses parallel joins to structure recursive computation. One excerpt demonstrates a Strassen-like matrix multiplication routine where a matmul implemented with Strassens approach is laid out, highlighting how the algorithm partitions work and could leverage parallelism. Another excerpt shows a nested join pattern that distributes multiple subproblems across parallel tasks, which is a direct instantiation of the divide-and-conquer workflow that Strassen-type methods rely on. A third excerpt provides an example of using rayon::join to coordinate two or more recursive steps, illustrating how tasks are split and then joined to form the final result. Additional excerpts reveal how the code partitions input data into quarters or smaller chunks and then combines intermediate results, which is characteristic of the kind of structured parallelism used in high-performance, CPU-bound workloads. Taken together, these excerpts directly support the claim that rayon::join is essential for efficiently handling balanced, recursive computations (like Strassens algorithm) due to its low overhead and good scheduler integration, and that such patterns are a productive idiomatic direction for high-performance Rust code.",
      "confidence": "high"
    },
    {
      "field": "parallel_iterator_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not",
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)"
          ]
        }
      ],
      "reasoning": "The most relevant passages discuss correctness and potential pitfalls when using parallel iteration: one notes that data-race freedom generally rules out parallel bugs but does not eliminate all issues, which is directly relevant to concerns about anti-patterns and misuse that could still cause problems if not careful. Another excerpt emphasizes that, when code compiles, it typically behaves the same as the sequential version, which touches on the risk of assuming parallelism is always beneficial and can mask anti-patterns like unnecessary concurrency. A concrete code example shows converting sequential iterators to parallel ones, highlighting how easy it is to apply par_iter, which is relevant to the anti-pattern of applying parallelism indiscriminately (overhead concerns and potential inefficiency). Additional context about data-parallelism and guarantees further informs why some anti-patterns (like mutating shared state or relying on non-thread-safe operations) are problematic, reinforcing why improper patterns are considered anti-patterns. Collectively, these excerpts map onto the anti-pattern concerns described in the field value (overhead on small collections, inappropriate use for I/O-bound tasks, and unsafe shared-state mutation that can cause contention and negate parallel benefits).",
      "confidence": "medium"
    },
    {
      "field": "parallel_slice_processing_patterns.0.code_template",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length.",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>",
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>"
          ]
        }
      ],
      "reasoning": "The fine-grained field value presents a Rust code template that uses a parallel iterator to operate on chunks of a slice (par_chunks_mut with a for_each to mutate and then asserts the final order). Excerpts that describe parallel chunking patterns in rayon directly support understanding of how chunking works in a parallel context. The most relevant excerpts discuss the par_chunks API and its behavior (including the idea of chunking a slice into fixed-size pieces and iterating in parallel). These excerpts help explain the core mechanism visible in the code template: dividing a slice into equal-sized chunks processed in parallel and each chunk mutated by a closure. Other excerpts that describe related parallel operations on chunks (such as par_chunks_exact, which provides exact-sized chunks, and general non-overlapping chunking behavior) further contextualize how chunking operates in a parallel setting. Excerpts about par_windows or par_split are tangential but still relate to the broader family of parallel slice operations and can help contrast different parallel iteration patterns. The least directly relevant excerpts discuss other parallel utilities (like splitting by a separator) which are related in spirit but not central to the provided code pattern. Overall, the most relevant content directly supports understanding of chunk-based parallel iteration and mutation semantics, while less relevant items provide peripheral context about related rayon API surfaces.",
      "confidence": "medium"
    },
    {
      "field": "platform_specific_patterns_wasm.1.alternate_patterns",
      "citations": [
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpts describe the mechanism by which multithreading is enabled in this context: a pool of workers is created and reused for multithreaded operations, and there is a function to initialize this thread pool (initThreadPool) that must be called before the rest of the code runs. This establishes that multithreading is achievable via a thread pool mechanism rather than a global single-threaded path, which is the opposite of the claim that there is no direct alternative and that only a single-threaded build exists. The presence of an explicit thread-pool initialization, and the description of an adapter that enables Rayon-based concurrency on Web with Web Workers, both serve as concrete alternatives to a naive or initial single-threaded approach. Because these excerpts describe concrete strategies to enable multithreading (thread pools, wasm-bindgen-rayon adapter) rather than endorsing a single-threaded alternative, they do not support the claim that no alternative exists; instead they provide multiple viable threading patterns. A few excerpts also highlight caveats and integration details when using threads with Wasm and Rayon, which further clarifies that multithreading is feasible but requires specific setup rather than implying there is no alternative. Overall, the excerpts collectively show explicit approaches to enable and manage multithreading, contradicting the idea that there is no direct alternative. ",
      "confidence": "low"
    },
    {
      "field": "parallel_slice_processing_patterns.2.anti_patterns",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length."
          ]
        }
      ],
      "reasoning": "The anti-pattern in question describes using a predicate that yields a large number of very small subslices, which can cause scheduling overhead and degrade performance. The first excerpt explicitly shows a usage pattern where a parallel split creates subslices based on a separator, with an example that yields several subslices (products derived from groups of numbers separated by zero). This demonstrates the core mechanism of creating subslices via a predicate, which is the prerequisite for forming many tiny subslices. The second excerpt describes how the parallel iterator processes chunks of a fixed size and notes that chunks do not overlap; while it does not discuss many subslices, it provides the parallel-slicing context and constraints that would interact with many tiny subslices, illustrating how the system groups elements into non-overlapping chunks or subslices. Taken together, these excerpts support the notion that using a predicate-based split can produce multiple subslices, and those subslices could become small enough to incur scheduling overhead, aligning with the described anti-pattern concept.",
      "confidence": "medium"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.2.code_template_concept",
      "citations": [
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "rayon::join(|| rcopy(s1, d1), || rcopy(s2, d2));",
            "let ((r1, r2), (r3, r4)) = rayon::join(|| rayon::join(f1, f2), || rayon::join(f3, f4));",
            " .zip(src.par_iter())",
            " .for_each(|(d, s)| *d += *s);",
            "fn rcopy(src: &[f32], dest: &mut [f32]) {",
            "dest.copy_from_slice(src);"
          ]
        }
      ],
      "reasoning": "The core field value describes a recursive or multi-way parallel pattern using rayon::join to split work across subproblems, including an abstracted form like rayon::join(|| recursive_op(sub_matrix_1), || recursive_op(sub_matrix_2)); This is directly exemplified by a line that shows a join invocation spawning two nested tasks: rayon::join(|| rayon::join(f1, f2), || rayon::join(f3, f4)); which mirrors the idea of hierarchical task splitting and composing multiple sub-operations. Another excerpt demonstrates a higher-level reuse pattern of join with more sub-tasks, illustrating a join involving multiple branches (join8) to parallelize several sub-operations, aligning with the concept of 4-way or 8-way concurrent tasks. The field value also mentions an element-wise parallel operation pattern achieved by zipping parallel iterators and applying a per-element update, which is shown by a snippet that chains a zip of parallel iterators: .zip(src.par_iter()) followed by .for_each(|(d, s)| *d += *s); This directly corresponds to applying an operation across corresponding elements in two slices in parallel. Additionally, an excerpt demonstrates a simple top-level usage of rayon::join to execute two separate computations concurrently: rayon::join(|| rcopy(s1, d1), || rcopy(s2, d2)); reinforcing the core idea of spawning multiple tasks and composing their results. The presence of a helper that copies data between slices inside a function (dest.copy_from_slice(src)) provides a lower-level data movement primitive that complements the join-based parallel structure, illustrating how data can be moved efficiently as part of a parallel workflow. Taken together, these excerpts substantiate the described idioms: recursive/multi-way task splitting with join constructs (including nested forms and abstractions) and element-wise parallelism via zipped par_iter-based loops.",
      "confidence": "high"
    },
    {
      "field": "interoperability_patterns.1.pattern_name",
      "citations": [
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to the idiomatic pattern name for combining two iterables via a zip operation, specifically zip() or zip_eq(). The excerpt explicitly describes a Zip in rayon::iter, noting that Zip is an iterator that zips up a and b into a single iterator of pairs and that this struct is created by the zip() method on IndexedParallelIterator. This directly maps to the requested pattern name, showing the practical usage of zip() in the Rayon library and how the zip operation is realized as a concrete pattern (Zip) in this codebase. Although the excerpt does not mention zip_eq(), it clearly supports the core pattern name zip() and its role in creating a paired iterator, which is the central element of the requested finegrained field value.",
      "confidence": "high"
    },
    {
      "field": "demonstrated_pipelines_from_rayon_demo.2.alternate_patterns_shown",
      "citations": [
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "pub fn matmulz(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "rayon::join(|| rcopy(s1, d1), || rcopy(s2, d2));",
            "let ((r1, r2), (r3, r4)) = rayon::join(|| rayon::join(f1, f2), || rayon::join(f3, f4));",
            "matmul_strassen(a: &[f32], b: &[f32], dest: &mut [f32]) {",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (b11, b12, b21, b22) = quarter_chunks(b);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "let (a11, a12, a21, a22) = quarter_chunks(a);",
            "fn rcopy(src: &[f32], dest: &mut [f32]) {",
            "dest.copy_from_slice(src);",
            "if dest.len() <= LINEAR_CHUNK {",
            "let (m1, m2, m3, m4, m5, m6, m7, _) = join8(",
            " .for_each(|(d, s)| *d += *s);",
            " .zip(src.par_iter())",
            "|| strassen_add2_mul(a11, a22, b11, b22),",
            "|| strassen_add_mul(a21, a22, b11),",
            "|| strassen_sub_mul(b12, b22, a11),",
            "}",
            "return;"
          ]
        },
        {
          "title": "Rayon-demo main.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/main.rs",
          "excerpts": [
            "A collection of different benchmarks of Rayon. You can run the full\nbenchmark suite by executing `cargo bench` or `rayon-demo bench`.\n\nAlternatively, you can run individual benchmarks by running\n`rayon-demo foo`, where `foo` is the name of a benchmark. Each\nbenchmark has its own options and modes, so try `rayon-demo foo\n--help`.\n\nBenchmarks:\n\n  - life : Conway's Game of Life.\n  - nbody: A physics simulation of multiple bodies attracting and repelling\n           one another.\n  - sieve: Finding primes using a Sieve of Eratosthenes.\n  - matmul: Parallel matrix multiplication.\n  - mergesort: Parallel mergesort.\n  - noop: Launch empty tasks to measure CPU usage.\n  - quicksort: Parallel quicksort.\n  - tsp: Traveling salesman problem solver (sample data sets in `data/tsp`).\n",
            "fn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        usage();\n    }\n\n    let bench_name = &args[1];\n    match &bench_name[..] {\n        \"matmul\" => matmul::main(&args[1..]),\n        \"mergesort\" => mergesort::main(&args[1..]),\n        \"nbody\" => nbody::main(&args[1..]),\n        \"quicksort\" => quicksort::main(&args[1..]),\n        \"sieve\" => sieve::main(&args[1..]),\n        \"tsp\" => tsp::main(&args[1..]),\n        \"life\" => life::main(&args[1..]),\n        \"noop\" => noop::main(&args[1..]),\n        _ => usage(),\n    }\n}\n"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        }
      ],
      "reasoning": "The finest-grained field value refers to a matmulz variant that purportedly uses a Z-order curve traversal to optimize cache locality. The only excerpt that directly references a function named matmulz is the one declaring a function with that exact name, indicating that this variant exists in the codebase. This directly supports the idea that a matmulz variant is present in the repository, which aligns with the notion of having an idiomatic pattern variant for matrix multiplication. However, there is no explicit content in the excerpts that describes or confirms a Z-order traversal or cache-locality optimization. Consequently, while the presence of a matmulz function supports the notion of an advanced pattern variant, it does not validate the specific Z-order/caching claim. Other excerpts discuss parallel composition and various matmul-related functions or patterns (e.g., matmul, matmul_strassen, and auxiliary routines like rcopy and quarter_chunks). These provide contextual support that the repository contains multiple matmul-related implementations and optimization-oriented ideas, but they do not confirm the Z-order pattern or cache- locality claims. Therefore, the strongest direct link is the matmulz function declaration, while the direct Z-order cache-locality claim remains unverified by the excerpts. Based on this, the most relevant content is the explicit matmulz declaration, followed by related matmul and parallelism patterns that establish a pattern of optimization-oriented variants, with diminishing relevance for the explicit Z-order claim due to lack of explicit evidence.",
      "confidence": "low"
    },
    {
      "field": "introduction_to_rayon_idioms",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "```",
            "```",
            "```",
            "```",
            "}"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "The usage of `join`\nis very simple. You invoke it with two closures, like shown below, and\nit will *potentially* execute them in parallel. Once they have both\nfinished, it will return:",
            "```\n// `do_something` and `do_something_else` *may* run in parallel\njoin(|| do_something(), || do_something_else())\n```",
            "```\ntrait Joiner {\n    /// True if this is parallel mode, false otherwise. fn is_parallel() -> bool;\n    \n    /// Either calls `rayon::join` or just invokes `oper_a(); oper_b();`.\nfn join<A,R_A,B,R_B>(oper_a: A, oper_b: B) -> (R_A, R_B)\n        where A: FnOnce() -> R_A + Send, B: FnOnce() -> R_B + Send;\n}\n```",
            "\n\n`join` is a great primitive for divide-and-conquer algorithms. These\nalgorithms tend to divide up the work into two roughly equal parts and\nthen recursively process those parts. For example, we can implement a\n[parallel version of quicksort](https://github.com/nikomatsakis/rayon/blob/22f04aee0e12b31e029ec669299802d6e2f86bf6/src/test.rs) like so:",
            "```\nfn quick_sort<T:PartialOrd+Send>(v: &mut [T]) {\n    if v.len() > 1 {\n        let mid = partition(v);\n        let (lo, hi) = v.split_at_mut(mid);\n        rayon::join(|| quick_sort(lo),\n                    || quick_sort(hi));\n    }\n}\nfn partition<T:PartialOrd+Send>(v: &mut [T]) -> usize {\n    // see https://en.wikipedia.org/wiki/Quicksort\n}\n```",
            "```\nstruct Parallel;\nimpl Joiner for Parallel { .. }\n\nstruct Sequential;\nimpl Joiner for Sequential { .. }\n```\n",
            "The idea is\nthat you can basically annotate your programs with calls to `join` to\nindicate where parallelism might be a good idea, and let the runtime\ndecide when to take advantage of that.",
            "    }",
            "```",
            "```",
            "```",
            "```",
            "}",
            "}"
          ]
        },
        {
          "title": "Intro to Rayon and join idioms (rayon-join patterns)",
          "url": "https://thedataquarry.com/blog/intro-to-rayon",
          "excerpts": [
            "The idea is that a program that uses a sequential iterator\ncan be easily converted to use a parallel iterator by simply replacing `iter` with `par_iter`. Under the hood, parallel iterators rely on a core primitive called `join` that allows Rayon to\npotentially execute two closures in parallel and bring their results together once they both finish.",
            "The remarkable feature is that Rayon *itself* (and not the user) decides whether or not parallelism\nis beneficial, and if so, how to divide the work among threads.",
            "Under the hood, parallel iterators apply a divide-and-conquer strategy to the task at hand. In the\nexample above, the parallel iterator initiated by the call to `par_iter` will spawn two threads that implement\na `join`, dividing the work into two halves. The worker thread in charge of either half\ncontinues to divide the work further until a sufficiently small amount of work is left to be done,\nwhich is then executed sequentially.",
            "Rayons implementation is based on the method\ndescribed in a paper by Blumofe and Leiserson[2]().",
            "Note that Rayon starts with roughly one worker thread per CPU core  not all steps in the parallel\niterator pipeline will spawn new threads."
          ]
        },
        {
          "title": "Benchmark suite  Issue #35  rayon-rs/rayon - GitHub",
          "url": "https://github.com/rayon-rs/rayon/issues/35",
          "excerpts": [
            "Description  quicksort -- everybody's favorite :)  mergesort or heapsort?  NBody -- I've started porting NBody from the ParallelJS benchmarks in ..."
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "```rust",
            "assert\\_eq! (v, vec! [0, 1, 5, 8, 22, 44",
            "/* rayon::join(|| quick\\_sort(lo),",
            "fn** join<A, B, RA, RB>(oper\\_a: A, oper\\_b: B) -> (RA, RB)",
            "| #[\"inline\"]",
            "* }",
            "* }",
            " ",
            "where",
            "{",
            "```",
            "```",
            "}"
          ]
        },
        {
          "title": "mergesort.rs source code [crates/rayon-1.10.0/src/slice/ ...",
          "url": "https://codebrowser.dev/rust/crates/rayon-1.10.0/src/slice/mergesort.rs.html",
          "excerpts": [
            "Jun 12, 2025  Source code of mergesort.rs rayon 1.10.0 on KDAB Codebrowser."
          ]
        },
        {
          "title": "Why is my Rayon-based mergesort slower than my thread- ...",
          "url": "https://www.reddit.com/r/learnrust/comments/16whqy0/why_is_my_rayonbased_mergesort_slower_than_my/",
          "excerpts": [
            "I was surprised to find that my rayon-based version of parallel mergesort is consistently outperformed by my std::thread -based version of parallel mergesort."
          ]
        },
        {
          "title": "Limiting parallelism for certain map operations in a Rayon ... - GitHub",
          "url": "https://github.com/rayon-rs/rayon/discussions/1193",
          "excerpts": [
            "The parallel computation, very roughly, is to find files on disk and scan them, all in parallel with as many cores as are available.",
            "Oct 11, 2024  Beware of #592 if you try the mutex idea -- that is, you may hit a recursion deadlock if you make rayon calls while holding a mutex. I think it...",
            "Oct 11, 2024  This also allows, for example, to initialize thread-local state (such as GPU contexts) on each worker of a particular Rayon thread pool.",
            "Here is a blog post from 2020 about using multiple thread pools in Rayon ... work-stealing scheme. But that would be a lot more complicated ... The parallel computation, very roughly, is to find files on disk and scan them, all in parallel with as many cores as are available."
          ]
        },
        {
          "title": "rayon::slice::quicksort - Rust",
          "url": "https://doc.servo.org/rayon/slice/quicksort/index.html",
          "excerpts": [
            "Scatters some elements around in an attempt to break patterns that might cause imbalanced partitions in quicksort. ... Chooses a pivot in v and returns the index ..."
          ]
        },
        {
          "title": "Sorting DateTime Objects with Parallel Merge Sort in Rust - Medium",
          "url": "https://medium.com/myorder/sorting-datetime-objects-with-parallel-merge-sort-in-rust-5db813bd8945",
          "excerpts": [
            "Parallel merge sort is an excellent choice for sorting large collections of date and time objects efficiently. With Rust and the rayon crate, ..."
          ]
        },
        {
          "title": "ParallelSliceMut in rayon::slice - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSliceMut.html",
          "excerpts": [
            "The current algorithm is an adaptive merge sort inspired by timsort. It is designed to be very fast in cases where the slice is nearly sorted, or consists of ... The current algorithm is based on pattern-defeating quicksort by Orson Peters, which combines the fast average case of randomized quicksort with the fast ...",
            "(struct.ChunksMut.html \"struct rayon::slice::ChunksMut\") <'\\_, T>\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks are mutable and do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet mut array = [ 1 , 2 , 3 , 4 , 5 ];\narray.par_chunks_mut( 2 )\n     .for_each(|slice| slice.reverse());\nassert_eq! (array, [ 2 , 1 , 4 , 3 , 5 ]);\n```\n\n[Source](../../src/rayon/slice/mod.rs.html)",
            "```\nuse rayon::prelude:: * ;\nlet mut array = [ 1 , 2 , 3 , 4 , 5 ];\narray.par_chunks_exact_mut( 3 )\n     .for_each(|slice| slice.reverse());\nassert_eq! (array, [ 3 , 2 , 1 , 4 , 5 ]);\n```\n\n[Source](../../src/rayon/slice/mod.rs.htm",
            "nksMut](struct.RChunksMut.html \"struct rayon::slice::RChunksMut\") <'\\_, T>\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time,\nstarting at the end. The chunks are mutable and do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet mut array = [ 1 , 2 , 3 , 4 , 5 ];\narray.par_rchunks_mut( 2 )\n     .for_each(|slice| slice.reverse());\nassert_eq! (array, [ 1 , 3 , 2 , 5 , 4 ]);\n```\n\n[Source](../../src/rayon/slice/mod.rs.html)",
            "usize ,\n    ) -> RChunksExactMut <'_, T> { ... }\n    fn par_sort (&mut self)\n       where T: Ord { ... }\n    fn par_sort_by <F>(&mut self, compare: F)\n       where F: Fn ( &T , &T ) -> Ordering + Sync { ... }\n    fn par_sort_by_key <K, F>(&mut self, f: F)\n       where K: Ord ,\n             F: Fn ( &T ) -> K + Sync { ... }\n    fn par_sort_by_cached_key <K, F>(&mut self, f: F)\n       where F: Fn ( &T ) -> K + Sync ,\n             K: Ord + Send { ... }\n    fn par_sort_unstable (&mut self)\n       where T: Ord { ... }\n    fn par_sort_unstable_by <F>(&mut self, compare: F)\n       where F: Fn ( &T , &T ) -> Ordering + Sync { ... }\n    fn par_sort_unstable_by_key <K, F>(&mut self, f: F)\n       where K: Ord ,\n             F: Fn ( &T ) -> K + Sync { ... }\n",
            "par_sort_by) <F>(&mut self, compare: F)\n\nwhere\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") ( [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html) , [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html) ) -> [Ordering](https://doc.rust-lang.org/nightly/core/cmp/enum.Ordering.html \"enum core::cmp::Ordering\") \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") ,\n\nSorts the slice in parallel with a comparator function. This sort is stable (i.e., does not reorder equal elements) and _O_ ( _n_ \\* log( _n_ )) worst-case. The comparator function must define a total ordering for the elements in the slice. If\nthe ordering is not total, the order of the elements is unspecified. An order is a\ntotal order if it is (for all `a` , `b` and `c` ):",
            "st-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") ,\n\nSorts the slice in parallel with a key extraction function. This sort is stable (i.e., does not reorder equal elements) and _O_ ( _m_ \\* _n_ \\* log( _n_ ))\nworst-case, where the key function is _O_ ( _m_ ). For expensive key functions (e.g. functions that are not simple property accesses or\nbasic operations), [`par_sort_by_cached_key`](.par_sort_by_cached_key) is likely to\nbe significantly faster, as it does not recompute element keys. When applicable, unstable sorting is preferred because it is generally faster than stable\nsorting and it doesnt allocate auxiliary memory.",
            "_key](.par_sort_by_cached_key) <K, F>(&mut self, f: F)\n\nwhere\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") ( [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html) ) -> K + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") ,\n K: [Ord](https://doc.rust-lang.org/nightly/core/cmp/trait.Ord.html \"trait core::cmp::Ord\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSorts the slice in parallel with a key extraction function. During sorting, the key function is called at most once per element, by using\ntemporary storage to remember the results of key evaluation. The key function is called in parallel, so the order of calls is completely unspecified. This sort is stable (i.e., does not reorder equal elements) and _O_ ( _m_ \\* _n_ \\+ _n_ \\* log( _n_ ))\nworst-case, where the key function is _O_ ( _m_ ).",
            "par_sort_unstable_by) <F>(&mut self, compare: F)\n\nwhere\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") ( [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html) , [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html) ) -> [Ordering](https://doc.rust-lang.org/nightly/core/cmp/enum.Ordering.html \"enum core::cmp::Ordering\") \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") ,\n\nSorts the slice in parallel with a comparator function, but might not preserve the order of\nequal elements. This sort is unstable (i.e., may reorder equal elements), in-place\n(i.e., does not allocate), and _O_ ( _n_ \\* log( _n_ )) worst-case. The comparator function must define a total ordering for the elements in the slice. If\nthe ordering is not total, the order of the elements is unspecified.",
            "by\\_key](.par_sort_unstable_by_key) <K, F>(&mut self, f: F)\n\nwhere\n K: [Ord](https://doc.rust-lang.org/nightly/core/cmp/trait.Ord.html \"trait core::cmp::Ord\") ,\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") ( [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html) ) -> K + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") ,\n\nSorts the slice in parallel with a key extraction function, but might not preserve the order\nof equal elements. This sort is unstable (i.e., may reorder equal elements), in-place\n(i.e., does not allocate), and _O_ (m \\* _n_ \\* log( _n_ )) worst-case,\nwhere the key function is _O_ ( _m_ ).",
            "#### fn [par\\_sort\\_unstable](.par_sort_unstable) (&mut self)\n\nwhere\n T:",
            "rrent implementation\n\nThe current algorithm is based on [pattern-defeating quicksort](https://github.com/orlp/pdqsort) by Orson Peters,\nwhich combines the fast average case of randomized quicksort with the fast worst case of\nheapsort, while achieving linear time on slices with certain patterns. It uses some\nrandomization to avoid degenerate cases, but with a fixed seed to always provide\ndeterministic behavior. In the worst case, the a",
            " . ##### []() Current implementation\n\nThe current algorithm is an adaptive merge sort inspired by [timsort](https://en.wikipedia.org/wiki/Timsort) . It is designed to be very fast in cases where the slice is nearly sorted, or consists of\ntwo or more sorted sequences concatenated one after another. Also, it allocates temporary storage the same size as `self` , but for very short slices a\nnon-allocating insertion sort is used instead. In order to sort the slice in parallel, the slice is first divided into smaller chunks and\nall chunks are sorted in parallel. Then, adjacent chunks that together form non-descending\nor descending runs are concatenated. Finally, the remaining chunks are merged together using\nparallel subdivision of chunks and parallel merge operation.",
            "\\_by\\_key](.par_sort_by_key) <K, F>(&mut self, f: F)\n\nwhere\n K: [Ord](https://doc.rust-lang.org/nightly/core/cmp/trait.Ord.html \"trait core::cmp::Ord\") ,\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") ( [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html) ) -> K + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") ,\n\nSorts the slice in parallel with a key extraction function. This sort is stable (i.e., does not reorder equal elements) and _O_ ( _m_ \\* _n_ \\* log( _n_ ))\nworst-case, where the key function is _O_ ( _m_ ). For expensive key functions (e.g. functions that are not simple property accesses or\nbasic operations), [`par_sort_by_cached_key`](.par_sort_by_cached_key) is likely to\nbe significantly faster, as it does not recompute element keys.",
            "par_sort) (&mut self)\n\nwhere\n T: [Ord](https://doc.rust-lang.org/nightly/core/cmp/trait.Ord.html \"trait core::cmp::Ord\") ,\n\nSorts the slice in parallel. This sort is stable (i.e., does not reorder equal elements) and _O_ ( _n_ \\* log( _n_ )) worst-case. When applicable, unstable sorting is preferred because it is generally faster than stable\nsorting and it doesnt allocate auxiliary memory. See [`par_sort_unstable`](.par_sort_unstable) .",
            " ##### []() Current implementation\n\nThe current algorithm is an adaptive merge sort inspired by [timsort](https://en.wikipedia.org/wiki/Timsort) . It is designed to be very fast in cases where the slice is nearly sorted, or consists of\ntwo or more sorted sequences concatenated one after another. Also, it allocates temporary storage the same size as `self` , but for very short slices a\nnon-allocating insertion sort is used instead. In order to sort the slice in parallel, the slice is first divided into smaller chunks and\nall chunks are sorted in parallel. Then, adjacent chunks that together form non-descending\nor descending runs are concatenated. Finally, the remaining chunks are merged together using\nparallel subdivision of chunks and parallel merge operation.",
            "Returns a parallel iterator over mutable subslices separated by elements that match the separator, including the matched part as a terminator."
          ]
        },
        {
          "title": "join hangs if a worker thread panics  Issue #10  rayon-rs ... - GitHub",
          "url": "https://github.com/rayon-rs/rayon/issues/10",
          "excerpts": [
            "If a worker thread panics, I would expect rayon to either return an error result or simply propagate that panic."
          ]
        },
        {
          "title": "mergesort.rs - parallel merge sort using rayon",
          "url": "https://rust-lang.github.io/hashbrown/src/rayon/slice/mergesort.rs.html",
          "excerpts": [
            "//! Parallel merge sort. //!",
            "//! This implementation is copied verbatim from `std::slice::sort` and then parallelized. //! The only difference from the original is that the sequential `mergesort` returns",
            "rayon_core::join",
            "par_merge(left_l, right_l, dest_l as *mut T, is_less)",
            "par_merge(left_r, right_r, dest_r as *mut T, is_less)",
            "par_chunks_mut(CHUNK_LENGTH)",
            "v.par_chunks_mut(CHUNK_LENGTH)",
            "Source of the Rust file `/home/travis/.cargo/registry/src/github.com-1ecc6299db9ec823/rayon-1.5.0/src/slice/mergesort.rs`."
          ]
        },
        {
          "title": "Quick Sort vs Merge Sort - GeeksforGeeks",
          "url": "https://www.geeksforgeeks.org/dsa/quick-sort-vs-merge-sort/",
          "excerpts": [
            "Quick sort first partitions the array and then make two recursive calls. Merge sort first makes recursive calls for the two halves, and then merges the two ..."
          ]
        },
        {
          "title": "I think it's fair to say that pdqsort (pattern-defeating quicksort) is ...",
          "url": "https://news.ycombinator.com/item?id=14666710",
          "excerpts": [
            "Pdqsort efficiently eliminates branch mispredictions and brings some other improvements over introsort as well - for example, the complexity becomes O(nk) if ..."
          ]
        },
        {
          "title": "Work-Stealing Algorithm Distilled | by Ryan Zheng | The Startup",
          "url": "https://medium.com/swlh/work-stealing-distilled-d2ed86d3065d",
          "excerpts": [
            "This work-stealing algorithm is so general, it could be used in all other languages to manage task scheduling. For example, in Kotlin and Python, there are ..."
          ]
        },
        {
          "title": "quicksort.rs - source",
          "url": "https://rust-lang.github.io/hashbrown/src/rayon/slice/quicksort.rs.html",
          "excerpts": [
            "`rayon_core::join`. use std::cmp; use std::mem; use std::ptr; /// When dropped, takes the value out of `Option` and writes it into `dest`. /// /// This ..."
          ]
        },
        {
          "title": "rayon (or other) - nested parallelism? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/ayqa6r/rayon_or_other_nested_parallelism/",
          "excerpts": [
            "Rayon is already based on work-stealing fork-join parallelism, so it recursively splits the data as much as it needs to satisfy all processors.",
            "Rayon is already based on work-stealing fork-join parallelism, so it recursively splits the data as much as it needs to satisfy all processors. In addition, rayon::join (which is basically what parallel iterators boil down to) is really cheap and does not even allocate dynamic memory. hi, I've done a lot of nested parallelism using rayon. even up to 3 nested levels. you can find an example of a complex algorithm using a scope ...",
            "hi, I've done a lot of nested parallelism using rayon. even up to 3 nested levels. you can find an example of a complex algorithm using a scope here: <http://www-id.imag.fr/Laboratoire/Membres/Wagner_Frederic/folding-with-help.html> (see prefix sectio",
            "Rayon is already based on work-stealing fork-join parallelism, so it recursively splits the data as much as it needs to satisfy all processors. So nested parallelism is already a core part of rayon.",
            "Rayon is already based on work-stealing fork-join parallelism, so it recursively splits the data as much as it needs to satisfy all processors. So nested parallelism is already a core part of rayon."
          ]
        },
        {
          "title": "lib.rs - source",
          "url": "https://docs.rs/rayon/latest/src/rayon/lib.rs.html",
          "excerpts": [
            "1//! Rayon is a data-parallelism library that makes it easy to convert sequential 2//! computations into parallel. 3//! 4//! It is lightweight and ... 1//! Rayon is a data-parallelism library that makes it easy to convert sequential 2//! computations into parallel. 3//! 4//! It is lightweight and...",
            "The [`par_sort`] method sorts `&mut [T]` slices (or vectors) in paral",
            "1//! Rayon is a data-parallelism library that makes it easy to convert sequential 2//! computations into parallel. 3//! 4//! It is lightweight and...",
            "1//! Rayon is a data-parallelism library that makes it easy to convert sequential 2//! computations into parallel. 3//! 4//! It is lightweight and ..."
          ]
        },
        {
          "title": "Stack overflow with rayon::scope and spawn  Issue #854 - GitHub",
          "url": "https://github.com/rayon-rs/rayon/issues/854",
          "excerpts": [
            "Apr 30, 2021  Here is a simple piece of code which causes a stack overflow with rayon 1.5.0: use rayon::prelude::*; fn do_work(index: u32) { if index...",
            "Rayon has implicit \"recursion\" due to work stealing. That is, whenever a rayon thread is blocked on the result from another rayon thread, it will look for other pending work to do in the meantime. That stolen work is executed directly from the same stack where it was blocked. Your `par_iter().for_each()` becomes a bunch of nested `join`s, and each one of those may block if one half gets stolen to a new thread.",
            "Your par_iter().for_each() becomes a bunch of nested join s, and each one of those may block if one half gets stolen to a new thread.",
            "Apr 30, 2021  Your par_iter().for_each() becomes a bunch of nested join s, and each one of those may block if one half gets stolen to a new thread."
          ]
        },
        {
          "title": "Scoped threads vs. mpsc - The Rust Programming Language Forum",
          "url": "https://users.rust-lang.org/t/scoped-threads-vs-mpsc/108632",
          "excerpts": [
            "My problem is that this works with std:: thread::scope, but it does not work with a ThreadPool::scope() in rayon, God knows why, in the sense ..."
          ]
        },
        {
          "title": "Rust Rayon ThreadPool: 'Cannot borrow as mutable, as it is a ...",
          "url": "https://stackoverflow.com/questions/78479584/rust-rayon-threadpool-cannot-borrow-as-mutable-as-it-is-a-captured-variable-i",
          "excerpts": [
            "Chapter 4.2 of the Rust Book says that you can't have multiple mutable references to a variable, which is essentially what each thread would be getting."
          ]
        },
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack.",
            "Panics\n\nIf a panic occurs, either in the closure given to `scope()` or in\nany of the spawned jobs, that panic will be propagated and the\ncall to `scope()` will panic. If multiple panics occurs, it is\nnon-deterministic which of their panic values will propagate. Regardless, once a task is spawned using `scope.spawn()` , it will\nexecute, even if the spawning task should later panic",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:\n\n```\npub fn join<A,B,RA,RB>(oper_a: A, oper_b: B) -> (RA, RB)\n    where A: FnOnce() -> RA + Send,\n          B: FnOnce() -> RB + Send,\n          RA: Send,\n          RB: Send,\n{\n    let mut result_a: Option<RA> = None;\n    let mut result_b: Option<RB> = None;\n    rayon::scope(|s| {\n        s.spawn(|_| result_a = Some(oper_a()));\n        s.spawn(|_| result_b = Some(oper_b()));\n    });\n    (result_a.unwrap(), result_b.unwrap())\n}\n```\n",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned.",
            "pub fn scope<'scope, OP, R>(op: OP) -> R",
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "o reference `bad` we must\ntake ownership of it. One way to do this is to detach the closure\nfrom the surrounding stack frame, using the `move` keyword. This\nwill cause it to take ownership of _all_ the variables it touches,\nin this case including both `ok` _and_ `bad",
            "That closure is fine, but now we can't use \\`ok\\` anywhere else,\n    // since it is owned by the previ",
            "While this works, it could be a problem if we want to use `ok` elsewhere. There are two choices. We can keep the closure as a `move` closure, but\ninstead of referencing the variable `ok` , we create a shadowed variable that\nis a borrow of `ok` and capture _tha",
            "Another option is not to use the `move` keyword but instead to take ownership\nof individual variables:",
            "`scope()` returns once all spawned jobs have completed, and any panics are\npropagated at that point.",
            "Creates a fork-join scope s and invokes the closure with a reference to s. This closure can then spawn asynchronous tasks into s.",
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "The closure given to `scope()` executes in the Rayon thread pool,\nas do those given to `spawn()` . This means that you cant access\nthread-local variables (well, you can, but they may have\nunexpected values).",
            "Task execution potentially starts as soon as `spawn()` is called. The task will end sometime before `scope()` returns. Note that the _closure_ given to scope may return much earlier.",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned. So in this example, absent any stealing, we can\nexpect `s.2` to execute before `s.1` , and `t.2` before `t.1` . Other\nthreads always steal from the other end of the deque, like FIFO\norder.",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:",
            "everything spawned into scope `s` will\nterminate (at latest) at the same point  right before the\noriginal call to `rayon::scope` returns. This includes new\nsubtasks created by other subtasks (e.g., task `s.1.1` ). If a new\nscope is created (such as `t` ), the things spawned into that scope\nwill be joined before that scope returns, which in turn occurs\nbefore the creating task (task `s.1.1` in this case) finishes.",
            "In general, spawned tasks may access stack data in place that\noutlives the scope itself. Other data must be fully owned by the\nspawned task.",
            "Panics\n\nIf a panic occurs, either in the closure given to `scope()` or in\nany of the spawned jobs, that panic will be propagated and the\ncall to `scope()` will panic. If multiple panics occurs, it is\nnon-deterministic which of their panic values will propagate. Regardless, once a task is spawned using `scope.spawn()` , it will\nexecute, even if the spawning task should later panic.",
            "The point here is that everything spawned into scope `s` will\nterminate (at latest) at the same point  right before the\noriginal call to `rayon::scope` returns.",
            "For an alternate approach, consider [`scope_fifo()`](fn.scope_fifo.html \"fn rayon::scope\\_fifo\") instead",
            "    R: Send ,",
            "n\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible.",
            "scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack",
            "However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "pub fn join<A,B,RA,RB>(oper_a: A, oper_b: B) -> (RA, RB)\n    where A: FnOnce() -> RA + Send,\n          B: FnOnce() -> RB + Send,\n          RA: Send,\n          RB: Send,\n{",
            "This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete.",
            "For an alternate approach, consider [`scope_fifo()`](fn.scope_fifo.html \"fn rayon::scope\\_fifo\") instead."
          ]
        },
        {
          "title": "rayon_core::scope - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon_core/fn.scope.html",
          "excerpts": [
            "Creates a fork-join scope s and invokes the closure with a reference to s. This closure can then spawn asynchronous tasks into s."
          ]
        },
        {
          "title": "Rayon Scope and spawn documentation",
          "url": "https://docs.rs/rayon/latest/rayon/struct.Scope.html",
          "excerpts": [
            "Spawns a job into the fork-join scope `self` . This job will\nexecute sometime before the fork-join scope completes. The\njob is specified as a closure, and this closure receives its\nown reference to the scope `self` as argument. This can be\nused to inject new jobs into `self` . ##### []() Returns\n\nNothing. The spawned closures cannot pass back values to the\ncaller directly, though they can write to local variables on\nthe stack (if those variables outlive the scope) or\ncommunicate through shared channels. (The intention is to eventually integrate with Rust futures to\nsupport spawns of functions that compute a value.)",
            "```\nlet mut value_a = None ;\nlet mut value_b = None ;\nlet mut value_c = None ;\nrayon::scope(|s| {\n    s.spawn(|s1| {\n          // ^ this is the same scope as \\`s\\`; this handle \\`s1\\`\n          //   is intended for use by the spawned task,\n          //   since scope handles cannot cross thread boundaries. value_a = Some ( 22 );\n\n        // the scope \\`s\\` will not end until all these tasks are done\n        s1.spawn(| _ | {\n            value_b = Some ( 44 );\n        });\n    });\n\n    s.spawn(| _ | {\n        value_c = Some ( 66 );\n    });\n});\nassert_eq! (value_a, Some ( 22 ));\nassert_eq! (value_b, Some ( 44 ));\nassert_eq! (value_c, Some ( 66 ));\n```",
            "pub struct Scope<'scope> { /* private fields */ }",
            "Expand description",
            "Represents a fork-join scope which can be used to spawn any number of tasks. See [`scope()`](fn.scope.html \"fn rayon::scope\") for more information.",
            "spawn](.spawn)<BODY>(&self, body: BODY) where BODY: [FnOnce](https://doc.rust-lang.org/nightly/core/ops/function/trait.FnOnce.html \"trait core::ops::function::FnOnce\")(&[Scope](struct.Scope.html \"struct rayon::Scope\")<'scope>) + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + 'scope,",
            "Returns\n\nNothing. The spawned closures cannot pass back values to the\ncaller directly, though they can write to local variables on\nthe stack (if those variables outlive the scope) or\ncommunicate through shared channels",
            "This job will\nexecute on each thread sometime before the fork-join scope completes.",
            "let mut value_a = None ;",
            "let mut value_b = None ;",
            "let mut value_c = None ;",
            "    s.spawn(|s1| {",
            "        // the scope \\`s\\` will not end until all these tasks are do",
            "        s1.spawn(| _ | {",
            "            value_b = Some ( 44 );",
            "        });",
            "    s.spawn(| _ | {",
            "        value_c = Some ( 66 );",
            "assert_eq! (value_a, Some ( 22 ));",
            "assert_eq! (value_b, Some ( 44 ));",
            "assert_eq! (value_c, Some ( 66 ));",
            "pub fn [spawn](.spawn) <BODY>(&self, body: BODY)",
            "Scope in rayon - Rust",
            "Links",
            "Repository",
            "https://github.com/rayon-rs/rayon",
            "rayon::scope(|s| {",
            "rayon::scope(|s| {",
            "rayon::scope(|s| {",
            "rayon::scope(|s| {",
            "    });",
            "    });",
            "    });",
            "    });",
            "    });",
            "    });",
            "});",
            "});",
            "});",
            "});",
            "});",
            "Represents a fork-join scope which can be used to spawn any number of tasks. See `scope()` for more information.",
            "```",
            "```"
          ]
        },
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "        });",
            "        });",
            "        }",
            "///",
            "///",
            "///",
            "///",
            "///",
            "///",
            "where",
            "where",
            "where",
            "where",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    where",
            "    {"
          ]
        },
        {
          "title": "rayon_core/scope/mod.rs.html",
          "url": "https://docs.rs/rayon-core/latest/src/rayon_core/scope/mod.rs.html",
          "excerpts": [
            "/// `scope()` is a more flexible building block compared to `join()`, 69 /// since a loop can be used to spawn any number of tasks without 70 /// recursing. However, that flexibility comes at a performance price: 71 /// tasks spawned using `scope()` must be allocated onto the heap, 72 /// whereas `join()` can make exclusive use of the stack. **Prefer 73 /// `join()` (or, even better, parallel iterators) where possible. **",
            "/// The closure given to `scope()` executes in the Rayon thread-pool, 102 /// as do those given to `spawn()`. This means that you can't access 103 /// thread-local variables (well, you can, but they may have 104 /// unexpected values).",
            ".. \nThe spawned closures cannot pass back values to the 475 /// caller directly, though they can write to local variables on 476 /// the stack (if those variables outlive the scope) or 477 /// communicate through shared channels.",
            "Creates a \"fork-join\" scope `s` and invokes the closure with a 62 /// reference to `s`. This closure can then spawn asynchronous tasks 63 /// into `s`. Those tasks may run asynchronously with respect to the 64 /// closure; they may themselves spawn additional tasks into `s`. When 65 /// the closure returns, it will block until all tasks that have been 66 ",
            "st, to reference `bad` we must 209 /// take ownership of it. One way to do this is to detach the closure 210 /// from the surrounding stack frame, using the `move` keyword.",
            " { 196 /// // We can access `ok` because outlives the scope `s`. 197 /// println! (\"ok: {:? }\", ok);",
            "/// unexpected values).",
            "s 275 /// 276 /// If a panic occurs, either in the closure given to `scope()` or in 277 /// any of the spawned jobs, that panic will be propagated and the 278 /// call to `scope()` will panic.",
            "/// let mut result_b: Option<RB> = None;",
            "/// rayon::scope(|s| {",
            " 92 /// s.spawn(|_| result_a = Some(oper_a()));",
            " 93 /// s.spawn(|_| result_b = Some(oper_b()));",
            "/// });",
            "/// (result_a.unwrap(), result_b.unwrap())",
            "/// }",
            "1//! Methods for custom fork-join scopes, created by the [`scope()`] 2//! and [`in_place_scope()`] functions. These are a more flexible alternative to...",
            "///"
          ]
        },
        {
          "title": "scope_fifo in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope_fifo.html",
          "excerpts": [
            "Creates a fork-join scope `s` with FIFO order, and invokes the closure with a reference to `s`. This closure can then spawn asynchronous tasks into `s`.",
            "cription\n\nCreates a fork-join scope `s` with FIFO order, and invokes the\nclosure with a reference to `s` . This closure can then spawn\nasynchronous tasks into `s` . Those tasks may run asynchronously with\nrespect to the closure; they may themselves spawn additional tasks\ninto `s` . When the closure returns, it will block until all tasks\nthat have been spawned into `s` complete.",
            "\nThe various tasks that are run will execute roughly like so:\n\n```notrust\n| (start)\n|\n| (FIFO scope \\`s\\` created)\n+--------------------+ (task s.1)\n+-------+ (task s.2) |\n|       |            +---+ (task s.1.1)\n|       |            |   |\n|       |            |   | (FIFO scope \\`t\\` created)\n|       |            |   +----------------+ (task t.1)\n|       |            |   +---+ (task t.2) |\n| (mid) |            |   |   |            |\n:       |            |   + <-+------------+ (scope \\`t\\` ends)\n:       |            |   |\n|<------+------------+---+ (scope \\`s\\` ends)\n|\n| (end)\n```\n\nUnder `scope_fifo()` , the spawns are prioritized in a FIFO order on\nthe thread from which they were spawned, as opposed to `scope()` s\nLIFO. So in this example, we can expect `s.1` to execute before `s.2` , and `t.1` before `t.2` . Other threads also steal tasks in\nFIFO order, as usual.",
            "If a panic occurs, either in the closure given to `scope_fifo()` or\nin any of the spawned jobs, that panic will be propagated and the\ncall to `scope_fifo()` will panic. If multiple panics occurs, it is\nnon-deterministic which of their panic values will propagate. Regardless, once a task is spawned using `scope.spawn_fifo()`, it\nwill execute, even if the spawning task should later panic. `scope_fifo()` returns once all spawned jobs have completed, and any\npanics are propagated at that point.",
            "rayon::scope_fifo(|s| {\n    s.spawn_fifo(|s| { // task s.1\n        s.spawn_fifo(|s| { // task s.1.1\n            rayon::scope_fifo(|t| {\n                t.spawn_fifo(| _ | ()); // task t.1\n                t.spawn_fifo(| _ | ()); // task t.2\n            });\n        });\n    });\n    s.spawn_fifo(|s| { // task s.2\n    });\n    // point mid\n});"
          ]
        },
        {
          "title": "rayon-rs - GitHub",
          "url": "https://github.com/rayon-rs",
          "excerpts": [
            "rayon-rs has 5 repositories available. Follow their code on GitHub."
          ]
        },
        {
          "title": "mod.rs source code [crates/rustc-rayon-core-0.5.0/src/scope/mod.rs ...",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/scope/mod.rs.html",
          "excerpts": [
            "/// Represents a fork-join scope which can be used to spawn any number of tasks.  /// Those spawned from the same thread are prioritized in ... /// Represents a fork-join scope which can be used to spawn any number of tasks.  /// Those spawned from the same thread are prioritized in relative FIFO order."
          ]
        },
        {
          "title": "spawn in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.spawn.html",
          "excerpts": [
            "Puts the task into the Rayon thread pool's job queue in the static or global scope. Just like a standard thread, this task is not tied to the current ...",
            "spawn in rayon - Rust",
            "Puts the task into the Rayon thread pools job queue in the static\nor global scope. Just like a standard thread, this task is not\ntied to the current stack frame, and hence it cannot hold any\nreferences other than those with `'static` lifetime. If you want\nto spawn a task that references stack data, use [the `scope()`\nfunction](fn.scope.html \"fn rayon::scope\") to create a scope. Since tasks spawned with this function cannot hold references into\nthe enclosing stack frame, you almost certainly want to use a\n`move` closure as their argument (otherwise, the closure will\ntypically hold references to any variables from the enclosing\nfunction that you happen to use). This API assumes that the closure is executed purely for its\nside-effects (i.e., it might send messages, modify data protected\nby a mutex, or some such thing). There is no guaranteed order of execution for spawns, given that\nother threads may steal tasks at any time. However, they are\ngenerally prioritized in a LIFO order on the thread from which\nthey were spawned. Other threads always steal from the other end of\nthe deque, like FIFO order.\nThe idea is that recent tasks are\nmost likely to be fresh in the local CPUs cache, while other\nthreads can steal older stale tasks. For an alternate approach,\nconsider [`spawn_fifo()`](fn.spawn_fifo.html \"fn rayon::spawn_fifo\") instead.",
            ". If you want\nto spawn a task that references stack data, use [the `scope()`\nfunction](fn.scope.html \"fn rayon::scope\") to create a scope.",
            "This API assumes that the closure is executed purely for its\nside-effects (i.e., it might send messages, modify data protected\nby a mutex, or some such thing).",
            "There is no guaranteed order of execution for spawns, given that\nother threads may steal tasks at any time.",
            "For an alternate approach,\nconsider [`spawn_fifo()`](fn.spawn_fifo.html \"fn rayon::spawn_fifo\") instead.",
            "static GLOBAL_COUNTER: AtomicUsize = ATOMIC_USIZE_INIT;\n\nrayon::spawn(move || {\n    GLOBAL_COUNTER.fetch_add(1, Ordering::SeqCst);\n});",
            "If you want to spawn a task that references stack data, use the scope() function to create a scope. Since tasks spawned with this function cannot hold..."
          ]
        },
        {
          "title": "mod.rs - source",
          "url": "https://rust-lang.github.io/hashbrown/src/rayon_core/scope/mod.rs.html",
          "excerpts": [
            "Methods for custom fork-join scopes, created by the [`scope()`] //! function. These are a more flexible alternative to [`join()`]."
          ]
        },
        {
          "title": "in_place_scope in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.in_place_scope.html",
          "excerpts": [
            "Creates a fork-join scope `s` and invokes the closure with a reference to `s`. This closure can then spawn asynchronous tasks into `s`."
          ]
        },
        {
          "title": "in_place_scope in rayon - Rust",
          "url": "https://strawlab.org/strand-braid-api-docs/latest/rayon/fn.in_place_scope.html",
          "excerpts": [
            "Creates a fork-join scope `s` and invokes the closure with a reference to `s`. This closure can then spawn asynchronous tasks into `s`."
          ]
        },
        {
          "title": "ScopeFifo in rayon - Rust",
          "url": "https://difftastic.wilfred.me.uk/rustdoc/rayon/struct.ScopeFifo.html",
          "excerpts": [
            "Represents a fork-join scope which can be used to spawn any number of tasks. Those spawned from the same thread are prioritized in relative FIFO order."
          ]
        },
        {
          "title": "I dont understand 'borrowed value does not live long enough'",
          "url": "https://www.reddit.com/r/rust/comments/1fu6in8/i_dont_understand_borrowed_value_does_not_live/",
          "excerpts": [
            "thread::spawn always borrows variables as 'static . ... Check out std::thread::scope and rayon for examples of ways around this problem."
          ]
        },
        {
          "title": "rust - Borrowed value does not live long enough in testing methods",
          "url": "https://stackoverflow.com/questions/71453899/borrowed-value-does-not-live-long-enough-in-testing-methods",
          "excerpts": [
            "Scoped threads allow us to share non- 'static data at the cost of our threads be forced to finish before we return (it'll join() implicitly ..."
          ]
        },
        {
          "title": "rayon_core::spawn - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon_core/fn.spawn.html",
          "excerpts": [
            "If you want to spawn a task that references stack data, use the scope() function to create a scope. Since tasks spawned with this function cannot hold..."
          ]
        },
        {
          "title": "vendor/rayon-0.8.2 - chromiumos/third_party/rust_crates",
          "url": "https://chromium.googlesource.com/chromiumos/third_party/rust_crates/+/refs/heads/firmware-skywalker-16378.B/vendor/rayon-0.8.2/",
          "excerpts": [
            "Quick demo. To see Rayon in action, check out the rayon-demo directory, which includes a number of demos of code using Rayon. For example, run this command..."
          ]
        },
        {
          "title": "Scope in crossbeam::thread - Rust",
          "url": "https://docs.rs/crossbeam/latest/crossbeam/thread/struct.Scope.html",
          "excerpts": [
            "The difference is that this thread is scoped, meaning it's guaranteed to terminate before the scope exits, allowing it to reference variables outside the scope."
          ]
        },
        {
          "title": "crossbeam::Scope - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/master/crossbeam/struct.Scope.html",
          "excerpts": [
            "The difference is that this thread is scoped, meaning that it's guaranteed to terminate before the current stack frame goes away, allowing you to reference..."
          ]
        },
        {
          "title": "scope in crossbeam - Rust",
          "url": "https://docs.rs/crossbeam/*/crossbeam/fn.scope.html",
          "excerpts": [
            "Creates a new scope for spawning threads. All child threads that haven't been manually joined will be automatically joined just before this function..."
          ]
        },
        {
          "title": "How to wait all spawn jobs using rayon? - code review",
          "url": "https://users.rust-lang.org/t/how-to-wait-all-spawn-jobs-using-rayon/83899",
          "excerpts": [
            "Nov 7, 2022  This solution has one problem: the function will return when jobs are submitted, not the time they are finished. So I have to add a condition var to notify..."
          ]
        },
        {
          "title": "Advanced Concurrency in Rust: Exploring Parallelism with ...",
          "url": "https://codedamn.com/news/rust/advanced-concurrency-rust-exploring-parallelism-rayon",
          "excerpts": [
            "Mar 25, 2023  In this example, we create a new parallel scope using rayon::scope . Inside the scope, we iterate over the indices and elements of the input..."
          ]
        },
        {
          "title": "crossbeam-rs/crossbeam: Tools for concurrent programming in Rust",
          "url": "https://github.com/crossbeam-rs/crossbeam",
          "excerpts": [
            "This crate provides a set of tools for concurrent programming: Atomics, Data structures, Memory management, Thread synchronization, Utilities."
          ]
        },
        {
          "title": "Which async/concurrency crate to choose from? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/djzd5t/which_asyncconcurrency_crate_to_choose_from/",
          "excerpts": [
            "Crossbeam provides building blocks, such as various types of channels, a work-stealing deque (double-ended queue), and scope as a nice way to ..."
          ]
        },
        {
          "title": "Is it possible to combine Rayon and Faster? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/51253203/is-it-possible-to-combine-rayon-and-faster",
          "excerpts": [
            "Rayon looks great for algorithm parallelization of collections, and Faster is great for vectorization (SIMD) on the x86 platform for collections ...",
            "You can just use Rayon's par_chunks and process each chunk with Faster. let lots_of_3s = (&[-123.456f32; 1000000][..]) .par_chunks(128) ."
          ]
        },
        {
          "title": "Windows in rayon::slice - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/slice/struct.Windows.html",
          "excerpts": [
            "Collects the results of the iterator into the specified vector. The vector is always cleared before execution begins. If possible, reusing the vector across ...",
            "The type of item that this parallel iterator produces. For example, if you use the for_each method, this is the type of item that your closure will be invoked ..."
          ]
        },
        {
          "title": "How do I parallelise this loop with Rayon? (iteration by non ...",
          "url": "https://users.rust-lang.org/t/how-do-i-parallelise-this-loop-with-rayon-iteration-by-non-contigous-blocks/123664",
          "excerpts": [
            "Rayon does have par_chunks() , which allows you to iterate by chunks, but the problem is that in my case the chunks are non-contiguous, so I ..."
          ]
        },
        {
          "title": "ParallelSliceMut in rayon::slice - Rust",
          "url": "https://diem.github.io/diem-devtools/rustdoc/rayon/slice/trait.ParallelSliceMut.html",
          "excerpts": [
            "All other chunks will have that exact length. Examples. use rayon::prelude::*; let mut array = [1, 2, 3, 4, 5]; array.par_chunks_mut(2) .for_each(|slice| slice."
          ]
        },
        {
          "title": "ParallelSliceMut in rayon::slice - Rust",
          "url": "https://doc.servo.org/rayon/slice/trait.ParallelSliceMut.html",
          "excerpts": [
            "Returns a parallel iterator over mutable subslices separated by elements that match the separator. Examples. use rayon::prelude::*; let mut array..."
          ]
        },
        {
          "title": "Rayon sequential dependency between parallel calculations",
          "url": "https://users.rust-lang.org/t/rayon-sequential-dependency-between-parallel-calculations/55649",
          "excerpts": [
            "Feb 15, 2021  Rayon's parallel iterators work great when each calculation is independent from every other calculation. For example ... par_windows(2) //..."
          ]
        },
        {
          "title": "Parallelism, choosing between or combining Rayon and SIMD",
          "url": "https://users.rust-lang.org/t/parallelism-choosing-between-or-combining-rayon-and-simd/46700",
          "excerpts": [
            "By a simple change of \".windows\" to \".par_windows\" it spreads the work over multiple cores and in my tests scales linearly to at least 8 cores ( ... Aug 1, 2020  windows\" to \".par_windows\" it spreads the work over multiple cores and in my tests scales linearly to at least 8 cores (Wish I had more). And..."
          ]
        },
        {
          "title": "Implement `chunks`  Issue #501  rayon-rs/rayon",
          "url": "https://github.com/rayon-rs/rayon/issues/501",
          "excerpts": [
            "Dec 29, 2017  Right now if I have a slice I can do: slice.par_chunks(500).... but if I have an iterator I can't chunk it: (0..100000).par_chunks(500)."
          ]
        },
        {
          "title": "Usage with Read or Iterator as provider?  Issue #46",
          "url": "https://github.com/rayon-rs/rayon/issues/46",
          "excerpts": [
            "Feb 5, 2016  I see that only ranges and slices can be converted into parallel iterators. i wonder how to best utilize rayon while reading from a file.",
            "I see that only ranges and slices can be converted into parallel iterators. i wonder how to best utilize rayon while reading from a file."
          ]
        },
        {
          "title": "MinLen in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.MinLen.html",
          "excerpts": [
            "MinLen is an iterator that imposes a minimum length on iterator splits. This struct is created by the with_min_len() method on IndexedParallelIterator.",
            "#### fn [with\\_min\\_len](trait.IndexedParallelIterator.html.with_min_len) (self, min: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [MinLen](struct.MinLen.html \"struct rayon::iter::MinLen\") <Self>\n\nSets the minimum length of iterators desired to process in each\nrayon job. Rayon will not split any smaller than this length, but\nof course an iterator could already be smaller to begin with.",
            "#### fn [with\\_max\\_len](trait.IndexedParallelIterator.html.with_max_len) (self, max: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [MaxLen](struct.MaxLen.html \"struct rayon::iter::MaxLen\") <Self>\n\nSets the maximum length of iterators desired to process in each\nrayon job. Rayon will try to split at least below this length,\nunless that would put it below the length from `with_min_len()` . For example, given min=10 and max=15, a length of 16 will not be\nsplit any further.",
            "#### fn [chunks](trait.IndexedParallelIterator.html.chunks) (self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::iter::Chunks\") <Self>",
            "Sets the maximum length of iterators desired to process in each\nrayon job. Rayon will try to split at least below this length,\nunless that would put it below the length from `with_min_len()`.",
            "ks)\n\n[Source](../../src/rayon/iter/mod.rs.html) [](.fold_chunks)"
          ]
        },
        {
          "title": "rayon::slice::ParallelSlice - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            "Returns a plain slice, which is used to implement the rest of the parallel methods. Provided methods. fn par_split<P>(&self, separator: P) -> Split<'_, T, ..."
          ]
        },
        {
          "title": "with_min_len/with_max_len doesn't work with u64 ranges because ...",
          "url": "https://github.com/rayon-rs/rayon/issues/359",
          "excerpts": [
            "Jun 8, 2017  with_min_len/with_max_len doesn't work with u64 ranges because they don't implement the indexed trait  Issue #359  rayon-rs/rayon.",
            "On the hand, Rayon, unlike the standard library, uses it to split the iterator, and here u64 makes sense, since a 32-bit program can still ...",
            "Jun 8, 2017  with_min_len/with_max_len doesn't work with u64 ranges because they don't implement the indexed trait  Issue #359  rayon-rs/rayon. On the hand, Rayon, unlike the standard library, uses it to split the iterator, and here u64 makes sense, since a 32-bit program can still ..."
          ]
        },
        {
          "title": "How to obtain the chunk index in Rayon's par_chunks_mut",
          "url": "https://stackoverflow.com/questions/61230633/how-to-obtain-the-chunk-index-in-rayons-par-chunks-mut",
          "excerpts": [
            "The easiest thing to do is avoid the need for an index at all. For this example, we can just zip the iterators."
          ]
        },
        {
          "title": "Parallel Matrix Multiplication in Rayon Rust",
          "url": "https://roclocality.org/2024/04/15/parallel-matrix-multiplication-in-rayon-rust/",
          "excerpts": [
            "By using par_chunks_mut , we can divide the matrix c into n distinct, separate sections, with each section smaller than or equal to n . Rayon ..."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. ##### []",
            "pub trait IndexedParallelIterator: ParallelIterator {",
            "    fn len (&self) -> usize ;",
            "    fn drive <C: Consumer <Self:: Item >>(self, consumer: C) -> C:: Result ;",
            "    fn by_uniform_blocks (self, block_size: usize ) -> UniformBlocks <Self> { ... }",
            "        self,",
            "    fn with_producer <CB: ProducerCallback <Self:: Item >>(\n        self,\n        callback: CB,\n    ) -> CB:: Output ;",
            "    fn by_exponential_blocks (self) -> ExponentialBlocks <Self> { ... }",
            "    fn collect_into_vec (self, target: &mut Vec <Self:: Item >) { ... }",
            "fn unzip_into_vecs<A, B>(self, left: &mut Vec<A>, right: &mut Vec<B>)",
            "       where Self: IndexedParallelIterator<Item = (A, B)>,",
            "             A: Send,",
            "    fn unzip_into_vecs <A, B>(self, left: &mut Vec <A>, right: &mut Vec <B>)\n       where Self: IndexedParallelIterator <Item = (A, B) >,\n             A: Send ,\n             B: Send { ... }",
            "fn zip<Z>(self, zip_op: Z) -> Zip<Self, Z::Iter>",
            "    fn zip <Z>(self, zip_op: Z) -> Zip <Self, Z:: Iter >\n       where Z: IntoParallelIterator <Iter: IndexedParallelIterator > { ... }",
            "fn zip_eq<Z>(self, zip_op: Z) -> ZipEq<Self, Z::Iter>",
            "    fn zip_eq <Z>(self, zip_op: Z) -> ZipEq <Self, Z:: Iter >\n       where Z: IntoParallelIterator <Iter: IndexedParallelIterator > { ... }",
            "fn interleave<I>(self, other: I) -> Interleave<Self, I::Iter>",
            "    fn interleave <I>(self, other: I) -> Interleave <Self, I:: Iter >\n       where I: IntoParallelIterator <Item = Self:: Item , Iter: IndexedParallelIterator > { ... }",
            "    fn interleave_shortest <I>(\n        self,\n        other: I,\n    ) -> InterleaveShortest <Self, I:: Iter >\n       where I: IntoParallelIterator <Item = Self:: Item , Iter: IndexedParallelIterator > {",
            "       where I: IntoParallelIterator<Item = Self::Item, Iter: IndexedParallelIterator> { ... }",
            "fn enumerate(self) -> Enumerate<Self> { ... }",
            "fn position_any<P>(self, predicate: P) -> Option<usize>",
            "fn position_first<P>(self, predicate: P) -> Option<usize>",
            "fn position_last<P>(self, predicate: P) -> Option<usize>",
            "fn positions<P>(self, predicate: P) -> Positions<Self, P>",
            "       where P: Fn(Self::Item) -> bool + Sync + Send { ... }",
            "       where P: Fn(Self::Item) -> bool + Sync + Send { ... }",
            "       where P: Fn(Self::Item) -> bool + Sync + Send { ... }",
            "       where P: Fn(Self::Item) -> bool + Sync + Send { ... }",
            "fn rev(self) -> Rev<Self> { ... }",
            "fn with_min_len(self, min: usize) -> MinLen<Self> { ... }",
            "fn with_max_len(self, max: usize) -> MaxLen<Self> { ... }",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.",
            "<Self>\n\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.\nThis means that if two threads are used there will be **no** speedup **at\nall** . `by_exponential_blocks` on the other hand will start with the leftmost range from 0\nto `p` (threads number), continue with p to 3p, the 3p to 7p\n\nEach subrange is treated in parallel, while all subranges are treated sequentially. We therefore ensure a logarithmic number of blocks (and overhead) while guaranteeing\nwe stop at the first block containing the searched data. [Source](../../src/rayon/iter/mod.rs.html)\n",
            "    // Provided methods",
            "The main application is to obtain better memory locality (especially if the reduce operation re-use folded data). Panics if block_size is 0. Example. use rayon...",
            "Yields an index along with each item.",
            "Produces a new iterator with the elements of this iterator in\nreverse order.",
            " ;\n\nlet result: Vec< _ > = ( 0 .. 5 )\n    .into_par_iter()\n    .rev()\n    .collect();\n\nassert_eq! (result, [ 4 , 3 , 2 , 1 , 0 ]);\n```",
            ")\n\n#### fn [with\\_min\\_len](.with_min_len) (self, min: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [MinLen](struct.MinLen.html \"struct rayon::iter::MinLen\") <Self>\n\nSets the minimum length of iterators desired to process in each\nrayon job. Rayon will not split any smaller than this length, but\nof course an iterator could already be smaller to begin with. Producers like `zip` and `interleave` will use greater of the two\nminimums. Chained iterators and iterators inside `flat_map` may each use\ntheir own minimum length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\n\nlet min = ( 0 .. 1_000_000 )\n    .into_par_iter()\n    .with_min_len( 1234 )\n    .fold(|| 0 , |acc, _ | acc + 1 ) // count how many are in this segment\n    .min().unwrap();\n\nassert!\n(min >= 1234 );\n```\n\n[Source](../../src/rayon/iter/mod.rs.html)",
            "ml)\n\n#### fn [with\\_max\\_len](.with_max_len) (self, max: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [MaxLen](struct.MaxLen.html \"struct rayon::iter::MaxLen\") <Self>\n\nSets the maximum length of iterators desired to process in each\nrayon job. Rayon will try to split at least below this length,\nunless that would put it below the length from `with_min_len()` . For example, given min=10 and max=15, a length of 16 will not be\nsplit any further. Producers like `zip` and `interleave` will use lesser of the two\nmaximums. Chained iterators and iterators inside `flat_map` may each use\ntheir own maximum length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\n\nlet max = ( 0 .. 1_000_000 )\n    .into_par_iter()\n    .with_max_len( 1234 )\n    .fold(|| 0 , |acc, _ | acc + 1 ) // count how many are in this segment\n    .max().unwrap();\n\nassert! (max <= 1234 );\n```\n\n## Dyn Compatibility []()\n\nThis trait is",
            "For example, given min=10 and max=15, a length of 16 will not be\nsplit any further.",
            "fn with_min_len (self, min: usize ) -> MinLen <Self> { ... }",
            "fn with_max_len (self, max: usize ) -> MaxLen <Self> { ... }",
            "\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.",
            "nd\") ,\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. ",
            "Searches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice.",
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "[Source](../../src/rayon/iter/mod.rs.html)",
            "let a = [ 1 , 2 , 3 , 3 ];",
            "let i = a.par_iter().position_any(| & x| x == 3 ).expect( \"found\" );",
            "assert! (i == 2 || i == 3 );",
            "assert_eq!\n(a.par_iter().position_first(| & x| x == 3 ), Some ( 2 ));",
            "assert_eq! (a.par_iter().position_last(| & x| x == 3 ), Some ( 3 ));",
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points."
          ]
        },
        {
          "title": "Rayon Documentation: Iteration and Parallel Iterators",
          "url": "https://docs.rs/rayon/latest/rayon/iter/index.html",
          "excerpts": [
            "[Source](../../src/rayon/iter/mod.rs.html)",
            "Parallel Bridge",
            "FoldChunks is an iterator that groups elements of an underlying iterator and applies a function over them, producing a single value for each group."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Collects the results of the iterator into the specified vector. The vector is always truncated before execution begins. If possible, reusing the vector across ...",
            "Examples. use rayon::prelude::*; let par_iter = (0..100).into_par_iter().zip(vec![0; 10]); assert_eq!(par_iter.len(), 10); let vec: Vec<_> = par_iter. Like the zip method on ordinary iterators, if the two iterators are of unequal length, you only get the items they have in common.",
            "### `fn [positions](.positions) <P>(self, predicate: P) -> [Positions](struct.Positions.html \"struct rayon::iter::Positions\") <Self, P> where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for items in the parallel iterator that match the given\npredicate, and returns their indices. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let primes = vec! [ 2 , 3 , 5 , 7 , 11 , 13 , 17 , 19 , 23 , 29 ];\n\n // Find the positions of primes congruent to 1 modulo 6 \n let p1mod6 : Vec < _ > = primes . par_iter (). positions ( | & p | p % 6 = = 1 ). collect ();\n assert_eq! ( p1mod6 , [ 3 , 5 , 7 ]); // primes 7, 13, and 19 \n\n // Find the positions of primes congruent to 5 modulo 6 \n let p5mod6 : Vec < _ > = primes . par_iter (). positions ( | & p | p % 6 = = 5 ).",
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```",
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_last](.position_last) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.\n# [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 3 ), Some ( 3 ));\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 100 ), None );\n```\n"
          ]
        },
        {
          "title": "Shared state concurrency help -- rayon",
          "url": "https://users.rust-lang.org/t/shared-state-concurrency-help-rayon/73032",
          "excerpts": [
            "Mar 15, 2022  I am trying to implement a density matrix simulator of a quantum computer. The quantum gates that act of the qubit density matrix state do..."
          ]
        },
        {
          "title": "What is the advantage of using a stable sort algorithm vrs an ...",
          "url": "https://stackoverflow.com/questions/58522500/what-is-the-advantage-of-using-a-stable-sort-algorithm-vrs-an-unstable-sort-usin",
          "excerpts": [
            "Except for cache effects, stable sorts are generally faster than unstable sorts when they are allowed to use extra memory."
          ]
        },
        {
          "title": "Stable and unstable sorting algorithms - Educative.io",
          "url": "https://www.educative.io/answers/stable-and-unstable-sorting-algorithms",
          "excerpts": [
            "Stable sorting algorithms preserve the order of equal elements, crucial for data consistency, unlike unstable ones, which prioritize performance."
          ]
        },
        {
          "title": "Ordering question  Issue #551  rayon-rs/rayon - GitHub",
          "url": "https://github.com/rayon-rs/rayon/issues/551",
          "excerpts": [
            "I was just wondering: Do the Rayon parallel iterators preserve ordering? For example, if I have vec![obj1, obj2, obj3].par_iter().map(|o| ... Mar 8, 2018  I was just wondering: Do the Rayon parallel iterators preserve ordering? For example, if I have vec![obj1, obj2, obj3].par_iter().map(|o|...",
            "I was just wondering: Do the Rayon parallel iterators preserve ordering? For example, if I have\nvec! [obj1, obj2, obj3].par_iter().map(|o| { operation_on(o) }) , can I assume that the resulting iterator has the corresponding map results in the same order as in the\nvec! ?",
            "Ordering question  #55",
            "Mar 8, 2018  I was just wondering: Do the Rayon parallel iterators preserve ordering? For example, if I have vec![obj1, obj2, obj3].par_iter().map(|o|...",
            "Mar 8, 2018  I was just wondering: Do the Rayon parallel iterators preserve ordering? For example, if I have vec![obj1, obj2, obj3].par_iter().map(|o|... I was just wondering: Do the Rayon parallel iterators preserve ordering? For example, if I have vec![obj1, obj2, obj3].par_iter().map(|o| ...",
            "I was just wondering: Do the Rayon parallel iterators preserve ordering? For example, if I have vec![obj1, obj2, obj3].par_iter().map(|o| ..."
          ]
        },
        {
          "title": "rayon::slice::ParallelSliceMut - Rust - Will Usher",
          "url": "https://www.willusher.io/tray_rust/rayon/slice/trait.ParallelSliceMut.html",
          "excerpts": [
            "See par_sort_unstable_by_key . Current implementation. The current algorithm is an adaptive merge sort inspired by timsort. It is designed to be very fast in ... It is designed to be very fast in cases where the slice is nearly sorted, or consists of two or more sorted sequences concatenated one after another."
          ]
        },
        {
          "title": "Trait ParallelSliceMut - prelude::cara::rayon - cellular-raza.com",
          "url": "https://www.cellular-raza.com/docs/cellular_raza/prelude/cara/rayon/prelude/trait.ParallelSliceMut.html",
          "excerpts": [
            "Due to its key calling strategy, par_sort_unstable_by_key is likely to be slower than par_sort_by_cached_key in cases where the key function is expensive. All ..."
          ]
        },
        {
          "title": "New Rayon release! - announcements - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/new-rayon-release/11591",
          "excerpts": [
            "par_sort , par_sort_by , and par_sort_by_key perform stable sorts in parallel, using the default order, a custom comparator, or a key extraction"
          ]
        },
        {
          "title": "Issues  rayon-rs/rayon - GitHub",
          "url": "https://github.com/rayon-rs/rayon/issues",
          "excerpts": [
            "Rayon: A data parallelism library for Rust. Contribute to rayon-rs/rayon development by creating an account on GitHub."
          ]
        },
        {
          "title": "Pull requests  rayon-rs/rayon - GitHub",
          "url": "https://github.com/rayon-rs/rayon/pulls",
          "excerpts": [
            "Rayon: A data parallelism library for Rust. Contribute to rayon-rs/rayon development by creating an account on GitHub."
          ]
        },
        {
          "title": "rayon - Rust",
          "url": "https://docs.rs/rustc-rayon/",
          "excerpts": [
            "The par_sort method sorts &mut [T] slices (or vectors) in parallel. par_extend can be used to efficiently grow collections with items produced by a parallel...",
            "The IndexedParallelIterator trait adds methods for iterators that support ... Those spawned from the same thread are prioritized in relative FIFO order."
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "... ParallelSliceMut.html#method.par_sort //! [`par_extend`]: iter/trait.ParallelExtend.html#tymethod.par_extend //! [`ThreadPoolBuilder`]: struct...",
            "- **High-level parallel constructs** are the simplest way to use Rayon and also\n//! typically the most efficient. //! - [Parallel iterators] make it easy to convert a sequential iterator to\n//! execute ",
            "Next, to use parallel iterators or the other high-level methods,\n//! you need to import several traits. Those traits are bundled into\n//! the module [`rayon::prelude`]. It is recommended that you import\n//! all of these traits at once by adding `use rayon::prelude::*` at\n//! the top of each module that use",
            "These traits give you access to the `par_iter` method which provides\n//! parallel implementations of many iterative functions such as [`map`],\n//! [`for_each`], [`filter`], [`fold`], and",
            " crate mirror [`std`] itself: so, e.g., the `option` module in\n//! Rayon contains parallel iterators for the `Option` type, which is\n//! found in [the `option` module of `std`]. Similarly, the\n//! `collections` module in Rayon offers parallel iterator types for\n//! [the `collections` fro",
            "Rayon extends many of the types found in the standard library with\n//! parallel iterator implementati",
            "`\n//! Rayon is a data-parallelism library that makes it easy to convert sequential\n//! computations into parallel. //! //! It is lightweight and convenient for introducing parallelism into existing",
            "//! # Basic usage and the Rayon prelude",
            "//! First, you will need to add `rayon` to your `Cargo.toml`. //!",
            "//! Next, to use parallel iterators or the other high-level methods,\n//! you need to import several tra",
            " Those traits are bundled into\n//! the module [`rayon::prelude`]. It is recommended that you import\n//! all of these traits at once by adding `use rayon::prelude::*` at\n//! the top of each module that uses Rayon",
            "//! These traits give you access to the `par_iter` method which provides\n//! parallel implementations of many iterative functions such as [`map`],\n//! [`for_each`], [`filter`], [`fold`], and",
            "/// We need to transmit raw pointers across threads.\nIt is possible to do this\n/// without any unsafe code by converting pointers to usize or to AtomicPtr<T>\n/// then back to a raw pointer for use. We prefer this approach because code\n/// that uses this type is more e",
            "unsafe impl<T: Send> Send for SendPtr<T> {}",
            "unsafe impl<T: Send> Sync for SendPtr<T> {}",
            "impl<T> SendPtr<T> {",
            "    // Helper to avoid disjoint captures of `send_ptr.0`",
            "    fn get(self) -> *mut T {",
            "        self.0",
            "// Implement Clone without the T: Clone bound from the derive",
            "impl<T> Clone for SendPtr<T> {",
            "    fn clone(&self) -> Self {",
            "        *self",
            "// Implement Copy without the T: Copy bound from the derive",
            "impl<T> Copy for SendPtr<T> {}",
            "There are two ways to use Rayon:",
            "    }",
            "    }",
            "}",
            "}"
          ]
        },
        {
          "title": "Parallel Quick Sort in Rust - help",
          "url": "https://users.rust-lang.org/t/parallel-quick-sort-in-rust/33995",
          "excerpts": [
            "`rayon: par_sort_unstable` provides a parallel quick sort. Parallel partition may not reduce asymptotic time, and may not be faster for normal ... Oct 26, 2019  `rayon: par_sort_unstable` provides a parallel quick sort. Parallel partition may not reduce asymptotic time, and may not be faster for normal..."
          ]
        },
        {
          "title": "2.2.- pdqsort - Boost",
          "url": "https://www.boost.org/doc/libs/1_82_0/libs/sort/doc/html/sort/single_thread/pdqsort.html",
          "excerpts": [
            "Pattern-defeating quicksort (pdqsort) is a novel sorting algorithm that combines the fast average case of randomized quicksort with the fast worst case of ..."
          ]
        },
        {
          "title": "orlp/pdqsort: Pattern-defeating quicksort. - GitHub",
          "url": "https://github.com/orlp/pdqsort",
          "excerpts": [
            "pdqsort is a novel sorting algorithm that combines the fast average case of randomized quicksort with the fast worst case of heapsort."
          ]
        },
        {
          "title": "Bad performance with rayon? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/bad-performance-with-rayon/81290",
          "excerpts": [
            "Parallel execution has a lot of overhead, summing a small list of numbers isn't a big enough task to pass the threshold where that overhead is smaller than the ..."
          ]
        },
        {
          "title": "How Rust supports Rayon's data parallelism - Red Hat Developer",
          "url": "https://developers.redhat.com/blog/2021/04/30/how-rust-makes-rayons-data-parallelism-magical",
          "excerpts": [
            "Rayon is a data parallelism library for the Rust programming language. Common reactions from programmers who start to use Rayon express how it seems magical.",
            "Apr 30, 2021  You could solve this by using an atomic type for total , or by using Rayon's built-in parallel sum() or your own custom fold+reduce on the... Rayon is a data parallelism library for the Rust programming language. Common reactions from programmers who start to use Rayon express how it seems magical.",
            "Apr 30, 2021  You could solve this by using an atomic type for total , or by using Rayon's built-in parallel sum() or your own custom fold+reduce on the...",
            "foo_vector.par_iter_mut()",
            "cannot assign to \\`total\\`, as it is a captured variable in a \\`Fn\\` clo",
            "Rayon requires `Fn` here, that gets locked in by the compiler",
            "Rayon can make it really easy to dip your toes into parallelism",
            "only has to specify its constraints. The parallel iterators and their items have to implement `Send",
            "The parallel iterators and their items have to implement `Send` , simply because they will be sent between threads."
          ]
        },
        {
          "title": "How to improve parallelism with Rayon and reduce waiting time?",
          "url": "https://www.reddit.com/r/rust/comments/uadc9f/how_to_improve_parallelism_with_rayon_and_reduce/",
          "excerpts": [
            "If you can determine that a slice is going to require a lot of calculation, then you may be able to do sub-parallelization within draw_slice().",
            "I'm writing a raycaster game in which I need to draw pixel by pixel an rgba image and display it, and since every column is independent from each other I can..."
          ]
        },
        {
          "title": "C++ Benchmark: Timsort vs pdqsort vs quadsort vs std::stable_sort",
          "url": "https://www.reddit.com/r/cpp/comments/fgxfqa/c_benchmark_timsort_vs_pdqsort_vs_quadsort_vs/",
          "excerpts": [
            "Keep in mind that on the generic order test pdqsort and ska_sort are faster specifically because they are unstable. The random 1-1023 test ..."
          ]
        },
        {
          "title": "ParallelSliceMut in cellular_raza::prelude - rayon - cellular-raza.com",
          "url": "https://www.cellular-raza.com/docs/cellular_raza/prelude/cara/rayon/slice/trait.ParallelSliceMut.html",
          "excerpts": [
            "Sorts the slice in parallel with a comparator function. This sort is stable (i.e., does not reorder equal elements) and O(n * log(n)) worst-case. The comparator ... Returns a parallel iterator over mutable subslices separated by elements that match the separator, including the matched part as a terminator. Examples. use..."
          ]
        },
        {
          "title": "Rayon gets parallel sorts (benchmark against Java and C++) - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/6jt4l9/rayon_gets_parallel_sorts_benchmark_against_java/",
          "excerpts": [
            "There is a cost associated with this, but it's pretty low overhead ... sort 7046 ms sort_unstable 3897 ms par_sort 1598 ms par_sort_unstable 1045 ..."
          ]
        },
        {
          "title": "Why is rust's rayon taking longer with Arc<Mutex<anyhow",
          "url": "https://stackoverflow.com/questions/75831833/why-is-rusts-rayon-taking-longer-with-arcmutexanyhowresult",
          "excerpts": [
            "Using `Arc<Mutex>` with `rayon` causes a bottleneck because locking serializes the push, making threads wait. Using `.collect()` avoids this.",
            "I am trying to parallelize my codes using the crate rayon. The process is to read a file, process it and output the processed file."
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "**NOTE**: The requested URLs (https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs, https://github.com/rayon-rs/rayon/blob/main/src/iter/par_extend.rs, and https://github.com/rayon-rs/rayon/blob/main/src/iter/mod.rs) could not be retrieved or parsed in this step, so no new findings about FromParallelIterator/ParallelExtend documentation or patterns could be extracted from these sources in this attempt.",
            "fn collect\\_extended<C, I>(par\\_iter: I) ->",
            "I: IntoParallelIterator,",
            "C: ParallelExtend<I::Item> + Default,",
            "let mut collection = C::default();",
            "collection.par\\_extend(par\\_iter",
            "Collection",
            "/// Collects items from a parallel iterator into a vector.",
            "impl<T> FromParallelIterator<T> for Vec<T>",
            "/// Collects items from a parallel iterator into a boxed slice.",
            "impl<T> FromParallelIterator<T> for Box<[T]>",
            "impl<T> FromParallelIterator<T> for Rc<[T]>",
            "/// Collects items from a parallel iterator into an atomically-reference-counted slice.",
            "impl<T> FromParallelIterator<T> for Arc<[T]>",
            "/// Collects items from a parallel iterator into a vecdeque.",
            "impl<T> FromParallelIterator<T> for VecDeque<T>",
            "/// Collects items from a parallel iterator into a binaryheap.",
            "/// The heap-ordering is calculated serially after all items are collected.",
            "impl<T> FromParallelIterator<T> for BinaryHeap<T>",
            "T: Ord + Send,",
            "Vec::from\\_par\\_iter(par\\_iter).int",
            "Vec::from\\_par\\_iter(par\\_iter).int",
            "Vec::from\\_par\\_iter(par\\_iter).int",
            "Vec::from\\_par\\_iter(par\\_iter).int",
            "Vec::from\\_par\\_iter(par\\_iter).int",
            "impl<T> FromParallelIterator<T> for LinkedList<T>",
            "impl<K, V, S> FromParallelIterator<(K, V)> for HashMap<K, V, S>",
            "K: Eq + Hash + Send,",
            "/// overwritten, just as with a sequential iterator.",
            "/// overwritten, just as with a sequential iterator.",
            "impl<K, V> FromParallelIterator<(K, V)> for BTreeMap<K, V>",
            "K: Ord + Send,",
            "V: Send,",
            "V: Send,",
            "I: IntoParallelIterator<Item = (K, V)>,",
            "I: IntoParallelIterator<Item = (K, V)>,",
            "impl<V, S> FromParallelIterator<V> for HashSet<V, S>",
            "V: Eq + Hash + Send,",
            "S: BuildHasher + Default + Send,",
            "S: BuildHasher + Default + Send,",
            "/// Collects values from a parallel iterator into a btreeset.",
            "impl<V> FromParallelIterator<V> for BTreeSet<V>",
            "V: Send + Ord,",
            "I: IntoParallelIterator<Item = V>,",
            "I: IntoParallelIterator<Item = V>,",
            "macro\\_rules! collect\\_stri",
            "($desc:literal, $item:ty $(, $a:lifetime)?) => {",
            "#[doc = concat!(\"Collects \", $desc, \" from a parallel iterator into a string.\")]",
            "impl$(<$a>)? FromParallelIterator<$item> for String {",
            "#[doc = concat!(\"Collects \", $desc, \" from a parallel iterator into a boxed string.\")]",
            "impl$(<$a>)? FromParallelIterator<$item> for Box<str> {",
            "I: IntoParallelIterator<Item = $item>,",
            "I: IntoParallelIterator<Item = $item>,",
            "collect\\_string!(\"characters\", char)",
            "collect\\_string!(\"characters\", &'a char, 'a)",
            "collect\\_string!(\"string slices\", &'a str, 'a)",
            "collect\\_string!(\"string slices\", Cow<'a, str>, 'a)",
            "collect\\_string!(\"boxed strings\", Box<str>)",
            "collect\\_string!(\"strings\", String)",
            "impl<'a> FromParallelIterator<&'a OsStr> for OsString {",
            "I: IntoParallelIterator<Item = &'a OsStr>,",
            "/// Collects OS-strings from a parallel iterator into one large OS-string.",
            "impl FromParallelIterator<OsString> for OsString {",
            "I: IntoParallelIterator<Item = OsString>,",
            "impl<'a> FromParallelIterator<Cow<'a, OsStr>> for OsString {",
            "\nI: IntoParallelIterator<Item = Cow<'a, OsStr>>,",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "collect\\_extended(par\\_ite",
            "/// Collects an arbitrary `Cow` collection.",
            "/// Note, the standard library only has `FromIterator` for `Cow<'a, str>` and",
            "/// `Cow<'a, [T]>`, because no one thought to add a blanket implementation",
            "/// before it was stabilized.",
            "impl<'a, C, T> FromParallelIterator<T> for Cow<'a, C>",
            "C: ToOwned<Owned: FromParallelIterator<T>> + ?Sized,",
            "T: Send,",
            "T: Send,",
            "T: Send,",
            "T: Send,",
            "T: Send,",
            "T: Send,",
            "T: Send,",
            "I: IntoParallelIterator<Item = T>,",
            "I: IntoParallelIterator<Item = T>,",
            "I: IntoParallelIterator<Item = T>,",
            "I: IntoParallelIterator<Item = T>,",
            "I: IntoParallelIterator<Item = T>,",
            "I: IntoParallelIterator<Item = T>,",
            "I: IntoParallelIterator<Item = T>,",
            "I: IntoParallelIterator<Item = T>,",
            "Cow::Owned(C::Owned::from\\_par\\_iter(par\\_ite",
            "/// Collapses all unit items from a parallel iterator into one.",
            "/// collecting to a `Result<(), E>` where you only care about errors:",
            "/// use std::io::\\*",
            "/// use rayon::prelude::\\*",
            "/// let data = vec![1, 2, 3, 4, 5];",
            "/// let res: Result<()> = data.par\\_iter(",
            "/// .map(|x| writeln!(stdout(), \"{}\", x))",
            "/// .collect();",
            "/// assert!(res.is\\_ok())",
            "/// ```",
            "/// ```",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "fn from\\_par\\_iter<I>(par\\_iter: I) -> S",
            "I: IntoParallelIterator<Item = ()>,",
            "_iter.into\\_par\\_iter().drive\\_unindexed(NoopConsumer)",
            "/// Collects OS-string slices from a parallel iterator into an OS-string.",
            "/// Collects OS-string slices from a parallel iterator into an OS-string.",
            "/// This is more useful when combined with higher-level abstractions, like",
            "///",
            "///",
            "///",
            "///",
            "/// linked list.",
            "impl FromParallelIterator<()> for () {",
            "/// Collects items from a parallel iterator into a reference-counted slice.",
            "/// Collects items from a parallel iterator into a freshly allocated",
            "/// hashmap. If multiple pairs correspond to the same key, then the",
            "/// Collects (key, value) pairs from a parallel iterator into a",
            "/// Collects (key, value) pairs from a parallel iterator into a",
            "/// btreemap. If multiple pairs correspond to the same key, then the",
            "/// ones produced earlier in the parallel iterator will be",
            "/// ones produced earlier in the parallel iterator will be",
            "/// Collects values from a parallel iterator into a hashset.",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "rayon::iter::FromParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "Collects (key, value) pairs from a parallel iterator into a hashmap. If multiple pairs correspond to the same key, then the ones produced earlier in the..."
          ]
        },
        {
          "title": "RELEASES.md - platform/external/rust/crates/rayon - Git at Google",
          "url": "https://android.googlesource.com/platform/external/rust/crates/rayon/+show/b1457495c5f4967f72a614f92c0fd5ff36011a41/RELEASES.md",
          "excerpts": [
            "- Type inference now works better with parallel `Range` and `RangeInclusive`. - The implementation of `FromParallelIterator` and `ParallelExtend` for. `Vec<T>..."
          ]
        },
        {
          "title": "Extend HashMap with results from rayon parallel iterator",
          "url": "https://users.rust-lang.org/t/extend-hashmap-with-results-from-rayon-parallel-iterator/133415",
          "excerpts": [
            "Aug 27, 2025  I'm trying to accumulate a HashMap with results from a parallel iterator of json file string data of football matches:"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "pub trait FromParallelIterator<T>",
            "    // Required method",
            "       where I: IntoParallelIterator<Item = T>;",
            "FromParallelIterator` implements the creation of a collectio",
            "from a [`ParallelIterator`](trait.ParallelIterator.html \"trait rayon::iter::ParallelIterator\").",
            "By implementing",
            "FromParallelIterator is used through ParallelIterator 's collect() method. Examples. Implementing FromParallelIterator for your type: use rayon::prelude::*; ...",
            "created from an iterator.",
            "ParallelIterator\")s [`collect()`](trait.ParallelIterator.html.collect \"method rayon::iter::ParallelIterator::collect\") method.",
            "    T: Send,",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "where",
            "{",
            "}"
          ]
        },
        {
          "title": "rayon docs: Iteration - ParallelExtend and FromParallelIterator",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "ParallelExtend in rayon::iter - Rust",
            "pub trait ParallelExtend<T>\n\nwhere\n    T: Send ,\n\n{\n    // Required method\n    fn par_extend <I>(&mut self, par_iter: I)\n       where I: IntoParallelIterator <Item = T> ;\n}",
            "where\n    T: Send,\n\n{\n    // Required method\n    fn par_extend<I>(&mut self, par_iter: I)\n       where I: IntoParallelIterator<Item = T>;\n}",
            "ParallelExtend` extends an existing collection with items from a [`ParallelIterator`](trait.ParallelIterator.html \"trait rayon::iter::ParallelIterator\")",
            "--\n\nImplementing `ParallelExtend` for your type:\n\n```\nuse rayon::prelude::*;\n\nstruct BlackHole {\n    mass: usize,\n}\n\nimpl<T: Send> ParallelExtend<T> for BlackHole {\n    fn par_extend<I>(&mut self, par_iter: I)\n        where I: IntoParallelIterator<Item = T>\n    {\n        let par_iter = par_iter.into_par_iter();\n        self.mass += par_iter.count() * size_of::<T>();\n    }\n}\n\nlet mut bh = BlackHole { mass: 0 };\nbh.par_extend(0i32..1000);\nassert_eq! (bh.mass, 4000);\nbh.par_extend(0i64..10);\nassert_eq!",
            "use rayon::prelude:: *",
            "let mut vec = vec! []",
            "vec.par_extend( 0 .. 5 );",
            "vec.par_extend(( 0 .. 5 ).into_par_iter().map(|i| i * i));",
            "assert_eq! (vec, [ 0 , 1 , 2 , 3 , 4 , 0 , 1 , 4 , 9 , 16 ]);",
            "Extends an instance of the collection with the elements drawn\nfrom the parallel iterator `par_iter` . ##### []() Exampl",
            "where",
            "```",
            "```"
          ]
        },
        {
          "title": "rayon/iter/mod.rs (Rust Rayon documentation)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/mod.rs.html",
          "excerpts": [
            "To use parallel iterators, first import the traits by adding\n33//! something like `use rayon::prelude::*` to your module. You can\n34//! then call `par_iter`, `par_iter_mut`, or `into_par_iter` to get a\n35//! parallel iterator. Like a [regular iterator][], parallel\n36//! iterators work by first constructing a computatio",
            " - Various collections offer [`par_extend`], which grows a\n48//!   collection given a parallel iterator. (If you don't have a\n49//!   collection to extend, you can use [`collect()`] to create a new",
            "! To see the full range of methods available on parallel iterators,\n58//! check out the [`ParallelIterator`] and [`IndexedParallelIterator`]",
            " A note about object safety: It is currently _not_ possible to wrap\n75//! a `ParallelIterator` (or any trait that depends on it) using a\n76//! `Box<dyn ParallelIterator>` or other kind of dynamic allocation,\n77//! because `ParallelIterator` is **not o"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "/// Creates an empty default collection and extends it. 14 fn collect_extended<C, I>(par_iter: I) -> C",
            "impl <T> FromParallelIterator<T> for Rc<[T]>",
            "/// overwritten, just as with a sequential iterator. 121 impl <K, V, S> FromParallelIterator<(K, V)> for HashMap<K, V, S>",
            "/// Collects items from a parallel iterator into a boxed slice. 38 impl <T> FromParallelIterator<T> for Box<[T]>",
            "fn collect_extended<C, I>(par_iter: I) -> C",
            "    I: IntoParallelIterator,",
            "    C: ParallelExtend<I::Item> + Default,",
            "    let mut collection = C::default();",
            "    collection.par_extend(par_iter);",
            "    collection",
            "/// Collects items from a parallel iterator into a vector. 25 impl <T> FromParallelIterator<T> for Vec<T>",
            "    T: Send,",
            "    K: Eq + Hash + Send,",
            "    V: Send,",
            "    S: BuildHasher + Default + Send,",
            "macro_rules! collect_string {",
            "  ( $desc :literal, $item :ty $(, $a :lifetime) ? ) => {",
            "        #[doc = concat! ( \"Collects \" , $desc , \" from a parallel iterator into a string.\" )]",
            "        impl $(< $a >) ? FromParallelIterator< $item > for String {",
            "                collect_extended(par_iter)",
            "        #[doc = concat! ( \"Collects \" , $desc , \" from a parallel iterator into a boxed string.\" )]",
            "/// Collects items from a parallel iterator into an atomically-reference-counted slice. 64 impl <T> FromParallelIterator<T> for Arc<[T]>",
            "            fn from_par_iter<I>(par_iter: I) -> Self",
            "            fn from_par_iter<I>(par_iter: I) -> Self",
            "            where",
            "            where",
            "                I: IntoParallelIterator<Item = $item >,",
            "                I: IntoParallelIterator<Item = $item >,",
            "            {",
            "            {",
            "                String::from_par_iter(par_iter).into_boxed_str()",
            "            }",
            "            }",
            "        }",
            "        }",
            "collect_string! ( \"characters\" , char);",
            "collect_string! ( \"characters\" , & 'a char, 'a );",
            "collect_string! ( \"string slices\" , & 'a str, 'a );",
            "collect_string! ( \"string slices\" , Cow< 'a , str>, 'a );",
            "collect_string! ( \"boxed strings\" , Box<str>);",
            "collect_string! ( \"strings\" , String);",
            "/// Collects OS-string slices from a parallel iterator into an OS-string.",
            "impl < 'a > FromParallelIterator<Cow< 'a , OsStr>> for OsString {",
            "        I: IntoParallelIterator<Item = & 'a OsStr>,",
            "/// Collapses all unit items from a parallel iterator into one. 259 ///",
            "/// This is more useful when combined with higher-level abstractions, like",
            "/// collecting to a \\`Result<(), E>\\` where you only care about errors:",
            "///",
            "///",
            "/// use std::io::*;",
            "/// use rayon::prelude::*;",
            "/// linked list.",
            "/// let data = vec! [1, 2, 3, 4, 5];",
            "/// let res: Result<()> = data.par_iter()",
            "///     .map(|x| writeln! (stdout(), \"{}\", x))",
            "///     .collect();",
            "/// assert!(res.is_ok());",
            "/// \\`\\`\\`",
            "/// \\`\\`\\`",
            "impl FromParallelIterator<()> for () {",
            "        I: IntoParallelIterator<Item = ()>,",
            "        par_iter.into_par_iter().drive_unindexed(NoopConsumer)",
            " {",
            "/// Collects items from a parallel iterator into a reference-counted slice.",
            "/// Collects items from a parallel iterator into a vecdeque. 77 impl <T> FromParallelIterator<T> for VecDeque<T>",
            "/// Collects items from a parallel iterator into a binaryheap. 90 /// The heap-ordering is calculated serially after all items are collected. 91 impl <T> FromParallelIterator<T> for BinaryHeap<T>",
            "   T: Ord + Send,",
            "        Vec::from_par_iter(par_iter).into()",
            "        Vec::from_par_iter(par_iter).into()",
            "        Vec::from_par_iter(par_iter).into()",
            "        Vec::from_par_iter(par_iter).into()",
            "        Vec::from_par_iter(par_iter).into()",
            "/// Collects items from a parallel iterator into a freshly allocated",
            "impl <T> FromParallelIterator<T> for LinkedList<T>",
            "   T: Send,",
            "   T: Send,",
            "   T: Send,",
            "   T: Send,",
            "   T: Send,",
            "        I: IntoParallelIterator<Item = T>,",
            "        I: IntoParallelIterator<Item = T>,",
            "        I: IntoParallelIterator<Item = T>,",
            "        I: IntoParallelIterator<Item = T>,",
            "        I: IntoParallelIterator<Item = T>,",
            "        I: IntoParallelIterator<Item = T>,",
            "        I: IntoParallelIterator<Item = T>,",
            "/// hashmap. If multiple pairs correspond to the same key, then the",
            "/// Collects (key, value) pairs from a parallel iterator into a",
            "/// Collects (key, value) pairs from a parallel iterator into a",
            "/// btreemap. If multiple pairs correspond to the same key, then the",
            "/// ones produced earlier in the parallel iterator will be",
            "/// ones produced earlier in the parallel iterator will be",
            "/// overwritten, just as with a sequential iterator. 139 impl <K, V> FromParallelIterator<(K, V)> for BTreeMap<K, V>",
            "   K: Ord + Send,",
            "   V: Send,",
            "        I: IntoParallelIterator<Item = (K, V)>,",
            "        I: IntoParallelIterator<Item = (K, V)>,",
            "/// Collects values from a parallel iterator into a hashset.",
            "impl <V, S> FromParallelIterator<V> for HashSet<V, S>",
            "   V: Eq + Hash + Send,",
            "   S: BuildHasher + Default + Send,",
            "/// Collects values from a parallel iterator into a btreeset. 167 impl <V> FromParallelIterator<V> for BTreeSet<V>",
            "   V: Send + Ord,",
            "        I: IntoParallelIterator<Item = V>,",
            "        I: IntoParallelIterator<Item = V>,",
            "        impl $(< $a >) ?",
            "FromParallelIterator< $item > for Box<str> {",
            "/// Collects OS-string slices from a parallel iterator into an OS-string. 211 impl < 'a > FromParallelIterator< & 'a OsStr> for OsString {",
            "/// Collects OS-strings from a parallel iterator into one large OS-string. 221 impl FromParallelIterator<OsString> for OsString {",
            "        I: IntoParallelIterator<Item = OsString>,",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "    fn from_par_iter<I>(par_iter: I) -> Self",
            "        I: IntoParallelIterator<Item = Cow< 'a , OsStr>>,",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            "        collect_extended(par_iter)",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            " }",
            "(res.is_ok());",
            "   fn from_par_iter<I>(par_iter: I) -> Self",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "where",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "{",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    where",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "    {",
            "   where",
            "   {",
            "   }",
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "        }",
            "Examples",
            "where",
            "    }",
            "   }",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "        }",
            "        }",
            "        }",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon fold into a HashMap - Stack Overflow",
          "url": "https://stackoverflow.com/questions/57641821/rayon-fold-into-a-hashmap",
          "excerpts": [
            "I have a Vec<Result<MyStruct, ()>> , and I want to put them into buckets inside a HashMap, where keys are MyStruct.b field and values are a Vec containing all ..."
          ]
        },
        {
          "title": "How do I use Rayon with an existing iterator?",
          "url": "https://stackoverflow.com/questions/48922420/how-do-i-use-rayon-with-an-existing-iterator",
          "excerpts": [
            "I am trying to use it with Rayon, but I can't figure out how to make Rayon work with an existing iterator without converting it to a vector first. Is this...",
            "Note that you can use rayon::prelude::* to get traits such as ParallelBridge and ParallelIterator automatically. (It might be a matter of taste, ... Note that you can use rayon::prelude::* to get traits such as ParallelBridge and ParallelIterator automatically. (It might be a matter of taste,..."
          ]
        },
        {
          "title": "ParallelExtend in maybe_rayon::prelude - Rust",
          "url": "https://doc.servo.org/maybe_rayon/prelude/trait.ParallelExtend.html",
          "excerpts": [
            "Extends an instance of the collection with the elements drawn from the parallel iterator par_iter . Examples. use rayon::prelude::*; let mut vec = vec!"
          ]
        },
        {
          "title": "extend.rs source code [crates/rayon/src/iter/extend.rs]",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/extend.rs.html",
          "excerpts": [
            "}  /// Extends a string with string slices from a parallel iterator.  impl<'a> ParallelExtend<&'a str> for String {  fn par_extend <I>(&mut self, par_iter : I)."
          ]
        },
        {
          "title": "from_par_iter.rs source code [crates/rustc-rayon-0.5.1/src/iter ...",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-0.5.1/src/iter/from_par_iter.rs.html",
          "excerpts": [
            "/// Collects items from a parallel iterator into a binaryheap.  /// The heap-ordering is calculated serially after all items are collected.  impl<T> ..."
          ]
        },
        {
          "title": "rayon::iter - Rust",
          "url": "https://laysakura.github.io/louds-rs/rayon/iter/",
          "excerpts": [
            "To use parallel iterators, first import the traits by adding something like use rayon::prelude::* to your module. You can then call par_iter , par_iter_mut , ... See the ParallelString trait for the full list. Various collections offer par_extend , which grows a collection given a parallel iterator. (If you don't have a ..."
          ]
        },
        {
          "title": "How to use Boxes with rayon? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/how-to-use-boxes-with-rayon/72510",
          "excerpts": [
            "Hi ! I'm trying to use rayon with a vector of Boxed structs : use rayon::prelude::*; use crate::{entity::Entity, message::Message}; ..."
          ]
        },
        {
          "title": "Rayon: collect into multiple arrays? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/kp6dxc/rayon_collect_into_multiple_arrays/",
          "excerpts": [
            "I'm trying to use rayon to run my loop in parallel, but I've hit an issue I don't know how to solve. I have some code as follows:"
          ]
        },
        {
          "title": "Rayon: Catching panic from `par_iter()` - help - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/rayon-catching-panic-from-par-iter/35136",
          "excerpts": [
            "It's the question about catching panic from par_iter if I don't know would it panic or not, and my goal is to prevent rayon default behavior which aborts the ..."
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://laysakura.github.io/fid-rs/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "ParallelExtend extends an existing collection with items from a ParallelIterator . Examples. Implementing ParallelExtend for your type: use rayon::prelude::..."
          ]
        },
        {
          "title": "`par_iter` not running in parallel",
          "url": "https://users.rust-lang.org/t/par-iter-not-running-in-parallel/67582",
          "excerpts": [
            "Nov 18, 2021  If you want more granular parallelism for smaller maps and sets, you could collect item references to a Vec first. That's what rayon does anyway..."
          ]
        },
        {
          "title": "rust - How to use rayon's .par_iter() with a vector of generics?",
          "url": "https://stackoverflow.com/questions/41576433/how-to-use-rayons-par-iter-with-a-vector-of-generics",
          "excerpts": [
            "par_iter means distributing &T to different threads. That means T: Sync. Map is returning T s by value (and passing them to potential new threads) that..."
          ]
        },
        {
          "title": "Perform computation in a parallel iterator, then feed it to ...",
          "url": "https://stackoverflow.com/questions/68304515/perform-computation-in-a-parallel-iterator-then-feed-it-to-a-single-threaded-on",
          "excerpts": [
            "This one is pretty simple: instead of adding elements to the HashSet one at a time during computation, map the data with your computation and then collect it... This one is pretty simple: instead of adding elements to the HashSet one at a time during computation, map the data with your computation and then collect it ...",
            "This one is pretty simple: instead of adding elements to the HashSet one at a time during computation, map the data with your computation and then collect it..."
          ]
        },
        {
          "title": "From Vectors to HashSets: Navigating Rust's Data Structures |",
          "url": "https://leapcell.medium.com/from-vectors-to-hashsets-navigating-rusts-data-structures-810f3680f73f",
          "excerpts": [
            "The Rust standard library provides fundamental data structures such as Vectors (Vec<T>), Hash Maps (HashMap<K, V>), and Hash Sets (HashSet<T>)."
          ]
        },
        {
          "title": "Rayon Hash",
          "url": "https://github.com/rayon-rs/rayon-hash",
          "excerpts": [
            "Rayon Hash"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust",
          "url": "https://doc.servo.org/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "Internally, most FromParallelIterator / ParallelExtend implementations use this strategy; each job collecting their chunk of the iterator to a Vec<T> and ..."
          ]
        },
        {
          "title": "std::collections - Rust",
          "url": "https://doc.rust-lang.org/std/collections/index.html",
          "excerpts": [
            "Rust's standard collection library provides efficient implementations of the most common general purpose programming data structures."
          ]
        },
        {
          "title": "rust-lang/docs.rs: crates.io documentation generator",
          "url": "https://github.com/rust-lang/docs.rs",
          "excerpts": [
            "Docs.rs (formerly cratesfyi) is an open source project to host documentation of crates for the Rust Programming Language."
          ]
        },
        {
          "title": "Make multithreaded/async app more readable in htop/gdb?",
          "url": "https://users.rust-lang.org/t/make-multithreaded-async-app-more-readable-in-htop-gdb/84183",
          "excerpts": [
            "It is a complex beast involving tokio tasks, some of which spawn_blocking rayon par_iter() tasks. I have a feeling it is somewhere in rayon that ..."
          ]
        },
        {
          "title": "Rayon par_iter not working on Vec<struct> - help - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/rayon-par-iter-not-working-on-vec-struct/53317",
          "excerpts": [
            "I tried using par_iter on a vector filled with structs: use rayon::prelude::*; struct Test{ int:i32, f:f32 } fn main() { //create a vector ..."
          ]
        },
        {
          "title": "Rayon FromParallelIterator Implementations (from_par_iter.rs)",
          "url": "https://codebrowser.dev/rust/crates/rayon-1.10.0/src/iter/from_par_iter.rs.html",
          "excerpts": [
            " into a vector. * |\n| 25 | **impl**<T> [FromParallelIterator](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::FromParallelIterator\")<T> **for** [Vec](../../../alloc/src/vec/mod.rs.html \"alloc::vec::Vec\")<T> |\n| 26 | **where** |\n| 27 | T: [Send](../../../core/src/marker.rs.html \"core::marker::Send\"), |\n| 28 | { |\n| 29 | **fn** from\\_par\\_iter<I>(par\\_iter: I) -> Self |\n| 30 | **where** |\n| 31 | I: [IntoParallelIterator](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::IntoParallelIterator\")<[Item](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::IntoParallelIterator::Item\") = T>, |\n| 32 | { |\n| 33 | [collect\\_extended]( \"collect_extended\")([par\\_iter]( \"par_iter\"))",
            "*/// Collects (key, value) pairs from a parallel iterator into a* |\n| 118 | */// hashmap. If multiple pairs correspond to the same key, then the* |\n| 119 | */// ones produced earlier in the parallel iterator will be* |\n| 120 | */// overwritten, just as with a sequential iterator.\n* |\n| 121 | **impl**<K, V, S> [FromParallelIterator](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::FromParallelIterator\")<(K, V)> **for** [HashMap](../../../std/src/collections/hash/map.rs.html \"std::collections::hash::map::HashMap\")<K, V, S> |\n| 122 | **where** |\n| 123 | K: [Eq](../../../core/src/cmp.rs.html \"core::cmp::Eq\") + [Hash](../../../core/src/hash/mod.rs.html \"core::hash::Hash\") + [Send](../../../core/src/marker.rs.html \"core::marker::Send\"), |\n| 124 | V: [Send](../../../core/src/marker.rs.html \"core::marker::Send\"), |\n| 125 | S: [BuildHasher](../../../core/src/hash/mod.rs.html \"core::hash::BuildHasher\") + [Default](../../../core/src/default.rs.html \"core::default::Default\") + [Send](../../../core/src/marker.rs.html \"core::marker::Send\"), |\n| 126 | { |\n| 127 | **fn** from\\_par\\_iter<I>(par\\_iter: I) -> Self |\n| 128 | **where** |\n| 129 | I: [IntoParallelIterator](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::IntoParallelIterator\")<[Item](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::IntoParallelIterator::Item",
            "| */// Collects values from a parallel iterator into a hashset.\n* |\n| 153 | **impl**<V, S> [FromParallelIterator](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::FromParallelIterator\")<V> **for** [HashSet](../../../std/src/collections/hash/set.rs.html \"std::collections::hash::set::HashSet\")<V, S> |\n| 154 | **where** |\n| 155 | V: [Eq](../../../core/src/cmp.rs.html \"core::cmp::Eq\") + [Hash](../../../core/src/hash/mod.rs.html \"core::hash::Hash\") + [Send](../../../core/src/marker.rs.html \"core::marker::Send\"), |\n| 156 | S: [BuildHasher](../../../core/src/hash/mod.rs.html \"core::hash::BuildHasher\") + [Default](../../../core/src/default.rs.html \"core::default::Default\") + [Send](../../../core/src/marker.rs.html \"core::marker::Send\"), |\n| 157 | { |\n| 158 | **fn** from\\_par\\_iter<I>(par\\_iter: I) -> Self |\n| 159 | **where** |\n| 160 | I: [IntoParallelIterator](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::IntoParallelIterator\")<[Item](../../../rayon-1.10.0/src/iter/mod.rs.html \"rayon::iter::IntoParallelIterator::Item\") = V>, |\n| 161 | { |\n|"
          ]
        },
        {
          "title": "rayon::par_iter::IndexedParallelIterator - Rust - autumnai.github.io",
          "url": "https://autumnai.github.io/cuticula/rayon/par_iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points."
          ]
        },
        {
          "title": "Findes in Java Stream - Gene Zeiniss",
          "url": "https://genezeiniss.medium.com/java-stream-find-methods-67a8e7f6b06",
          "excerpts": [
            "findFirst() can guarantee the same result when running on the same source. The reason to use findAny() is to give a more flexible alternative to ..."
          ]
        },
        {
          "title": "Java 8 Stream findFirst() and findAny() - Mkyong.com",
          "url": "https://mkyong.com/java8/java-8-stream-findfirst-and-findany/",
          "excerpts": [
            "In Java 8 Stream, the findFirst() returns the first element from a Stream, while findAny() returns any element from a Stream."
          ]
        },
        {
          "title": "Update in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Update.html",
          "excerpts": [
            "... IndexedParallelIterator<Item = (A, B)>, A: Send, B: Send,. Unzips the results of the iterator into the specified vectors. The vectors are always cleared...",
            "Collects the results of the iterator into the specified vector. The vector is always cleared before execution begins. If possible, reusing the vector across..."
          ]
        },
        {
          "title": "Iter in rayon::result - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/result/struct.Iter.html",
          "excerpts": [
            "Collects the results of the iterator into the specified vector. The vector is always cleared before execution begins. If possible, reusing the vector across..."
          ]
        },
        {
          "title": "Problem with understanding Rayon IntoParallelRefIterator",
          "url": "https://users.rust-lang.org/t/problem-with-understanding-rayon-intoparallelrefiterator/26425",
          "excerpts": [
            "Hi, I recently tried to understand the mechanism of IntoParallelRefIterator in Rayon framework and tried to copy all the related struct and ..."
          ]
        },
        {
          "title": "option.rs - source",
          "url": "https://docs.rs/rayon/latest/src/rayon/option.rs.html",
          "excerpts": [
            "1//! Parallel iterator types for [options][std::option] 2//! 3//! You will rarely need to interact with this module directly unless you need 4//! to name..."
          ]
        },
        {
          "title": "Rayon: accept anything that can be converted into ...",
          "url": "https://users.rust-lang.org/t/rayon-accept-anything-that-can-be-converted-into-indexedparalleliterator/89597",
          "excerpts": [
            "Feb 20, 2023  TLDR. How to write a function which can accept anything that can be converted into rayon::iter::IndexedParallelIterator ? Feb 20, 2023  However, I still don't see how to link the IndexedParallelIterator bound to non-rayon iterators which know how many elements they will produce.",
            "TLDR. How to write a function which can accept anything that can be converted into rayon::iter::IndexedParallelIterator ?"
          ]
        },
        {
          "title": "zip_eq.rs - source - Docs.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/zip_eq.rs.html",
          "excerpts": [
            "1use super::plumbing::*; 2use super::*; 3 4/// An [`IndexedParallelIterator`] that iterates over two parallel iterators of equal 5/// length simultaneously."
          ]
        },
        {
          "title": "Take in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Take.html",
          "excerpts": [
            "... find_any , the parallel search will not necessarily find the first match, and once a match is found we'll attempt to stop processing any more. Read more.",
            "Searches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like\n`ParallelIterator::find_any`, the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more.",
            "Searches for **some** item in the parallel iterator that\nmatches the given predicate and returns it. This operation\nis similar to [`find` on sequential iterators](https://doc.rust-lang.org/nightly/core/iter/traits/iterator/trait.Iterator.html.find \"method core::iter::traits::iterator::Iterator::find\") but\nthe item returned may not be the **first** one in the parallel\nsequence which matches, since we search the entire sequence in paralle",
            "Searches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate and returns it.",
            "Searches for **some** item in the parallel iterator that\nmatches the given predicate, and if so returns true. Once\na match is found, well attempt to stop process the rest\nof the items. Proving that theres no match, returning false,\ndoes require visiting every item."
          ]
        },
        {
          "title": "Docs for Rayon: IndexedParallelIterator (docs.rs) and Rayon usage",
          "url": "https://docs.rs/rayon/latest/rayon/?search=find",
          "excerpts": [
            "The [`IndexedParallelIterator`](iter/trait.IndexedParallelIterator.html \"trait rayon::iter::IndexedParallelIterator\") trait adds methods for iterators that support random\n      a",
            "Rayon is a data-parallelism library that makes it easy to convert sequential\ncomputations into parallel. It is lightweight and convenient for introducing parallelism into existing\ncode. It guarantees data-race free executions and takes advantage of\nparallelism when sensible, based on work-load at runtime.",
            "There are two ways to use Rayon:"
          ]
        },
        {
          "title": "rayon::par_iter::IndexedParallelIterator - Rust",
          "url": "http://docs.piston.rs/texture_packer/rayon/par_iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports \"random access\" to its data, meaning that you can split it at arbitrary indices and draw data from those points. Provided Methods. fn..."
          ]
        },
        {
          "title": "Rust: After parallelization with rayon, write out results in ...",
          "url": "https://stackoverflow.com/questions/76960134/rust-after-parallelization-with-rayon-write-out-results-in-order-without-waiti",
          "excerpts": [
            "I want to print (stdout or to a file) the results of every call to do_work(), but do this printing only in the order of the original iterator.",
            "par_bridge()` doesn't and can't split its input in half, because an ordinary `Iterator` doesn't permit that",
            "Ah, right, I didn't see it's `par_bridge()` . It's less efficient, though :)",
            "rayon` usually splits iterators in half",
            "As @ChayimFriedman mentioned, this isn't necessarily feasible because `rayon` likes to subdivide work starting in large chunks, so the order won't be friendly.",
            "However, _because_ you are using `.par_bridge()` , Rayon must take items from the `Iterator` in order, so the order will be close to the original orde",
            "Here is a demonstration program.",
            "the order will be close to the original order",
            "a buffer and `.enumerate()` , without consuming large amounts of memory.",
            "```rust\nuse std::collections::HashMap;\nuse std::sync::mpsc;\nuse std::time::Duration;\n\nuse rand::Rng;\nuse rayon::prelude::{ParallelBridge, ParallelIterator};\n\nfn main() {\n    let data_source = (0..500u32).rev();\n\n    // Channel with enough capacity to hold an item from each thread\n    let (tx, rx) = mpsc::sync_channel(std::thread::available_parallelism().map_or(8, |n| n.get()));\n\n    rayon::scope(|s| {\n        s.spawn(move |_| {\n            data_source\n                .enumerate()\n                .par_bridge()\n                .map(|(i, value)| {\n                    // pretend to do some work\n                    std::thread::sleep(Duration::from_millis(\n                        1000 + rand::thread_rng().gen_range(0..10),\n                    ));\n                    (i, value)\n                })\n                .for_each_with(tx, |tx, pair| {\n                    let _ = tx.send(pair);\n                });\n        });\n\n        recover_order(rx, emit);\n    });\n}\n\nfn emit(item: u32) {\n    println!\n(\"done with {item}\");\n}\n\nfn recover_order<T>(rx: mpsc::Receiver<(usize, T)>, mut op: impl FnMut(T)) {\n    let mut next_index: usize = 0;\n    let mut buffer: HashMap<usize, T> = HashMap::new();\n    for (i, value) in rx {\n        if i == next_index {\n            op(value);\n            next_index += 1;\n            while let Some((_, value)) = buffer.remove_entry(&next_index) {\n                op(value);\n                next_index += 1;\n            }\n        } else {\n            // Item is out of order\n            buffer.insert(i, value);\n        }\n    }\n\n    assert! (buffer.is_empty(), \"channel closed with missing items\");\n\n    println! (\"Buffer capacity used: {}\", buffer.capacity());\n}\n`",
            ";\n}\n```\n\nThe `for_each_with()` transfers items from Rayon control to the channel, and the `recover_order()` function consumes the channel to call `emit()` with the items in proper order. The use of `rayon::scope()` and `spawn()` allows the `for_each_with()` parallel iteration to run in the background on the existing Rayon thread pool, so that the current thread can handle the receiving directly.",
            "As @ChayimFriedman mentioned, this isn't necessarily feasible because `rayon` likes to subdivide work starting in large chunks, so the order won't be friendly. However, _because_ you are using `.par_bridge()` , Rayon must take items from the `Iterator` in order, so the order will be close to the original order. Therefore, it is feasible to recover the original order using a buffer and `.enumerate()` , without consuming large amounts of memory. Here is a demonstration program."
          ]
        },
        {
          "title": "Either in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/enum.Either.html",
          "excerpts": [
            "The type of item that this parallel iterator produces. For example, if you use the for_each method, this is the type of item that your closure will be invoked...",
            "The type of item that this parallel iterator produces. For example, if you use the for_each method, this is the type of item that your closure will be invoked... The Either type is symmetric and treats its variants the same way, without preference. (For representing success or error, use the regular Result enum instead.)..."
          ]
        },
        {
          "title": "Is there a way to convert Select.rs's find iterator into a Rayon ...",
          "url": "https://stackoverflow.com/questions/55737587/is-there-a-way-to-convert-select-rss-find-iterator-into-a-rayon-paralleliterato",
          "excerpts": [
            "I would like to convert Select.rs's Find -iterator into a Rayon ParallelIterator . I haven't been able to do this by simply mucking about ...",
            "I would like to convert Select.rs's Find -iterator into a Rayon ParallelIterator . I haven't been able to do this by simply mucking about ... I would like to convert Select.rs's Find -iterator into a Rayon ParallelIterator . I haven't been able to do this by simply mucking about..."
          ]
        },
        {
          "title": "Map in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Map.html",
          "excerpts": [
            "Map is an iterator that transforms the elements of an underlying iterator. This struct is created by the map() method on ParallelIterator."
          ]
        },
        {
          "title": "Positions in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Positions.html",
          "excerpts": [
            "Positions takes a predicate predicate and filters out elements that match, yielding their indices. This struct is created by the positions() method on...",
            "The type of item that this parallel iterator produces. For example, if you use the for_each method, this is the type of item that your closure will be ... Positions takes a predicate predicate and filters out elements that match, yielding their indices. This struct is created by the positions() method on ...",
            " ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate and returns it. This operation\nis similar to [`find` on sequential iterators](https://doc.rust-lang.org/nightly/core/iter/traits/iterator/trait.Iterator.html.find \"method core::iter::traits::iterator::Iterator::find\") but\nthe item returned may not be the **first** one in the parallel\nsequence which matches, since we search the entire sequence in parallel.",
            "Searches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate and returns it.",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate and returns it.",
            "where\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.h",
            "#### fn [find\\_first](trait.ParallelIterator.html.find_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "\n#### fn [all](trait.ParallelIterator.html.all) <P>(self, predicate: P) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html)",
            "well attempt to stop processing more items, then return false.",
            "Searches for **some** item in the parallel iterator that\nmatches the given predicate, and if so returns true. Once\na match is found, well attempt to stop process the rest\nof the items. Proving that theres no match, returning false,\ndoes require visiting every item."
          ]
        },
        {
          "title": "Release rayon 1.7.0 / rayon-core 1.11.0 (2023-03-03)",
          "url": "https://android.googlesource.com/platform/external/rust/crates/rayon/+/782e7a8713938145981ee6627fabaeafac0f4c70/RELEASES.md",
          "excerpts": [
            "Parallel iterators now support find_first() , find_last() , position_first() , and position_last() . ... position_any ... Join the discussion at https://github.com/..."
          ]
        },
        {
          "title": "Using par_iter and Rayon in Rust - Stack Overflow",
          "url": "https://stackoverflow.com/questions/78095243/using-par-iter-and-rayon-in-rust",
          "excerpts": [
            "I want to parallelise the code below which takes two Rust vectors and sums each element, returning a new vector in the same order as the originals."
          ]
        },
        {
          "title": "range.rs - source",
          "url": "https://docs.rs/rayon/latest/src/rayon/range.rs.html",
          "excerpts": [
            "1//! Parallel iterator types for [ranges], 2//! the type for values created by `a..b` expressions 3//! 4//! You will rarely need to interact with this..."
          ]
        },
        {
          "title": "rayon::iter::MultiZip - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/struct.MultiZip.html",
          "excerpts": [
            "MultiZip is an iterator that zips up a tuple of parallel iterators to produce tuples of their items. It is created by calling into_par_iter() on a tuple of..."
          ]
        },
        {
          "title": "Parallel Iterators Part 2: Producers  baby steps",
          "url": "https://smallcultfollowing.com/babysteps/blog/2016/02/25/parallel-iterators-part-2-producers/",
          "excerpts": [
            "This post is the second post in my series on Rayon's parallel iterators. The goal of this series is to explain how parallel iterators are ... Feb 25, 2016  This post is the second post in my series on Rayon's parallel iterators. The goal of this series is to explain how parallel iterators are...",
            "Feb 25, 2016  This post is the second post in my series on Rayon's parallel iterators. The goal of this series is to explain how parallel iterators are..."
          ]
        },
        {
          "title": "How to achieve parallelism that retains order of tasks : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/nlyjb7/how_to_achieve_parallelism_that_retains_order_of/",
          "excerpts": [
            "So the problem I'm having with rayon is that it does not seem to try to execute the tasks in the order of the iterator. So, I want that last..."
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with\n`par_iter` instead.",
            "ion\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool. This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead. However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O. Iterator items are pulled by `next()` one at a time, synchronized from each thread that is\nready for work, so this may become a bottleneck if the serial iterator cant keep up with the\nparallel demand. The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "use rayon::iter::ParallelBridge;",
            "use rayon::prelude::ParallelIterator;",
            "use std::sync::mpsc::channel;",
            "let rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "assert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "Required Methods[]()",
            " Examples\n\nTo use this trait, take an existing `Iterator` and call `par_bridge` on it.\nAfter that, you can\nuse any of the `ParallelIterator` methods:",
            "After that, you can",
            "Iterator items are pulled by `next()` one at a time, synchronized from each thread that is\nready for work, so this may become a bottleneck if the serial iterator cant keep up with the\nparallel demand.",
            "\nparallel demand. The items are not buffered by `IterBridge` , so its fine to use this with",
            ";\nuse rayon::prelude::",
            "Parallel Bridge",
            " fn par_bridge (self) -> IterBridge <Self>;",
            "parallelize by other means, like channels or file or network I/O. Iterator items are pulled by `next()` one at a time, synchronized from each thread that is",
            "Examples",
            "let rx = {",
            "    let (tx, rx) = channel();",
            "    tx.send( \"one!\" );",
            "    tx.send( \"two!\" );",
            "    tx.send( \"three!\" );",
            "    rx",
            "};",
            "Iterator items are pulled by `next()` one at a time, synchronized from each thread that is\nready for work, so this may become a bottleneck if the serial iterator cant keep up with the\nparallel demand. The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "To use this trait, take an existing `Iterator` and call `par_bridge` on it.",
            "this may become a bottleneck if the serial iterator cant keep up with the\nparallel demand.",
            " can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/",
            "This creates a bridge from a sequential iterator to a parallel one, by distributing its items across the Rayon thread pool.",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "pub trait ParallelBridge: Sized {",
            "output.sort_unstable();",
            "```",
            "```",
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "Iterator items are pulled by \\`next()\\` one at a time, synchronized from each thread that is\n22 /// ready for work, so this may become a bottleneck if the serial iterator can't keep up with the\n23 /// para",
            "The items are not buffered by \\`IterBridge\\`, so it's fine to use this with\n24 /// large or even unbounded itera",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Iterator items are pulled by \\`next()\\` one at a time, synchronized from each thread that is\n22 /// ready for work, so this may become a bottleneck if the serial iterator can't keep up with the\n23 /// pa",
            "This has the advantage of being able to parallelize just about\n17/// anything, but the resulting `ParallelIterator` can be less efficient than if you started with\n18/// `par_it",
            "However, it can still be useful for iterators that are difficult to\n19/// parallelize by other means, like channels or file or networ",
            "pub trait ParallelBridge: Sized {",
            "where",
            "   T: Iterator<Item: Send> + Send,",
            "{",
            "    fn par_bridge( self ) -> IterBridge< Self > {",
            "        IterBridge { iter: self }",
            "    }",
            "/// This type is created when using the \\`par_bridge\\` method on \\`ParallelBridge\\`. See",
            "/// [\\`ParallelBridge\\`] documentation for detail",
            "pub struct IterBridge<Iter> {",
            "    iter: Iter,",
            "let mut output: Vec<&'static str> = rx.into_iter().par_bridge().collect();",
            "let num_threads = current_num_threads();",
            "let threads_started: Vec< _ > = ( 0 ..num_threads).map(| _ | AtomicBool::new( false )).collect();",
            "The items are not buffered by \\`IterBridge\\`, so it's fine to use this with\n24 /// large or even unbounded i",
            "/// large or even unbounded iterators. 25 ///",
            "/// The resulting iterator is not guaranteed to keep the order of the original iterator. 27 ///",
            "/// To use this trait, take an existing \\`Iterator\\` and call \\`par_bridge\\` on it.",
            "output.sort_unstable();",
            "assert_eq! (&*output, &[\"one! \", \"three! \", \"two! \"])",
            "Docs.rs. rayon-1.11.0. rayon 1.11.0; Permalink  Docs.rs crate page  MIT OR Apache ... Ordering::Relaxed, Ordering::Relaxed, |c| c.checked_sub(1)); 114 (self ...",
            "This creates a \"bridge\" from a sequential iterator to a parallel one, by distributing its items\n16 /// across the Rayon threa",
            "Conversion trait to convert an \\`Iterator\\` to a \\`ParallelIterator\\`.",
            "    /// Creates a bridge from this type to a \\`ParallelIterator\\`. 55    fn par_bridge( self ) -> IterBridge< Self >;",
            "8 impl <T> ParallelBridge for T\n59 where\n60    T: Iterator<Item: Send> + Send,\n61 {\n62    fn par_bridge( self ) -> IterBridge< Self > {\n63        IterBridge { iter:",
            "/// \\`IterBridge\\` is a parallel iterator that wraps a sequential iterator. 68 ///",
            "/// This type is created when using the \\`par_bridge\\` method on \\`ParallelBridge\\`. See the",
            "/// [\\`ParallelBridge\\`] documentation for details.",
            "#[derive(Debug, Clone)]",
            "impl <Iter> ParallelIterator for IterBridge<Iter>",
            "   Iter: Iterator<Item: Send> + Send,",
            "{\n80    type Item = Iter::Ite",
            "    fn drive_unindexed<C>( self , consumer: C) -> C::Result",
            "    where",
            "        C: UnindexedConsumer< Self ::Item>,",
            "    {",
            "        let num_threads = current_num_threads();",
            "        let threads_started: Vec< _ > = ( 0 ..num_threads).map(| _ | AtomicBool::new( false )).collect();",
            "        bridge_unindexed(",
            "            & IterParallelProducer {",
            "                split_count: AtomicUsize::new(num_threads),",
            "                iter: Mutex::new( self .iter.fuse()),",
            "                threads_started: & threads_started,",
            "            },",
            "            consumer,",
            "        )",
            "struct IterParallelProducer< 'a , Iter> {",
            "   split_count: AtomicUsize,",
            "   iter: Mutex<std::iter::Fuse<Iter>>,",
            "   threads_started: & 'a [AtomicBool],",
            "impl <Iter: Iterator + Send> UnindexedProducer for & IterParallelProducer< '_ , Iter> {",
            "   type Item = Iter::Item;",
            "   fn split( self ) -> ( Self , Option < Self >) {",
            "       // Check if the iterator is exhausted",
            "       let update = self",
            "           .split_count",
            "           .fetch_update(Ordering::Relaxed, Ordering::Relaxed, |c| c.checked_sub( 1 ));",
            "       ( self , update.is_ok().then_some( self ))",
            "   fn fold_with<F>( self , mut folder: F) ->",
            "f",
            "   where",
            "       F: Folder< Self ::Item>,",
            "   {",
            "       // Guard against work-stealing-induced recursion, in case \\`Iter::next()\\`",
            "       // calls rayon internally, so we don't deadlock our mutex. We might also",
            "       // be recursing via \\`folder\\` methods, which doesn't present a mutex hazard,",
            "       // but it's lower overhead for us to just check this once, rather than",
            "       // updating additional shared state on every mutex lock/unlock. 126        // (If this isn't a rayon thread, then there's no work-stealing anyway...)",
            "       if let Some (i) = current_thread_index() {",
            "           // Note: If the number of threads in the pool ever grows dynamically, then",
            "           // we'll end up sharing flags and may falsely detect recursion -- that's",
            "           // still fine for overall correctness, just not optimal for parallelism. 131            let thread_started = & self .threads_started[i % self .threads_started.len()];",
            "           if thread_started.swap( true , Ordering::Relaxed) {",
            "               // We can't make progress with a nested mutex, so just return and let",
            "               // the outermost loop continue with the rest of the iterator items.",
            "      ",
            "       loop {",
            "           if let Ok ( mut iter) = self .iter.lock() {",
            "               if let Some (it) = iter.next() {",
            "                   drop(iter);",
            "                   folder = folder.consume(it);",
            "                   if folder.full() {",
            "                       return folder;",
            "                   }",
            "               } else {",
            "                   return folder;",
            "               }",
            "           } else {",
            "               // any panics from other threads will have been caught by the pool,",
            "               // and will be re-thrown when joined - just exit",
            "               return folder;",
            "               return folder;",
            "           }",
            "           }",
            "       }",
            "       }",
            "   }",
            "   }",
            "}",
            "}"
          ]
        },
        {
          "title": "FoldWith in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.FoldWith.html",
          "excerpts": [
            "where",
            "where",
            "where",
            "where",
            "where",
            "where"
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "where",
            "where",
            "where"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "    }",
            "#[derive(Debug, Clone)]",
            "    where",
            "    where",
            "    where",
            "    {",
            "    {",
            "    {",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo life module (life/mod.rs)",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/life/mod.rs",
          "excerpts": [
            "    }",
            "    }"
          ]
        },
        {
          "title": "zip.rs - source",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/zip.rs.html",
          "excerpts": [
            "Docs.rs. rayon-1.11.0. rayon 1.11.0; Permalink  Docs.rs crate page  MIT OR Apache ... ParallelIterator for Zip<A, B> 25where 26 A: IndexedParallelIterator..."
          ]
        },
        {
          "title": "Deadlock? when using par_bridge()  Issue #690  rayon-rs ...",
          "url": "https://github.com/rayon-rs/rayon/issues/690",
          "excerpts": [
            "dy actions\n\nI'm using rayon 1.2.0 on Windows 10 and rustc 1.36.0 stable. I'm not sure how to best report this bug and I don't even know if it is a bug in rayon at all, but I thought it's better when someone has a look at this. I can provide additional information as requested. I've written the following code:\n\n```\nuse jwalk :: WalkDir ;\n\nlet entries = WalkDir :: new ( path ) . into_iter ( ) . par_bridge ( ) . map ( |entry| {\n    entry .\nunwrap ( ) . path ( ) . display ( ) . to_string ( )\n} ) . collect :: < Vec < _ > > ( ) ;\n```\n\nI'm using jwalk 0.4.0; it uses rayon internally. If I run this code on a big folder ( `C:\\Users\\Home` or `C:\\` ) it _sometimes_ hangs indefinitely in the `par_bridge.rs` . It tries to aquire the lock on line 165, but always continues with the `Err(TryLockError::WouldBlock)` match arm.  React with  1 pkolaczk",
            " Deadlock? when using par\\_bridge() #690",
            "```\nuse jwalk :: WalkDir ;\n\nlet entries = WalkDir :: new ( path ) . into_iter ( ) . par_bridge ( ) . map ( |entry| {\n    entry .",
            "    entry .",
            "unwrap ( ) . path ( ) . display ( ) . to_string ( )",
            "} ) . collect :: < Vec < _ > > ( ) ;",
            "\n## Metadata",
            "### Assignees",
            "No one assigned",
            "### Labels",
            "No labels",
            "### Type",
            "No type",
            "### Projects",
            "No projects",
            "You cant perform that action at this time.",
            "Description"
          ]
        },
        {
          "title": "rayon_par_bridge - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-par-bridge",
          "excerpts": [
            "This crate provides an elegant solution for integrating Rayon's parallel processing power with the traditional sequential iterator pattern in Rust."
          ]
        },
        {
          "title": "Introduce an alternative to ParallelBridge that does not ...",
          "url": "https://github.com/rayon-rs/rayon/issues/676",
          "excerpts": [
            "Jul 8, 2019  par_bridge() gets a reference to something that is not Sync, so thus, the Iterator is not Send, prohibiting the use of rayon without quite some...",
            "Jul 8, 2019  The current implementation of .par_bridge() wraps the iterator type in a mutex, necessitating a Send bound (or T: Sync for &T: Send );...",
            "I have an use-case where the Iterator before .par_bridge() gets a reference to something that is not Sync, so thus, the Iterator is not Send, ..."
          ]
        },
        {
          "title": "GitHub Issue: Performance of par_bridge (#685)",
          "url": "https://github.com/rayon-rs/rayon/issues/685",
          "excerpts": [
            "\ncombinations\n.par_bridge()\n.flat_map(|combination| permutations::permutations(&combination))\n.map(|permutation| {\nlet phrase = permutation.join(\" \");\nlet has_property = has_property(phrase);\n(phrase, has_property)\n})\n.filter(|(_, has_property)| has_property)\n.for_each(|(phrase, _)| println!(\"{:?\n}\", phrase));",
            "I was expecting that one thread would be doing the work of computing items of the combinations iterator and the others in the pool would be consuming the items and processing them. I can see that's not the case from profiling the binary and the performance (rate of finding matching phrases) actually drops, but I'm not sure how to proceed from there. Am I using par_bridge the way it's intended? Is there a way to achieve a performance boost for this sort of problem using Rayon? Thank you for your help!",
            "I've tried the naive approach and the overall performance drops.",
            "Performance of par_bridge  #68",
            "New issue",
            "New issue",
            "Copy link",
            "Copy link",
            "Closed",
            "Closed",
            "Performance of par_bridge #685",
            "Description",
            "gkudelis",
            "opened",
            "on Aug 28, 2019",
            "Issue body actions",
            "Hello! I'm trying to take an algorithm and parallelize a part of it. The first part generates combinations of items, I don't see how to parallelize it and it takes up the bulk of computation time. These combinations get fed into the next bit where I generate permutations of each combination, calculate some properties of these permutations and filter based on the properties. I then want to do something that pass the filter. The second part is trivial to parallelize - I can take every combination from the first part and analyze it separately. I've tried the naive approach and the overall performance drops. Here's what I'm using:",
            "combinations",
            ".par_bridge()",
            ".map(|permutation| {",
            "let phrase = permutation.join(\" \");",
            "let has_property = has_property(phrase);",
            "(phrase, has_property)",
            ".filter(|(_, has_property)| has_property)",
            "Hello! I'm trying to take an algorithm and parallelize a part of it. The first part generates combinations of items, I don't see how to ...",
            "})"
          ]
        },
        {
          "title": "Implementing a rayon::iter::ParallelIterator - rust",
          "url": "https://stackoverflow.com/questions/59028562/implementing-a-rayoniterparalleliterator",
          "excerpts": [
            "I'm rather new to Rust, but managed to successfully use Rayon to process data in parallel. At least as long as I'm working on existing data structures."
          ]
        },
        {
          "title": "How to convert ParallelIterator back to sequential Iterator?",
          "url": "https://stackoverflow.com/questions/66560235/how-to-convert-paralleliterator-back-to-sequential-iterator",
          "excerpts": [
            "Basically I want the opposite of par_bridge() ; something that runs on the thread where it's called, reads items from each thread, and produces..."
          ]
        },
        {
          "title": "rayon deadlock prevention : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/17krzer/rayon_deadlock_prevention/",
          "excerpts": [
            "I found out that it's pretty easy to exhaust threads in the rayon threadpool. Ie by making a blocking call, ie recv from a channel, or something of this kind."
          ]
        },
        {
          "title": "Rayon par_bridge() order : r/learnrust - Reddit",
          "url": "https://www.reddit.com/r/learnrust/comments/17q0v6q/rayon_par_bridge_order/",
          "excerpts": [
            "I'm trying to get a par_bridge() to keep some level of ordering for the processing: each item is a tuple (file, chunk) where file is a file handle ID and chunk ..."
          ]
        },
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. If the two iterators are of unequal length, you only get the items they have in common.",
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "Rayon isn't any faster than loop despite 16x more CPU usage : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/1cra4i8/rayon_isnt_any_faster_than_loop_despite_16x_more/",
          "excerpts": [
            "I have made a prime number calculator and I don't get the speed increase from rayon I'd expect. Here is the simple code behind it.",
            "Along the same lines as you - I'm thinking they might get more of a benefit by batching then parallelizing work over each batch."
          ]
        },
        {
          "title": "Rayon par_bridge deadlock discussion (The Rust Programming Language Forum)",
          "url": "https://users.rust-lang.org/t/rayon-par-bridge-deadlock/34677",
          "excerpts": [
            "par_bridge` is batching this way in order to amortize the synchronization overhead, so it's hard to tune this in a general way.",
            "There's nothing like `try_next` for general iterators, but you could certainly fork your own `par_bridge` using `try_recv` as you suggest.",
            "Nov 16, 2019  The problem is directory traversal. Step one is to put root directory into the queue. The work is to read that directory's dir_entry contents.",
            "I have a queue of work that feeds back into itself, processing work can generate more work.",
            "par_bridge` is batching this way in order to amortize the synchronization overhead, so it's hard to tune this in a general way. I think pulling just one at a time would be prohibitive though. There's also a sort of priority inversion problem possible, like this [`Mutex` bug](https://github.com/rayon-rs/rayon/issues/592) , where work stealing can get you in a situation where a job is waiting on some result from a suspended task on the same stack, causing a deadlo",
            "Each of those tasks will actually execute independently without worrying about nesting on the stack and such.",
            "What next?\nIs this expected to work or should I have a different design somehow?",
            "This topic was automatically closed 90 days after the last reply. New replies are no longer allowed."
          ]
        },
        {
          "title": "Parallel rayon version of itertools ZipLongest iterator?",
          "url": "https://users.rust-lang.org/t/parallel-rayon-version-of-itertools-ziplongest-iterator/79229",
          "excerpts": [
            "I'm looking for a rayon ParallelIterator which is analogous to the zip_longest iterator from itertools. In summary ZipLongest iterates over two iterators ..."
          ]
        },
        {
          "title": "rust - Zip iterators of different lengths - Stack Overflow",
          "url": "https://stackoverflow.com/questions/74972544/zip-iterators-of-different-lengths",
          "excerpts": [
            "I'd like to understand why .chain(std::iter::once(None)) is necessary. I know it is probably for \"padding\", but I'm not exactly sure how it helps."
          ]
        },
        {
          "title": "par_bridge.rs - source",
          "url": "https://rust-lang.github.io/hashbrown/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "Source of the Rust file `/home/travis/.cargo/registry/src/github.com-1ecc6299db9ec823/rayon-1.5.0/src/iter/par_bridge.rs`. /// /// This type is created when using the `par_bridge` method on `ParallelBridge`. See the /// [`ParallelBridge`] documentation for details. /// /// ...",
            "Source of the Rust file `/home/travis/.cargo/registry/src/github.com-1ecc6299db9ec823/rayon-1.5.0/src/iter/par_bridge.rs`. /// /// The resulting iterator is not guaranteed to keep the order of the original iterator. /// /// # Examples /// /// To use this trait, take an existing..."
          ]
        },
        {
          "title": "par_bridge in rayon_par_bridge - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-par-bridge/latest/rayon_par_bridge/fn.par_bridge.html",
          "excerpts": [
            "Transforms a Rayon parallel iterator into a sequentially processed iterator. This function enables the ergonomic bridging between Rayon's parallel ...",
            "Transforms a Rayon parallel iterator into a sequentially processed iterator. This function enables the ergonomic bridging between Rayon's parallel..."
          ]
        },
        {
          "title": "Rayon par_bridge deadlock - #6 by jessegrosjean - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/rayon-par-bridge-deadlock/34677/6",
          "excerpts": [
            "I have a queue of work that feeds back into itself, processing work can generate more work. The problem is directory traversal."
          ]
        },
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "impl<A, B> Zip<A, B> {",
            "/// Creates a new `Zip` iterator.",
            "pub(super) fn new(a: A, b: B) -> Self {",
            "Zip { a, b }",
            "fn len(&self) -> usize {",
            "Ord::min(self.a.len(), self.b.len())",
            "#[must\\_use = \"iterator adaptors are lazy and do nothing unless consumed\"",
            "pub struct Zip<A, B> {",
            "pub struct Zip<A, B> {",
            "a: A,",
            "a: A,",
            "b: B,",
            "b: B,",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FoldChunks in maybe_rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/maybe-rayon/latest/maybe_rayon/iter/struct.FoldChunks.html",
          "excerpts": [
            "FoldChunks is an iterator that groups elements of an underlying iterator and applies a function over them, producing a single value for each group."
          ]
        },
        {
          "title": "Teaching Parallelism in Rust Using Rayon: Building a ...",
          "url": "https://medium.com/@omkar_p/teaching-parallelism-in-rust-using-rayon-building-a-thread-race-game-e7f29552bf64",
          "excerpts": [
            "Implementing the Thread Task: Here we will define the function each thread has to do to win the race. Which thread will complete this task and..."
          ]
        },
        {
          "title": "Per-thread initialization in Rayon",
          "url": "https://stackoverflow.com/questions/42647900/per-thread-initialization-in-rayon",
          "excerpts": [
            "Use\nmap_with . This will clone every time a thread steals a work item from another thread. This will possibly clone more stores than there are threads, but it should be fairly low.",
            "If the clones are too expensive, you can increase the size rayon will split workloads with\nwith_min_len .",
            "Or use the scoped\nThreadLocal from the thread_local crate. This will ensure that you only use as many objects as there are threads, and that they are destroyed once the\nThreadLocal object goes out of scope. fn verify_and_store(store: &mut Store, txs: Vec<Tx>) {\nlet tl = ThreadLocal::new();",
            "It is possible to use a thread-local variable to ensure that local_store is not created more than once in a given thread. For example, this ...",
            "There are two problems with this code, however. One, if the clones of\nstore need to do something when\npar_iter() is done, such as flush their buffers, it simply won't happen - their\nDrop will only be called when Rayon's worker threads exit, and even that is not guaranteed .",
            "The second, and more serious problem, is that the clones of\nstore are created exactly once per worker thread. Since Rayon uses a global thread pool, this means that an unrelated later call to\nverify_and_store will continue working with last known clones of\nstore , which possibly have nothing to do with the current store. This can be rectified by complicating the code somewhat:",
            "   * Store the cloned variables in a\nMutex<Option<...>> instead of\nOption , so that they can be accessed by the thread that invoked\npar_iter() . This will incur a mutex lock on every access, but the lock will be uncontested and therefore cheap.",
            ". * Use an\nArc around the mutex in order to collect references to the created store clones in a vector. This vector is used to clean up the stores by resetting them to\nNone after the iteration has finished.",
            "\n* Wrap the whole call in an unrelated mutex, so that two parallel calls to\nverify_and_store don't end up seeing each other's store clones. (This might be avoidable if a new thread pool were created and installed before the iteration.)"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "There is one answer to how to collect thread local data from each thread in this old WIP pull request: [Add ThreadPool::broadcast by cuviper  Pull Request #492  rayon-rs/rayon  GitHub](https://github.com/rayon-rs/rayon/pull/492) ; to have it work repeatably you'd first broadcast to set a starting value and broadcast in the end to fetch. I would start by using fold or reduce, since that's an approximation to what you want to do! However, of course, rayon may split aggressively and create more jobs to resolve than there are threads. Using .with\\_min\\_len() could mitigate that. In your particular example, just using regular exclusive mutable references could also work? One &mut per thread job (but then you have to split manually",
            "I'd like to implement a pattern I have used in other languages that is essentially an expensive reduction; an effective way to realize it is to have a copy of the structure to be reduced per thread, then each thread work-steals from a queue, updating its local structure. Finally, after the queue of work is empty, we reduce the threads' structures into a final result. I can _almost_ do this with TLS, but I don't know how to do the final pass because there's no way that I know of to map 1 closure to 1 thread in rayon. Another way is to have a heap array of the structures, index by thread id, but I don't understand the magic Send work I need to do handle it. This is an example, albeit for a very simple reduction of u64s rather than some more complex struct. ```",
            "use rayon::prelude::*;\nuse std::cell::RefCell;\nthread_local! {\n    pub static SUM: RefCell<u64> = RefCell::new(0);\n}\nfn main() {\n    let N = 1u64 << 20;\n    // v0: closed-form\n    println! (\"{}\", N * (N-1) / 2);\n    // v1: serial\n    let sum: u64 = (0..N).sum();\n    println! (\"{}\", sum);\n    // v2: rayon reduce\n    let psum: u64 = (0..N).into_par_iter().reduce(|| 0, |x, y| x + y);\n    println!\n",
            "pool.scope(|s| {\n        for x in range {\n            s.spawn(move |_| SUM.with(|m| *m.borrow_mut() += x));\n        }\n    });",
            "fn main() {\n\n    let N = 1u64 << 20;\n\n    // v0: closed-form\n    println! (\"{}\", N * (N-1) / 2);\n\n    // v1: serial\n    let sum: u64 = (0..N).sum();\n\n    println! (\"{}\", sum);\n\n    // v2: rayon reduce\n    let psum: u64 = (0..N).into_par_iter().reduce(|| 0, |x, y| x + y);\n\n    println!\n(\"{}\", psum);\n\n    // v3: pool, with TLS\n    let pool = rayon::ThreadPoolBuilder::new()\n        .num_threads(8)\n        .build()\n        .unwrap();\n\n    let range = 0..1 << 20;\n    pool.scope(|s| {\n        for x in range {\n            s.spawn(move |_| SUM.with(|m| *m.borrow_mut() += x));\n        }\n    });\n\n    // Except How do I access SUM once for each thread to do a reduction now? // v4: Manual arrays\n    let pool = rayon::ThreadPoolBuilder::new()\n        .num_threads(8)\n        .build()\n        .unwrap();\n\n    let mut temps = vec! [0u64; pool.current_num_threads()];\n\n    let temps = temps.as_mut_ptr();\n\n    // how do I make this Send?\nlet range = 0..1 << 20;\n    pool.scope(|s| {\n        [{\n            for x in range {\n                s.spawn(|_| unsafe { *(temps.offset(rayon::current_thread_index().unwrap() as isize)) += x}) ;\n            }\n        }]\n    });",
            "thread_local! {",
            "Except How do I access SUM once for each thread to do a reduction now?",
            "error: could not compile `playground` due to previous error",
            "Well, technically, you _could_ just wrap the raw pointer in a struct for which you unsafely implement `Send` , but it's _very likely_ that using raw pointers and `unsafe` is not the right solution.",
            "For something as structured as this problem, where there is no need to interact with FFI or manage your own memory, you should absolutely stick to safe code.",
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem.",
            "}"
          ]
        },
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        },
        {
          "title": "Parallel execution of nested loop and collection of multiple ...",
          "url": "https://users.rust-lang.org/t/parallel-execution-of-nested-loop-and-collection-of-multiple-occurences-of-values/56365",
          "excerpts": [
            "Mar 2, 2021  Rayon has a fold operation, but it returns an iterator, which might be surprising. Fortunately, in the docs there's a nice description of fold+...",
            "Mar 2, 2021  I have here a system of nested loops where elements of vectors are combined and I want to execute that in parallel. Then I want to create some sort of..."
          ]
        },
        {
          "title": "Stack-based thread-local storage  Issue #941  rayon-rs ... - GitHub",
          "url": "https://github.com/rayon-rs/rayon/issues/941",
          "excerpts": [
            "The missing abstraction in Rayon for this is a nested task construct, where closures like the innermost ones above can borrow thread-local variables."
          ]
        },
        {
          "title": "Parallelize groupby with Rayon in Rust",
          "url": "https://stackoverflow.com/questions/72960751/parallelize-groupby-with-rayon-in-rust",
          "excerpts": [
            "How can I create a HashMap using Rayon's parallel fold? 3. Parallelizing nested loops in rust with rayon  1. Use thread-specific pre-allocated..."
          ]
        },
        {
          "title": "Rayon Docs: MapWith and fold/fold_with",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.MapWith.html",
          "excerpts": [
            "\n\n#### fn [fold\\_with](trait.ParallelIterator.html.fold_with) <F, T>(self, init: T, fold\\_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F>\n\nwhere\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n T: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") \\+ [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use.",
            "#### fn [fold](trait.ParallelIterator.html.fold) <T, ID, F>(self, identity: ID, fold\\_op: F) -> [Fold](struct.Fold.html \"struct rayon::iter::Fold\") <Self, ID, F>\n\nwhere\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n ID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n T: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nParallel fold is similar to sequential fold except that the\nsequence of items may be subdivided before it is\nfolded. Consider a list of numbers like `22 3 77 89 46` . If\nyou used sequential fold to add them ( `fold(0, |a,b| a+b)` ,\nyou would wind up first adding 0 + 22, then 22 + 3, then 25 +\n77, and so forth.\nThe **parallel fold** works similarly except\nthat it first breaks up your list into sublists, and hence\ninstead of yielding up a single sum at the end, it yields up\nmultiple sums. The number of results is nondeterministic, as\nis the point where the breaks occur. [Read more](trait.ParallelIterator.html.fold)",
            "#### fn [fold\\_chunks](trait.IndexedParallelIterator.html.fold_chunks)<T, ID, F>( self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html), identity: ID, fold\\_op: F, ) -> [FoldChunks](struct.FoldChunks.html \"struct rayon::iter::FoldChunks\")<Self, ID, F> where ID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\")() -> T + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\"), F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\")(T, Self::[Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\")) -> T + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\"), T: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\"),\n\nSplits an iterator into fixed-size chunks, performing a sequential [`fold()`](https://doc.rust-lang.org/nightly/core/iter/traits/iterator/trait.Iterator.html.fold \"trait core::iter::traits::iterator::Iterator\") on\neach chunk.\n ... \nThe **parallel fold** works similarly except\nthat it first breaks up your list into sublists, and hence\ninstead of yielding up a single sum at the end, it yields up\nmultiple sums. The number of results is nondeterministic, as\nis the point where the breaks occur. [Read more](trait.ParallelIterator.html.fold)\n\n[Source](../../src/rayon/iter/mod.rs.html)[](.fold_with)\n\n#### fn [fold\\_with](trait.ParallelIterator.html.fold_with)<F, T>(self, init: T, fold\\_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\")<Self, T, F> where F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\")(T, Self::[Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\")) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\"), T: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\"),\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use.\n ... \n[Read more](trait.ParallelIterator.html.any)\n\n[Source](../../src/rayon/iter/mod.rs.html)[](.all)\n\n#### fn [all](trait.ParallelIterator.html.all)<P>(self, predicate: P) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) where P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\")(Self::[Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\")) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\"),\n\nTests that every item in the parallel iterator matches the given\npredicate, and if so returns true. If a counter-example is found,\nwell attempt to stop processing more items, then return false.\n ... \n[Read more](https://doc.rust-lang.org/nightly/core/any/trait.Any.html.type_id)\n\n[Source](https://doc.rust-lang.org/nightly/src/core/borrow.rs.html)[](%3CT%3E-for-T)\n\n### impl<T> [Borrow](https://doc.rust-lang.org/nightly/core/borrow/trait.Borrow.html \"trait core::borrow::Borrow\")<T> for T where T: ? [Sized](https://doc.rust-lang.org/nightly/core/marker/trait.Sized.html \"trait core::marker::Sized\"),\n\n[Source](https://doc.rust-lang.org/nightly/src/core/borrow.rs.html)[](.borrow)\n\n#### fn [borrow](https://doc.rust-lang.org/nightly/core/borrow/trait.Borrow.html.borrow)(&self) -> [&T](https://doc.rust-lang.org/nightly/std/primitive.reference.html)\n\nImmutably borrows from an owned value. [Read more](https://doc.rust-lang.org/nightly/core/borrow/trait.Borrow.html.borrow)\n\n[Source](https://doc.rust-lang.org/nightly/src/core/borrow.rs.html)[](%3CT%3E-for-T)\n\n### impl<T> [BorrowMut](https://doc.rust-lang.org/nightly/core/borrow/trait.BorrowMut.html \"trait core::borrow::BorrowMut\")<T> for T where T: ? [Sized](https://doc.rust-lang.org/nightly/core/marker/trait.Sized.html \"trait core::marker::Sized\"),\n\n[Source](https://doc.rust-lang.org/nightly/src/core/borrow.rs.html)[](.borrow_mut)\n\n#### fn [borrow\\_mut](https://doc.rust-lang.org/nightly/core/borrow/trait.BorrowMut.html.borrow_mut)(&mut self) -> [&mut T](https://doc.rust-lang.org/nightly/std/primitive.reference.html)\n\nMutably borrows from an owned valu"
          ]
        },
        {
          "title": "Rayon with expensive-to-construct/combine accumulator",
          "url": "https://users.rust-lang.org/t/rayon-with-expensive-to-construct-combine-accumulator/78252",
          "excerpts": [
            "Jul 12, 2022  I have a datastructure which is pretty expensive to construct. let mut datastructure = empty_datastructure(); I have a bazillion data,... Is there some way of persuading rayon to create only one accumulator per thread? Or is rayon simply not the right tool for this kind of problem?"
          ]
        },
        {
          "title": "Scoped threads in the nursery (maybe with rayon?) - libs",
          "url": "https://internals.rust-lang.org/t/scoped-threads-in-the-nursery-maybe-with-rayon/4942",
          "excerpts": [
            "Mar 10, 2017  The key difference is one of philosophy: rayon's scoped threads are organized around a global thread-pool and are targeting data parallelism."
          ]
        },
        {
          "title": "My multi threaded rayon Rust loop can't outperform ...",
          "url": "https://www.reddit.com/r/rust/comments/1dt84i2/my_multi_threaded_rayon_rust_loop_cant_outperform/",
          "excerpts": [
            "Why are you allocating an Arc<Mutex> inside your parallel loop? That lock to make local_number mutable probably takes forever, and I don't..."
          ]
        },
        {
          "title": "Counter for each thread in rayon : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/1fi0xax/counter_for_each_thread_in_rayon/",
          "excerpts": [
            "You could use the rayon ThreadPoolBuilder's start_handler to get the thread number and insert that into the thread local."
          ]
        },
        {
          "title": "rayon::iter::FoldWith - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/struct.FoldWith.html",
          "excerpts": [
            "FoldWith is an iterator that applies a function over an iterator producing a single value. This struct is created by the fold_with() method on ..."
          ]
        },
        {
          "title": "making a parallel Rust workload 10x faster with (or without) Rayon",
          "url": "https://www.reddit.com/r/rust/comments/1gu8t2j/optimization_adventures_making_a_parallel_rust/",
          "excerpts": [
            "A tool rayon provides to reduce the maximum size of work units to help ensure that a single thread doesn't end up with a too-large heavy task.",
            "In the best case, Rayon performed slightly slower than my custom parallelism, in the worst case using with_max_len(1) was twice slower."
          ]
        },
        {
          "title": "Parallelization using rayon and chunks. : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/142dj6g/parallelization_using_rayon_and_chunks/",
          "excerpts": [
            "I am experimenting with parallelization using rayon. For the most part it works but when I split a vector of structs the parallelization deems to be more...",
            "I would expect you to be able to just replace chunks_exact_mut with par_chunks_exact_mut and it should work. Idea: Split the vector into chunks of two, execute the function, put the vector back together. In single threaded mode this works, but if I use ...",
            "Idea: Split the vector into chunks of two, execute the function, put the vector back together. In single threaded mode this works, but if I use..."
          ]
        },
        {
          "title": "Code Like a Pro in Rust",
          "url": "http://103.203.175.90:81/fdScript/RootOfEBooks/E%20Book%20collection%20-%202025%20-%20D/CSE%20%20IT%20AIDS%20ML/Manning.Code.Like.a.Pro.in.Rust.pdf",
          "excerpts": [
            "For more details on Rayon, consult the docu- mentation at https://docs.rs/rayon/latest/rayon/index.html. 11.5 Using Rust to accelerate other languages. The..."
          ]
        },
        {
          "title": "When Rust hurts | Hacker News",
          "url": "https://news.ycombinator.com/item?id=34803379",
          "excerpts": [
            "I recently wrote a program that used rayon to do a multithreaded but heavily I/O-bound computation. It was super simple to write that and ..."
          ]
        },
        {
          "title": "Rayon: data parallelism library for Rust - src/iter/mod.rs (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/mod.rs",
          "excerpts": [
            "(0..100).into\\_par\\_iter().for\\_each(|x| println!(\"{:?}\", x"
          ]
        },
        {
          "title": "How to iterate with enumeration using rayon? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/65656310/how-to-iterate-with-enumeration-using-rayon",
          "excerpts": [
            "Rayon seem to have IndexedParallelIterator , but I am not sure how to use it to produce similar result as the simple for loop shown above. Is ...",
            "When you create a ParallelIterator from a Vec by calling par_iter() it's also simultaneously an IndexedParallelIterator so you can call enumerate() on it to ..."
          ]
        },
        {
          "title": "Parallel iterator execution without job stealing (no rayon)",
          "url": "https://users.rust-lang.org/t/parallel-iterator-execution-without-job-stealing-no-rayon/124854",
          "excerpts": [
            "Executing in parallel will inherently run in an order that's not guaranteed to be the one emitted by the iterator. Or do you just mean you want ... Jan 30, 2025  Executing in parallel will inherently run in an order that's not guaranteed to be the one emitted by the iterator. Or do you just mean you want..."
          ]
        },
        {
          "title": "Rayon par_iter() println! being ignored - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/rayon-par-iter-println-being-ignored/24582",
          "excerpts": [
            "I have the following code let lines: Vec<&str> = contents.split_whitespace().collect(); println!(\"len: {:?}"
          ]
        },
        {
          "title": "Parallel Iterators Part 1: Foundations  baby steps",
          "url": "https://smallcultfollowing.com/babysteps/blog/2016/02/19/parallel-iterators-part-1-foundations/",
          "excerpts": [
            "This new iterator chain is now using Rayon's parallel iterators instead of the standard Rust ones. ... This is a side effect of all those ... Since giving a talk about Rayon at the Bay Area Rust meetup, I've been working off and on on the support for parallel iterators."
          ]
        },
        {
          "title": "A Survey on Parallelism and Determinism - ACM Digital Library",
          "url": "https://dl.acm.org/doi/10.1145/3564529",
          "excerpts": [
            "This survey takes the perspective of programming languages, and studies how programming models can ensure the determinism of parallel programs."
          ]
        },
        {
          "title": "lib.rs - source - Piston",
          "url": "https://docs.piston.rs/piston_window/src/rayon/lib.rs.html",
          "excerpts": [
            "Rayon is lightweight and convenient for introducing parallelism into existing code. It guarantees data-race free executions and takes advantage of parallelism ..."
          ]
        },
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "Rayon Ordering and Idioms Discussion",
          "url": "https://users.rust-lang.org/t/rust-simple-job-queue/24579",
          "excerpts": [
            "Rayon does guarantee it'll be executed precisely once. Nothing can guarantee it'll be executed in any particular order, because that would defeat the parallelism.",
            "If you need things to happen in order, you'll need to separate them out, and first perform parallelizable (order-independent) bits, collect to an ordered array (Rayon does guarantee `.collect()` collects elements in their original order), and run order-dependent side effects serially."
          ]
        },
        {
          "title": "rayon_core - Rust",
          "url": "https://docs.rs/rustc-rayon-core/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install()...",
            "hreadpool.html) can be used to create your own thread pools (using [`ThreadPoolBuilder`](struct.ThreadPoolBuilder.html)) or to customize the global",
            "Rayon-core houses the core stable APIs of Rayon. These APIs have been mirrored in the Rayon crate and it is recommended to use these from there. Tasks spawned within the pool (using install() , join() , etc.) will be added to a deque, where it becomes available for work stealing from other threads in the..."
          ]
        },
        {
          "title": "When should ThreadPoolBuilder be used?  Issue #677",
          "url": "https://github.com/rayon-rs/rayon/issues/677",
          "excerpts": [
            "Jul 8, 2019  A global \"use\" would be any rayon invocation that's not explicitly installed in some other ThreadPool first. You would use separate ThreadPool...",
            "The global thread pool remains for the life of the process. It can be manually initialized and configured with ThreadPoolBuilder::build_global() ..."
          ]
        },
        {
          "title": "rayon::Configuration - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.Configuration.html",
          "excerpts": [
            "Set the number of threads to be used in the rayon threadpool. If you specify a non-zero number of threads using this function, then the resulting...",
            "Old environment variable: RAYON_NUM_THREADS is a one-to-one replacement of the now deprecated RAYON_RS_NUM_CPUS environment variable. If both variables are ..."
          ]
        },
        {
          "title": "ThreadBuilder in rayon_core - Rust",
          "url": "https://docs.rs/rustc-rayon-core/latest/rayon_core/struct.ThreadBuilder.html",
          "excerpts": [
            "Gets the value that was specified by ThreadPoolBuilder::stack_size() . Source. pub fn run(self). Executes the main loop for this thread."
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "pub struct ThreadPoolBuilder<S = DefaultSpawn> { /* private fields */ }",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it.",
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Therefore, if you call build_global a second time, it will return an error. An Ok result indicates that this is the first initialization of the thread pool.",
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "Configuration in rustc_thread_pool - Rust",
          "url": "https://doc.rust-lang.org/beta/nightly-rustc/rustc_thread_pool/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead."
          ]
        },
        {
          "title": "Configuration in rayon_core - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon_core/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Creates and return a valid rayon thread pool configuration, but does not ..."
          ]
        },
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ...",
            "install() executes a closure in one of the ThreadPool 's threads. In addition, any other rayon operations called inside of install() will also execute in the ..."
          ]
        },
        {
          "title": "lib.rs - source",
          "url": "https://docs.rs/rustc-rayon-core/latest/src/rayon_core/lib.rs.html",
          "excerpts": [
            "1//! Rayon-core houses the core stable APIs of Rayon. 2//! 3//! These APIs have been mirrored in the Rayon crate and it is recommended to use these from..."
          ]
        },
        {
          "title": "lib.rs - source",
          "url": "https://doc.rust-lang.org/beta/nightly-rustc/src/rustc_thread_pool/lib.rs.html",
          "excerpts": [
            "1//! Rayon-core houses the core stable APIs of Rayon. 2//! 3//! These APIs have been mirrored in the Rayon crate and it is recommended to use these from...",
            "... ThreadPoolBuilder::num_threads`. 730 pub fn num_threads(mut self, num_threads: usize) -> Configuration { 731 self.builder = self.builder.num_threads(num_threads);..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Clarify rust rayon nested thread pool worker numbers - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76919721/clarify-rust-rayon-nested-thread-pool-worker-numbers",
          "excerpts": [
            "I have tried to use rayon 's parallel iterators in a nested way. As a global pool would have a fixed number of threads, I tend to create an outer-pool in main.",
            "let inner_pool = rayon::ThreadPoolBuilder::new().num_threads(1 as usize).build().unwrap();",
            "inner_pool.install(|| {",
            "vec!\n[1, 2, 3, 4].into_par_iter().map(|inner| stress(outer * 10 + inner)).collect(",
            "})",
            "let outer_pool = rayon::ThreadPoolBuilder::new().num_threads(1 as usize).build().unwrap();",
            "outer_pool.install(|| vec! [1, 2, 3, 4].into_par_iter().map(|outer| sub(outer)).collect())"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "})",
            "})",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "Rayon allows to build custom thread pools with `ThreadPoolBuilder` and `ThreadPool` structs. It is quite easy to create a custom thread pool and manually spawn tasks on it:",
            "let pool = rayon::ThreadPoolBuilder::new()\n    .num_threads(4)\n    .build()\n    .unwrap();\npool.spawn(|| println! (\"Task executes on thread: {:? }\", thread::current().id()));",
            "Multiple Thread Pools",
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); ",
            "let files: Vec<std::path::PathBuf> = ...\nlet (tx, rx) = std::sync::mpsc::channel();\nfor f in files.into_iter() {\n    let tx = tx.clone();  \n    let pool = if is_on_ssd(&f) { \n        &ssd_pool \n    } else { \n        &hdd_pool \n    };\n    pool.spawn(move || { \n        tx.send(compute_hash(f)).unwrap(); \n    });\n}\ndrop(tx); \nlet hashes: Vec<FileHash> = rx.into_iter().collect();",
            "Scopes",
            "use rayon::{Scope, ThreadPool};",
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();",
            "let ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); ",
            "let pools = [&hdd_pool, &ssd_pool]; // this could be constructed dynamically in real-world code",
            "multi_scope(&pools, |scopes| {\n    scopes[0].spawn(|s| { /* execute on hdd_pool, can use &common */ });\n    scopes[1].spawn(|s| { /* execute on ssd_pool, can use &common */ }",
            "pub fn multi_scope<'scope, OP, R>(pools: &[&ThreadPool], op: OP) -> R\nwhere\n    OP: FnOnce(&[&Scope<'scope>]) -> R + Send,\n    R: Send,\n{\n    nest(pools, Vec::with_capacity(pools.len()), op)\n}"
          ]
        },
        {
          "title": "ThreadPool in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user created thread-pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "rayon_core::ThreadPoolBuilder - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon_core/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Once started, the configuration cannot be changed. Therefore, if you call build_global a second time, it will return an error. An Ok result indicates that this...",
            "If num_threads is 0, or you do not call this function, then the Rayon runtime will select the number of threads automatically. At present, this is based on the..."
          ]
        },
        {
          "title": "tokio :: rayon - How thread starvation killed our production server",
          "url": "https://savannahar68.medium.com/how-thread-starvation-killed-our-production-server-fb5ba855aa57",
          "excerpts": [
            "Rayon has a thread pool with 16 threads (default), we didnt split Tokio and Rayon thread pools.",
            "If you have nested parallelism, Rayon threads deadlock; Everything grinds to a halt. The Fix: Proper Thread Pool Isolation. The solution was to ...",
            "// Move CPU work to blocking thread pool",
            "Dont block Tokios async workers",
            "But Rayon doesn't create new threads when the pool is exhausted. It uses a work-stealing scheduler that assumes threads will eventually free up."
          ]
        },
        {
          "title": "rayon_core::ThreadPoolBuilder - Rust",
          "url": "https://laysakura.github.io/louds-rs/rayon_core/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool The following creates a thread pool with 22 threads."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon_core - Rust",
          "url": "https://doc.servo.org/rayon_core/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. let...",
            "Used to create a new [`ThreadPool`](struct.ThreadPool.html \"struct rayon_core::ThreadPool\") or to configure the global rayon thread pool.",
            "rayon::ThreadPoolBuilder::new().num_threads(22).build_global().unwrap();",
            "The number of threads in the rayon thread pool. If zero will use the RAYON\\_NUM\\_THREADS environment variable. If RAYON\\_NUM\\_THREADS is invalid or zero will use the defa",
            "If you specify a non-zero number of threads using this\nfunction, then the resulting thread pools are guaranteed to\nstart at most this number of threads.",
            "d environment variable:** `RAYON_NUM_THREADS` is a one-to-one\nreplacement of the now deprecated `RAYON_RS_NUM_CPUS` environment\nvariable. If both variables are specified, `RAYON_NUM_THREADS` will\nbe preferred.",
            "If you do not call this function, the thread pool\nwill be automatically initialized with the default\nconfiguration.",
            " To reproduce the current default behavior, you\nmay wish to use [`std::thread::available_parallelism`](https://doc.rust-lang.org/1.89.0/std/thread/fn.available_parallelism.html \"fn std::thread::available_parallelism\")",
            "This initialization is\n**optional**. If you do not call this function, the thread pool\nwill be automatically initialized with the default\nconfigurat"
          ]
        },
        {
          "title": "lib.rs source code [crates/rayon-core-1.12.1/src/ ...",
          "url": "https://codebrowser.dev/rust/crates/rayon-core-1.12.1/src/lib.rs.html",
          "excerpts": [
            "Jun 12, 2025  Source code of lib.rs rayon_core 1.12.1 on KDAB Codebrowser."
          ]
        },
        {
          "title": "Intersecting Rayon Threadpools cause performance ...",
          "url": "https://stackoverflow.com/questions/73865529/intersecting-rayon-threadpools-cause-performance-overhead",
          "excerpts": [
            "If you create a custom rayon threadpool and at the same time also use the global threadpool through function calls like par_chunks or par_iter there is a..."
          ]
        },
        {
          "title": "Rust threadpool gathering results",
          "url": "https://stackoverflow.com/questions/76664012/rust-threadpool-gathering-results",
          "excerpts": [
            "Simply use parallel iterators. It will execute inside of the global rayon threadpool, which is automatically sized to the number of cores your system has."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool. After calling ThreadPoolBuilder::build() , you can then execute functions ..."
          ]
        },
        {
          "title": "Rough numbers for rayon thread pool startup/shutdown - help",
          "url": "https://users.rust-lang.org/t/rough-numbers-for-rayon-thread-pool-startup-shutdown/100597",
          "excerpts": [
            "rayon's global thread pool stays around for the duration of the program ... threads, making short-lived pools work better. system Closed ..."
          ]
        },
        {
          "title": "Conditionally Switch Between Rayon Parallel and Sequential ...",
          "url": "https://users.rust-lang.org/t/conditionally-switch-between-rayon-parallel-and-sequential-iteration-based-on-collection-size/130217",
          "excerpts": [
            "A better alternative to the par_chunks suggestion would be with_min_len , which tells Rayon not to split the iterator into parts smaller than n ..."
          ]
        },
        {
          "title": "Chunks in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/struct.Chunks.html",
          "excerpts": [
            "Creates an iterator that skips elements from anywhere in the original iterator until the given predicate returns false.",
            "Chunks is a parallel iterator over immutable, non-overlapping chunks of a slice, producing items of type `&'data [T]`."
          ]
        },
        {
          "title": "Split in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Split.html",
          "excerpts": [
            "Split is a parallel iterator using arbitrary data and a splitting function. This struct is created by the split() function. Trait Implementations. Source ..."
          ]
        },
        {
          "title": "How to use rayon ThreadPool in a sync way? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/how-to-use-rayon-threadpool-in-a-sync-way/123978",
          "excerpts": [
            "To create actual parallelism, you need to establish a scope() and then spawn() or join() within the scope. Also, you don't need Arc since scopes ..."
          ]
        },
        {
          "title": "parallel map not parallel  Issue #101  rayon-rs/rayon - GitHub",
          "url": "https://github.com/rayon-rs/rayon/issues/101",
          "excerpts": [
            "Rayon knows how to split the collection, but it's still an open question to decide when to split. See #81 and this discussion on the users ..."
          ]
        },
        {
          "title": "Rayon par_iter() auto larger chunks? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/rayon-par-iter-auto-larger-chunks/81555",
          "excerpts": [
            "Is there a way to tell rayon \"there are lots of tasks, but they are small, so assign them to threads in chunks of 100\" ?"
          ]
        },
        {
          "title": "Producer in rayon::iter::plumbing - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/plumbing/trait.Producer.html",
          "excerpts": [
            "#### fn [max\\_len](.max_len)(&self) -> [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html)\n\nThe maximum number of items that we will process\nsequentially. Defaults to MAX, which means that we can choose\nnot to split at all. This can be lowered using the\n[`with_max_len`](../trait.IndexedParallelIterator.html.with_max_len \"method rayon::iter::IndexedParallelIterator::with_max_len\") method, which will force us to create more\nparallel tasks. Note that Rayon automatically normally\nattempts to adjust the size of parallel splits to reduce\noverhead, so this should not be needed.",
            "#### fn [min\\_len](.min_len)(&self) -> [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html)\n\nThe minimum number of items that we will process\nsequentially. Defaults to 1, which means that we will split\nall the way down to a single item. This can be raised higher\nusing the [`with_min_len`](../trait.IndexedParallelIterator.html.with_min_len \"method rayon::iter::IndexedParallelIterator::with_min_len\") method, which will force us to\ncreate sequential tasks at a larger granularity. Note that\nRayon automatically normally attempts to adjust the size of\nparallel splits to reduce overhead, so this should not be\nneeded. [Source](../../../src/rayon/iter/plumbing/mod.rs.html)"
          ]
        },
        {
          "title": "Chunks in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Chunks.html",
          "excerpts": [
            "Chunks is an iterator that groups elements of an underlying iterator. This struct is created by the chunks() method on IndexedParallelIterator. Trait..."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust - Will Usher",
          "url": "https://www.willusher.io/tray_rust/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "Sets the minimum length of iterators desired to process in each thread. Rayon will not split any smaller than this length, but of course an iterator could ...",
            "Searches for some item in the parallel iterator that matches the given predicate, and returns its index. Like ParallelIterator::find_any , the parallel search ..."
          ]
        },
        {
          "title": "mod.rs - source",
          "url": "https://docs.piston.rs/piston_window/src/rayon/iter/plumbing/mod.rs.html",
          "excerpts": [
            "... Producer, C: Consumer<P::Item>, { let splitter = LengthSplitter::new(producer.min_len(), producer.max_len(), len); return helper(len, false, splitter, producer..."
          ]
        },
        {
          "title": "split_producer.rs - source",
          "url": "https://docs.rs/rayon/latest/src/rayon/split_producer.rs.html",
          "excerpts": [
            "Source of the Rust file `src/split_producer.rs`."
          ]
        },
        {
          "title": "Choosing the argument for rayons's with_min_len - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/choosing-the-argument-for-rayonss-with-min-len/120996",
          "excerpts": [
            "Using rayon's parallel iterators for ns-level tasks such as zeroing an array results in poor performance due to scheduling costs."
          ]
        },
        {
          "title": "MaxLen in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.MaxLen.html",
          "excerpts": [
            "Sets the minimum length of iterators desired to process in each\nrayon job. Rayon will not split any smaller than this length, but\nof course an iterator could already be smaller to begin with. [Read more](trait.IndexedParallelIterator.html.with_min_len)",
            "Sets the maximum length of iterators desired to process in each\nrayon job. Rayon will try to split at least below this length,\nunless that would put it below the length from `with_min_len()`. For example, given min=10 and max=15, a length of 16 will not be\nsplit any further."
          ]
        },
        {
          "title": "Iter in rayon::range - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/range/struct.Iter.html",
          "excerpts": [
            "... ExponentialBlocks<Self>. Divides an iterator into sequential blocks of exponentially-increasing size. Read more  Source. fn by_uniform_blocks(self, block_size ...",
            "Searches for **some** item in the parallel iterator that\nmatches the given predicate, and if so returns true. Once\na match is found, well attempt to stop process the rest\nof the items. Proving that theres no match, returning false,\ndoes require visiting every item.",
            "Tests that every item in the parallel iterator matches the given\npredicate, and if so returns true. If a counter-example is found,\nwell attempt to stop processing more items, then return false.",
            "Searches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index.",
            "Searches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index",
            "Applies the given predicate to the items in the parallel iterator and\nreturns the sequentially **last** non-None result of the map operation.",
            "Applies the given predicate to the items in the parallel iterator and\nreturns the sequentially **first** non-None result of the map operation.",
            "Searches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more."
          ]
        },
        {
          "title": "rayon::iter::plumbing - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/plumbing/index.html",
          "excerpts": [
            "This helper function is used to connect a parallel iterator to a consumer. It will convert the par_iter into a producer P and then pull items from P and feed...",
            "Traits and functions used to implement parallel iteration. These are\nlow-level details  users of parallel iterators should not need to\ninteract with them directly. See [the `plumbing` README](https://github.com/rayon-rs/rayon/blob/main/src/iter/plumbing/README.md) for a general overvi"
          ]
        },
        {
          "title": "Idiomatic way to implement shared state and behavior? - help",
          "url": "https://users.rust-lang.org/t/idiomatic-way-to-implement-shared-state-and-behavior/94641",
          "excerpts": [
            "I am building a falling sand simulation where I want to have different types of sand that each have different properties."
          ]
        },
        {
          "title": "Deadlock anti-patterns #1: No arbitration",
          "url": "https://www.infoworld.com/article/2163790/deadlock-anti-patterns-1-no-arbitration.html",
          "excerpts": [
            "Starvation occurs when one or more threads of execution are prevented from proceeding beyond a given point due to a predicate that will never be satisfied."
          ]
        },
        {
          "title": "How to dispatch work to rayon::ThreadPool",
          "url": "https://users.rust-lang.org/t/how-to-dispatch-work-to-rayon-threadpool/40918",
          "excerpts": [
            "Apr 13, 2020  If it's pretty small, you could try batching several together per spawn , locking the map just once for the group as late as possible. 1 Like."
          ]
        },
        {
          "title": "The Fastest Mutexes",
          "url": "https://news.ycombinator.com/item?id=41721668",
          "excerpts": [
            "... batching these samples. This dramatically saves IPC costs because you only need to lock these mutexes at 100Hz when batching 480 samples = 10ms of audio."
          ]
        },
        {
          "title": "Diving into Rust's Concurrency: Practical Tips and Tricks - Medium",
          "url": "https://medium.com/@giorgio.martinez1926/diving-into-rusts-concurrency-practical-tips-and-tricks-36148f2cd4fe",
          "excerpts": [
            "By leveraging techniques like interior mutability (e.g., using Mutex or RwLock ), you can safely share mutable data across multiple threads ..."
          ]
        },
        {
          "title": "Which is more efficient, basic mutex lock or atomic integer?",
          "url": "https://stackoverflow.com/questions/15056237/which-is-more-efficient-basic-mutex-lock-or-atomic-integer",
          "excerpts": [
            "Summing up, in general atomic operations are faster if contention between threads is sufficiently low. You should definitely do benchmarking ..."
          ]
        },
        {
          "title": "Mastering Rust Concurrency: Atomics, Locks, and Threads",
          "url": "https://www.bytemagma.com/index.php/rust-programming/mastering-rust-concurrency-atomics-locks-and-threads",
          "excerpts": [
            "Lock contention happens when two or more threads try to acquire the same mutex at the same time. Only one can proceed; the others must wait. In ... Next, we'll go deeper into shared mutability, exploring how to combine Arc with Mutex to safely read and write shared state from multiple ..."
          ]
        },
        {
          "title": "Concurrency  list of Rust libraries/crates ...",
          "url": "https://lib.rs/concurrency",
          "excerpts": [
            "Gracefully error when a thread attempts to acquire the same lock twice. v0.1 ... A lock manager with batch-lock support. v0.1.2 #locking #manager #batch..."
          ]
        },
        {
          "title": "Multicore dedup Vec<(u64, u64)>?",
          "url": "https://users.rust-lang.org/t/multicore-dedup-vec-u64-u64/80654",
          "excerpts": [
            "Sep 1, 2022  Here's a kludgy way to do a parallel dedup iterator from a slice with rayon: pub fn par_dedup<T: Eq + Sync>(slice: &[T]) -> impl..."
          ]
        },
        {
          "title": "Mastering Rust Arc and Mutex: A Comprehensive Guide to ...",
          "url": "https://medium.com/@Murtza/mastering-rust-arc-and-mutex-a-comprehensive-guide-to-safe-shared-state-in-concurrent-programming-1913cd17e08d",
          "excerpts": [
            "Rust's Arc and Mutex are a dynamic duo for managing shared state in concurrent programming, blending safety with performance in a way only Rust can."
          ]
        },
        {
          "title": "Over-parallelizing with too fine-grained tasks harms speedup",
          "url": "https://docs.ray.io/en/latest/ray-core/patterns/too-fine-grained-tasks.html",
          "excerpts": [
            "Anti-pattern: Over-parallelizing with too fine-grained tasks harms speedup#. TLDR: Avoid over-parallelizing. Parallelizing tasks has higher overhead than..."
          ]
        },
        {
          "title": "Shared-State Concurrency - The Rust Programming ...",
          "url": "https://doc.rust-lang.org/book/ch16-03-shared-state.html",
          "excerpts": [
            "Shared memory concurrency is like multiple ownership: multiple threads can access the same memory location at the same time."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://doc.servo.org/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "This can have many applications but the most notable ones are: better performance with find_first(); more predictable performance with find_any() or any ..."
          ]
        },
        {
          "title": "How to process Results with Rayon parallel iterator? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/79236766/how-to-process-results-with-rayon-parallel-iterator",
          "excerpts": [
            "Rayon's ParallelIterator has a few try_ methods like try_fold() but there doesn't seem to be a try_map() or try_collect()."
          ]
        },
        {
          "title": "Rust `find_any` keeps searching - parallel processing - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76822783/rust-find-any-keeps-searching",
          "excerpts": [
            "\"Searches for some item in the parallel iterator that matches the given predicate and returns it. This operation is similar to find on ..."
          ]
        },
        {
          "title": "Iter in rayon::collections::binary_heap - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/collections/binary_heap/struct.Iter.html",
          "excerpts": [
            "The type of item that this parallel iterator produces. For example, if you use the for_each method, this is the type of item that your closure will be invoked ..."
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ..."
          ]
        },
        {
          "title": "rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/index.html",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ..."
          ]
        },
        {
          "title": "rayon - Rust - Difftastic",
          "url": "https://difftastic.wilfred.me.uk/rustdoc/rayon/index.html",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ..."
          ]
        },
        {
          "title": "Rayon find_any, and return the found item's value - Stack Overflow",
          "url": "https://stackoverflow.com/questions/55959715/rayon-find-any-and-return-the-found-items-value",
          "excerpts": [
            "Rayon's .flat_map(...) method will apply f to each element, treat each return value as an iterator, and flatten all of those results into a single new iterator."
          ]
        },
        {
          "title": "Data Parallelism - Rust Cookbook",
          "url": "https://rust-lang-nursery.github.io/rust-cookbook/concurrency/parallel.html",
          "excerpts": [
            "rayon::any checks in parallel whether any element of the iterator matches the predicate, and returns as soon as one is found. rayon::all checks in parallel ...",
            "The example uses the rayon crate, which is a data parallelism library for Rust. rayon provides the par_iter_mut method for any parallel iterable data type."
          ]
        },
        {
          "title": "blocks.rs source code [crates/rayon/src/iter/blocks.rs] - Codebrowser",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/blocks.rs.html",
          "excerpts": [
            "Source code of blocks.rs rayon 1.10.0 on KDAB Codebrowser. ... /// This struct is created by the [`by_exponential_blocks()`] method on [`IndexedParallelIterator`]."
          ]
        },
        {
          "title": "Rayon ParallelIterator documentation (src/rayon/iter/mod.rs.html)",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.MultiZip.html",
          "excerpts": [
            "1)\n\n#### fn [any](trait.ParallelIterator.html.any)<P>(self, predicate: P) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) where P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\")(Self::[Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\")) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\"),\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and if so returns true. Once\na match is found, well attempt to stop process the rest\nof the items. Proving that theres no match, returning false,\ndoes require visiting every item.\n[Read more](trait.ParallelIterator.html.any)\n\n[Source](../../src/rayon/iter/mod.rs.html)[](.all-1)",
            "#### fn [find\\_any](trait.ParallelIterator.html.find_any)<P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\")<Self::[Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\")> where P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\")(&Self::[Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\")) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\"),\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate and returns it. This operation\nis similar to [`find` on sequential iterators](https://doc.rust-lang.org/nightly/core/iter/traits/iterator/trait.Iterator.html.find \"method core::iter::traits::iterator::Iterator::find\") but\nthe item returned may not be the **first** one in the parallel\nsequence which matches, since we search the entire sequence in parallel.\n ... \n[Read more](trait.ParallelIterator.html.find_map_last)\n\n[Source](../../src/rayon/iter/mod.rs.html)[](.any-5)",
            "\n#### fn [all](trait.ParallelIterator.html.all)<P>(self, predicate: P) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) where P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\")(Self::[Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\")) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\"),\n\nTests that every item in the parallel iterator matches the given\npredicate, and if so returns true. If a counter-example is found,\nwell attempt to stop processing more items, then return false.\n ... \n[Read more](trait.ParallelIterator.html.chain)\n\n[Source](../../src/rayon/iter/mod.rs.html)[](.find_any-6)"
          ]
        },
        {
          "title": "rayon::iter - Rust",
          "url": "https://doc.servo.org/rayon/iter/index.html",
          "excerpts": [
            "ExponentialBlocks is a parallel iterator that consumes itself as a sequence of parallel blocks of increasing sizes (exponentially). Filter. Filter takes a..."
          ]
        },
        {
          "title": "Struct Skip - prelude::cara::rayon::iter - cellular-raza.com",
          "url": "https://www.cellular-raza.com/docs/cellular_raza/prelude/cara/rayon/iter/struct.Skip.html",
          "excerpts": [
            "fn by_exponential_blocks(self) -> ExponentialBlocks<Self>. Divides an iterator into sequential blocks of exponentially-increasing size. Read more. . fn..."
          ]
        },
        {
          "title": "Use rayon's parallel iterator on any iterator without ...",
          "url": "https://users.rust-lang.org/t/use-rayons-parallel-iterator-on-any-iterator-without-collecting-first/17280",
          "excerpts": [
            "May 7, 2018  The find_items_to_process_iter is I/O-bound and takes long time to complete. The process_item is CPU-bound. Ideally I'd like items to be... Use rayon's parallel iterator on any iterator without collecting first ... I've got a process like this: find_items_to_process_iter() // .",
            "Use rayon's parallel iterator on any iterator without collecting first ... Conversion trait to convert an `Iterator` to a `ParallelIterator`. Use rayon's parallel iterator on any iterator without collecting first ... I've got a process like this: find_items_to_process_iter() // ."
          ]
        },
        {
          "title": "wasm-bindgen-rayon 1.2.0 release: you can now use parallel Rust ...",
          "url": "https://www.reddit.com/r/WebAssembly/comments/1995a8b/wasmbindgenrayon_120_release_you_can_now_use/",
          "excerpts": [
            "wasm-bindgen-rayon 1.2.0 release: you can now use parallel Rust iterators from the main Wasm thread. Not completely isolated - in theory you just need to add `Cross-Origin-Resource-Policy: cross-origin` in addition to COOP/COEP headers, or set..."
          ]
        },
        {
          "title": "SharedArrayBuffer - JavaScript - MDN - Mozilla",
          "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer",
          "excerpts": [
            "Jul 10, 2025  SharedArrayBuffer is a raw binary data buffer used to create views on shared memory, allowing shared data between agents, but is not..."
          ]
        },
        {
          "title": "SharedArrayBuffer will require cross-origin isolation as of ...",
          "url": "https://stackoverflow.com/questions/66489286/sharedarraybuffer-will-require-cross-origin-isolation-as-of-m91-around-may-2021",
          "excerpts": [
            "As the warning shows, Chrome will require cross-origin isolation starting version 91 in order to use SharedArrayBuffer."
          ]
        },
        {
          "title": "Creating a web worker from Rust/Wasm using a bundler",
          "url": "https://users.rust-lang.org/t/creating-a-web-worker-from-rust-wasm-using-a-bundler/104866",
          "excerpts": [
            "With @wasmer/sdk , we've made a Rust library that gets compiled to WebAssembly and uses Web Workers to implement a thread pool. When spawning ...",
            "Jan 5, 2024  It would be easiest for me to pass Rust objects to the worker, not JS objects. For this reason the shared memory approach discussed at Threads..."
          ]
        },
        {
          "title": "Use multi-threading using the rayon crate | TFHE-rs - Zama Docs",
          "url": "https://docs.zama.ai/tfhe-rs/0.5-3/how-to/rayon_crate",
          "excerpts": [
            "rayon is a popular crate to easily write multi-threaded code in Rust. It is possible to use rayon to write multi-threaded TFHE-rs code. Jan 30, 2024  rayon is a popular crate to easily write multi-threaded code in Rust. It is possible to use rayon to write multi-threaded TFHE-rs code."
          ]
        },
        {
          "title": "initThreadPool freezing after call  Issue #22 - GitHub",
          "url": "https://github.com/GoogleChromeLabs/wasm-bindgen-rayon/issues/22",
          "excerpts": [
            "It's surprising that you didn't see an error message in the Console, both Chrome and Firefox should complain when you're trying to use Wasm ...",
            "Dec 14, 2021  I'm trying to make the basic example with the sum function work #[wasm_bindgen] pub fn sum(numbers: &[i32]) -> i32..."
          ]
        },
        {
          "title": "Multithreading with WASM on the Browser. Is it possible yet? - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1cwmyaw/multithreading_with_wasm_on_the_browser_is_it/",
          "excerpts": [
            "The Wasm threads proposal addresses synchronization by adding atomic instructions, including futex-like wait/wake instructions you can use to ... Short answer: Web workers, atomics, and SharedArrayBuffers basically provide all the ingredients for multithreading. But it involves calling JS APIs through ..."
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "In order to use `SharedArrayBuffer` on the Web, you need to enable [cross-origin isolation policies](https://web.dev/coop-coep/) . Check out the linked article for details. Then, add `wasm-bindgen` , `rayon` , and this crate as dependencies to your `Cargo.toml` :",
            "```\n[ dependencies ]\nwasm-bindgen = \" 0.2 \"\nrayon = \" 1.8 \"\nwasm-bindgen-rayon = \" 1.2 \"\n```\n",
            "Then, reexport the `init_thread_pool` function:\n\n```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:\n\n```\nimport init , { initThreadPool /* ... */ } from './pkg/index.js' ;\n\n// Regular wasm-bindgen initialization. await init ( ) ;\n\n// Thread pool initialization with the given number of threads\n// (pass \\`navigator.hardwareConcurrency\\` if you want to use all cores). await initThreadPool ( navigator . hardwareConcurrency ) ;\n\n// ...now you can invoke any exported functions as you normally would\n```\n",
            "Use [Rayon](https://github.com/rayon-rs/rayon) iterators as you normally would, e.g. ```\n# [ wasm_bindgen ]\npub fn sum ( numbers : & [ i32 ] ) -> i32 {\n    numbers . par_iter ( ) .\nsum ( )\n}\n```\n\nwill accept an `Int32Array` from JavaScript side and calculate the sum of its values using all available threads. ## Building Rust code\n\n[]()\n\nFirst limitation to note is that you'll have to use `wasm-bindgen` / `wasm-pack` 's `web` target ( `--target web` ). _Why?_\n\nThis is because the Wasm code needs to take its own object (the `WebAssembly.Module` ) and share it with other threads when spawning them. This object is only accessible from the `--target web` and `--target no-modules` outputs, but we further restrict it to only `--target web` as we also use [JS snippets feature](https://rustwasm.github.io/wasm-bindgen/reference/js-snippets.html) . The other issue is that the Rust standard library for the WebAssembly target is built without threads support to ensure maximum portability. Since we want standard library to be thread-safe and [`std::sync`](https://doc.rust-lang.org/std/sync/) APIs to work, you'll need to use the nightly compiler toolchain and pass some flags to rebuild the standard library in addition to your own code. In order to reduce risk of breakages, it's strongly recommended to use a fixed nightly version. This crate was tested with `nightly-2024-08",
            "```\nimport init , { initThreadPool /* ... */ } from './pkg/index.js' ;\n\n// Regular wasm-bindgen initialization. await init ( ) ;\n\n// Thread pool initialization with the given number of threads\n// (pass \\`navigator.hardwareConcurrency\\` if you want to use all cores). await initThreadPool ( navigator . hardwareConcurrency ) ;\n\n// ...now you can invoke any exported functions as you normally would\n`",
            "For a quick demo, check out [this Mandelbrot fractal generator](https://rreverser.com/wasm-bindgen-rayon-demo/) :",
            "Then, reexport the `init_thread_pool` function:",
            "The easiest way to configure those flags is:\n\n1.\n ... \nYou only need to copy it once and hopefully forget about it :)\n",
            "```\nimport init , { initThreadPool /* ... */ } from './pkg/index.js' ;\n\n// Regular wasm-bindgen initialization. await init ( ) ;\n\n// Thread pool initialization with the given number of threads\n// (pass \\`navigator.hardwareConcurrency\\` if you want to use all cores). await initThreadPool ( navigator . hardwareConcurrency ) ;\n\n// ...now you can invoke any exported functions as you normally would\n```\n",
            "## Using Rayon\n",
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "This is because the Wasm code needs to take its own object (the `WebAssembly.Module` ) and share it with other threads when spawning them. This object is only accessible from the `--target web` and `--target no-modules` outputs, but we further restrict it to only `--target web` as we also use [JS snippets feature](https://rustwasm.github.io/wasm-bindgen/reference/js-snippets.html) .",
            "The other issue is that the Rust standard library for the WebAssembly target is built without threads support to ensure maximum portability. Since we want standard library to be thread-safe and [`std::sync`](https://doc.rust-lang.org/std/sync/) APIs to work, you'll need to use the nightly compiler toolchain and pass some flags to rebuild the standard library in addition to your own code.",
            "In order to reduce risk of breakages, it's strongly recommended to use a fixed nightly version. This crate was tested with `nightly-2024-08-02` .",
            "\n## Usage with various bundlers",
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]",
            "## Feature detection",
            "```",
            "import { threads } from 'wasm-feature-detect' ;",
            "let wasmPkg ;",
            "if ( await threads ( ) ) {",
            "  wasmPkg = await import ( './pkg-with-threads/index.js' ) ;",
            "  await wasmPkg .",
            "default ( ) ;",
            "  await wasmPkg . initThreadPool ( navigator . hardwareConcurrency ) ;",
            "} else {",
            "  wasmPkg = await import ( './pkg-without-threads/index.js' ) ;",
            "  await wasmPkg . default ( ) ;",
            "}",
            "```\n",
            "### Using config files",
            "[ dependencies ]",
            "wasm-bindgen-rayon = \" 1.2 \"",
            "// ..."
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}",
            "```\n"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Unlike Emscripten, Rust doesn't have a specialized end-to-end web target, but instead provides a\ngeneric `wasm32-unknown-unknown` target for generic WebAssembly output. If Wasm is intended to be used in a web environment, any interaction with JavaScript APIs is left to\nexternal libraries and tooling like [wasm-bindgen](https://rustwasm.github.io/docs/wasm-bindgen/) and [wasm-pack](https://rustwasm.github.io/docs/wasm-pack/) .",
            "In particular, [Rayon](https://crates.io/crates/rayon) is the most popular choice for\ndata-parallelism in Rust. It allows you to take method chains on regular iterators and, usually with\na single line change, convert them in a way where they'd run in parallel on all available threads\ninstead of sequentially. For example:\n\n```\n`pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . iter () \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nWith this small change, the code will split up the input data, calculate `x * x` and partial sums in\nparallel threads, and in the end add up those partial results togethe",
            "Luckily, the majority of the ecosystem depends on higher-level libraries to take care of\nmultithreading. At that level it's much easier to abstract away all the platform differences. In particular, [Rayon](https://crates.io/crates/rayon) is the most popular choice for\ndata-parallelism in Rust. It allows you to take method chains on regular iterators and, usually with\na single line change, convert them in a way where they'd run in parallel on all available threads\ninstead of sequentially. For example:",
            "Rayon provides hooks that allow to\ndefine custom logic for spawning and exiting threads. [wasm-bindgen-rayon](https://github.com/GoogleChromeLabs/wasm-bindgen-rayon) taps into those hooks\nto spawn WebAssembly threads as Web Workers. To use it, you need to add it as a dependency and\nfollow the configuration steps described in the [docs](https://github.com/GoogleChromeLabs/wasm-bindgen-rayon) .",
            "Note that the same [caveats](https://github.com/GoogleChromeLabs/wasm-bindgen-rayon) about\nblocking the main thread apply here too. Even the `sum_of_squares` example still needs to block the\nmain thread to wait for the partial results from other threads.",
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`",
            "s would be too expensive.\nTo opt-in, add the following headers to the main document in your\nserver configuration:\n\n```\n`Cross-Origin-Embedder-Policy: require-corp \n Cross-Origin-Opener-Policy: same-origin \n`\n```\n\nOnce you opt-in, you get access to `SharedArrayBuffer` (including `WebAssembly.Memory` backed by a `SharedArrayBuffer` ), precise timers, memory measurement and other APIs that require an isolated\norigin for security reason",
            "// Regular wasm - bindgen initialization . await init ();",
            "Once you opt-in, you get access to `SharedArrayBuffer` (including `WebAssembly.Memory` backed by a `SharedArrayBuffer` ), precise timers, memory measurement and other APIs that require an isolated\norigin for security reasons"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Allow setting COOP and COEP headers in Github Pages #13309",
          "url": "https://github.com/orgs/community/discussions/13309",
          "excerpts": [
            "In order to use SharedArrayBuffer and WebAssembly Threads, COOP and COEP headers need to be set, such that the page becomes cross-origin isolated."
          ]
        },
        {
          "title": "rayon_wasm - Rust",
          "url": "https://docs.rs/rayon-wasm",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel, and is lightweight and convenient."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()",
            "One of the major gotchas with threaded WebAssembly is that Rust does not ship a\nprecompiled target (e.g. standard library) which has threading support enabled.\n ... \nThis is because the WebAssembly file\nimports memory instead of exporting it, so we need to hook initialization of the\nwasm module at this time to provide the appropriate memory object. This demo\nuses `--target no-modules`, because Firefox does not support modules in workers. With `--target no-modules` you'll be able to use `importScripts` inside of each\nweb worker to import the shim JS generated by `wasm-bindgen` as well as calling\nthe `wasm_bindgen` initialization function with the shared memory instance from\nthe main thread. The expected usage is that WebAssembly on the main thread will\npost its memory object to all other threads to get instantiated with.",
            "Unfortunately at this time running Wasm on the web with threads has a number of\ncaveats, although some are specific to just `wasm-bindgen`. These are some\npieces to consider and watch out for, although we're always looking for\nimprovements to be made so if you have an idea please file an issue! * The main thread in a browser cannot block. This means that if you run\n  WebAssembly code on the main thread you can *never* block, meaning you can't\n  do so much as acquire a mutex. This is an extremely difficult limitation to\n  work with on the web, although one workaround is to run Wasm exclusively in\n  web workers and run JS on the main thread. It is possible to run the same wasm\n  across all threads, but you need to be extremely vigilant about\n  synchronization with the main thread.",
            "* Setting up a threaded environment is a bit wonky and doesn't feel smooth\n  today. For example `--target bundler` is unsupported and very specific shims\n  are required on both the main thread and worker threads. These are possible to\n  work with but are somewhat brittle since there's no standard way to spin up\n  web workers as Wasm threads.",
            "There is no standard notion of a \"thread\". For example the standard library\n  has no viable route to implement the `std::thread` module. As a consequence\n  there is no concept of thread exit and TLS destructors will never run. We do expose a helper, `__wbindgen_thread_destroy`, that deallocates\n  the thread stack and TLS. If you invoke it, it *must* be the last function\n  you invoke from the Wasm module for a given thread.",
            "Web Workers executing WebAssembly code cannot receive events from JS. A Web\n  Worker has to fully return back to the browser (and ideally should do so\n  occasionally) to receive JS messages and such. This means that common\n  paradigms like a rayon thread pool do not apply straightforward-ly to the web.",
            "export RUSTFLAGS='-C target-feature=+atomics,+bulk-memory,+mutable-globals'",
            "After this `cargo build` should produce a WebAssembly file with threading\nenabled, and the standard library will be appropriately compiled as well. The final step in this is to run `wasm-bindgen` as usual, and `wasm-bindgen` needs no extra configuration to work with threads.",
            "The intention of the web is that all long-term blocking happens in the browser\n  itself, not in each thread, but many crates in the ecosystem leveraging\n  threading are not necessarily engineered this "
          ]
        },
        {
          "title": "Rust + WASM: 10 Steps to Native-Fast Web | by Hash Block - Medium",
          "url": "https://medium.com/@connect.hashblock/rust-wasm-10-steps-to-native-fast-web-91cac85eadb8",
          "excerpts": [
            "... wasm-bindgen-rayon then initThreadPool() to match cores. For many apps, plain Workers + batching are enough and simpler to reason about. 5) ... If you need shared state or Rayon-style parallelism, set up cross-origin isolation and use a threads-enabled build with wasm-bindgen-rayon then ...",
            "Ten concrete steps to build native-fast web apps with Rust and WebAssembly  covering components, data flow, SIMD, threads, workers, ... ... wasm-bindgen-rayon then initThreadPool() to match cores. For many apps, plain Workers + batching are enough and simpler to reason about. 5) ..."
          ]
        },
        {
          "title": "Rust/wasm32 webworker parallelism/messaging primitives?",
          "url": "https://users.rust-lang.org/t/rust-wasm32-webworker-parallelism-messaging-primitives/77656",
          "excerpts": [
            "You could use GitHub - GoogleChromeLabs/wasm-bindgen-rayon: An adapter for enabling Rayon-based concurrency on the Web with WebAssembly. if ... You could use GitHub - GoogleChromeLabs/wasm-bindgen-rayon: An adapter for enabling Rayon-based concurrency on the Web with WebAssembly. if you ..."
          ]
        },
        {
          "title": "Web(Wasm) setup - Mopro",
          "url": "https://zkmopro.org/docs/setup/web-wasm-setup/",
          "excerpts": [
            "Initializing with initThreadPool is necessary to enable multi-threading n WebAssembly within the browser. Note that the web template generated using the mopro ... This tutorial will show you how to build static library for web browser. Before proceeding, ensure that Rust, Wasm-Pack and Chrome are installed."
          ]
        },
        {
          "title": "The `wasm-bindgen` Guide - Rust and WebAssembly",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/print.html",
          "excerpts": [
            "Introduction. This book is about wasm-bindgen , a Rust library and CLI tool that facilitate high-level interactions between Wasm modules and JavaScript."
          ]
        },
        {
          "title": "Nine Rules for Running Rust on WASM WASI - Medium",
          "url": "https://medium.com/data-science/nine-rules-for-running-rust-on-wasm-wasi-550cd14c252a",
          "excerpts": [
            "This allows you to tailor dependencies to different targets. For example, this says depend on Criterion with Rayon when not targeting wasm32 . This first article focuses on running code on WASM WASI, a container-like environment. We'll see that WASM WASI may (or may not) be useful in its own right."
          ]
        },
        {
          "title": "wasm-bindgen-rayon - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/wasm-bindgen-rayon/dependencies",
          "excerpts": [
            "Bindings for all JS global objects and functions in all JS environments like Node.js and browsers, built on `#[wasm_bindgen]` using the `wasm-bindgen` crate ... Bindings for all JS global objects and functions in all JS environments like Node.js and browsers, built on `#[wasm_bindgen]` using the `wasm-bindgen` crate."
          ]
        },
        {
          "title": "Demo for Rust + WebAssembly threads",
          "url": "https://rreverser.com/wasm-bindgen-rayon-demo/",
          "excerpts": [
            "This is a demo for wasm-bindgen-rayon, generating a Mandelbrot fractal with WebAssembly threads. Click one of the buttons to see the image & timings."
          ]
        },
        {
          "title": "I forked rayon to use rayon-style API with switchable ...",
          "url": "https://www.reddit.com/r/rust/comments/1jk6fzt/i_forked_rayon_to_use_rayonstyle_api_with/",
          "excerpts": [
            "js or rspack and disable parallelism for Wasm targets. Rayon already does this for Wasm targets, implicitly switching to sequential algorithm."
          ]
        },
        {
          "title": "GitHub - GoogleChromeLabs/wasm-bindgen-rayon",
          "url": "https://github.com/GoogleChromeLabs/wasm-bindgen-rayon",
          "excerpts": [
            "This repository was archived by the owner on Jul 17, 2024. It is now read-only. [GoogleChromeLabs](/GoogleChromeLabs) / **[wasm-bindgen-rayon](/GoogleChromeLabs/wasm-bindgen-rayon)** Public archive",
            "The continued development of this project has moved to [a personal fork](https://github.com/RReverser/wasm-bindgen-rayon) .",
            "An adapter for enabling Rayon-based concurrency on the Web with WebAssembly."
          ]
        },
        {
          "title": "r/rust on Reddit: wasm-bindgen-rayon: an adapter for enabling ...",
          "url": "https://www.reddit.com/r/rust/comments/m7stbw/wasmbindgenrayon_an_adapter_for_enabling/",
          "excerpts": [
            "We use Rayon + wasm-bindgen for OxiPNG in https://squoosh.app/ - an open-source project for image compression directly in the browser."
          ]
        },
        {
          "title": "wasm_bindgen_spawn - Rust",
          "url": "https://docs.rs/wasm-bindgen-spawn",
          "excerpts": [
            "A Web Worker based multithreading library for Rust and WebAssembly. This uses the WebAssembly threads proposal and shared memory to communicate between workers."
          ]
        },
        {
          "title": "Threads and messages with Rust and WebAssembly",
          "url": "https://tweag.io/blog/2022-11-24-wasm-threads-and-messages/",
          "excerpts": [
            "Nov 24, 2022  Memory chunks can be shared between WASM modules, so we can instantiate a new module using the same memory as the first one, and the two modules..."
          ]
        },
        {
          "title": "wasm-bindgen-rayon on crates.io",
          "url": "https://crates.io/crates/wasm-bindgen-rayon/1.1.3",
          "excerpts": [
            "\n\nwasm-bindgen-rayon v1.1.3",
            "3\nAdapter for using Rayon-based concurrency on the Web"
          ]
        },
        {
          "title": "Nested parallelism and Rayon - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/nested-parallelism-and-rayon/84210",
          "excerpts": [
            "It's fine, as long as you're not using an external mechanism to block threads. If they're perfectly balanced, the sub-parts of A will each run their B to completion on their current thread. If it's not balanced, then work stealing will spread the load when any thread would go idle.",
            "Nov 13, 2022  You have a CPU with 16 cores, and using rayon, you have distributed task A across all 16 cores. But to complete task A it calls on an algorithm B that itself... You have a CPU with 16 cores, and using rayon, you have distributed task A across all 16 cores. But to complete task A it calls on an algorithm B that itself ...",
            "To be concrete: _B_ 's parallel work should be using _the same thread that called `par_iter()`_ to do the computation."
          ]
        }
      ],
      "reasoning": "- The core idiom highlighted in the field value is to express parallelism idiomatically by converting a sequential iterator into Rayons parallel counterpart, typically by replacing a normal iterator call like iter() with par_iter(). This is explicitly stated as the primary idiom: changing foo.iter() to foo.par_iter() to enable parallel execution, while leveraging the high-level parallel iterator methods (map, fold, reduce, etc.). This is the defining pattern that makes code idiomatic in Rayon and is designed to yield high efficiency with minimal boilerplate. A second, closely related idiom is to use the Rayon prelude to bring in the necessary traits so that par_iter and related methods are in scope, enabling ergonomic usage without manual trait work. The idea is to embrace high-level abstractions rather than manual thread management, which reduces bugs and improves readability. The data-race freedom guarantee is a fundamental design principle that supports safety of idiomatic Rayon usage: if the code compiles, it is typically free of data races due to Rusts safety guarantees, and parallel iterators preserve results with the same semantics as sequential iterators (modulo non-deterministic ordering for some side effects). Regarding parallel control flow constructs, join and scope are presented as canonical idioms for divide-and-conquer parallelism: join splits a task into two parallel sub-tasks, and scope allows spawning multiple parallel tasks within a fork-join scope, with explicit notes about when results are ready and ordering may be non-deterministic. The par_bridge facility is the idiomatic bridge from a regular iterator to a parallel one, enabling parallel workflows when you cannot directly produce a parallel iterator from a collection. The mixture of these idiomspar_iter, prelude for ergonomic access, join/scope for explicit parallelism, and par_bridge for bridging non-parallel sourcesconstitutes the canonical idioms in Rayon for turning sequential code into parallel, efficient, and safe code. The quotes illustrate these core ideas: a simple replacement of iter with par_iter to enable parallel processing; the use of map, fold, reduce on parallel iterators to express data-parallel computations; and the emphasis on data-race freedom and non-deterministic ordering for side effects as a design feature rather than a bug. Based on the corpus, these excerpts collectively provide strong, coherent support for the claim that Rayon idioms center on idiomatic conversion of sequential code to parallel iterators, reliance on high-level parallel operations, avoidance of manual threading, and the safety guarantees that make this approach reliable.",
      "confidence": "high"
    },
    {
      "field": "platform_specific_patterns_wasm.1.anti_patterns",
      "citations": [
        {
          "title": "Allow setting COOP and COEP headers in Github Pages #13309",
          "url": "https://github.com/orgs/community/discussions/13309",
          "excerpts": [
            "In order to use SharedArrayBuffer and WebAssembly Threads, COOP and COEP headers need to be set, such that the page becomes cross-origin isolated."
          ]
        },
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon.",
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "## Using Rayon\n",
            "\n\nWebAssembly threads use Web Workers under the hood for instantiating other threads with the same WebAssembly module & memory. wasm-bindgen-rayon provides the required JS code for those Workers internally, and [uses a syntax that is recognised across various bundlers]"
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        }
      ],
      "reasoning": "The claimed anti-pattern asserts that initializing or using a Wasm thread pool on a non-cross-origin-isolated page will fail and degrade to single-threaded execution, undermining parallelism gains. The most directly supporting information states that to use SharedArrayBuffer and WebAssembly threads, COOP and COEP headers must be set to achieve cross-origin isolation, which is a prerequisite for threading on the web. This establishes the concrete condition that the anti-pattern depends on: without cross-origin isolation, threading is not available. Additional excerpts describe that wasm-bindgen-rayon provides and initializes a thread pool via an initThreadPool function, and that a pool of workers is created for multithreaded operations, reinforcing that a proper, isolated environment is essential for thread pools to function as intended. Other excerpts outline the general role of WebAssembly threads and how the thread pool is initialized and used in examples, further linking to the anti-pattern by showing that the feature relies on correct environment setup (cross-origin isolation) and proper initialization order. Therefore, the anti-pattern claim is most strongly anchored by the explicit cross-origin isolation requirement, with complementary support showing the threading infrastructure and initialization sequence that would be ineffective or error-prone if the isolation prerequisites are not met.",
      "confidence": "medium"
    },
    {
      "field": "platform_specific_patterns_wasm.0.alternate_patterns",
      "citations": [
        {
          "title": "Using WebAssembly threads from C, C++ and Rust",
          "url": "https://web.dev/articles/webassembly-threads",
          "excerpts": [
            "The example above will\nend up looking like this:\n\n```\n`pub use wasm_bindgen_rayon : : init_thread_pool ; \n\n # [ wasm_bindgen ] \n pub fn sum_of_squares ( numbers : & [ i32 ] ) - > i32 { \n  numbers \n  . par_iter () \n  . map ( | x | x * x ) \n  . sum () \n } \n`\n```\n\nOnce done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon. This pool mechanism is similar to the `-s PTHREAD_POOL_SIZE=...` option in Emscripten explained\nearlier, and also needs to be initialized before the main code to avoid deadlocks:\n\n```\n``import init , { initThreadPool , sum_of_squares } from './pkg/index.js' ; \n\n // Regular wasm - bindgen initialization . await init (); \n\n // Thread pool initialization with the given number of threads \n // ( pass ` navigator . hardwareConcurrency ` if you want to use all cores ) . await initThreadPool ( navigator . hardwareConcurrency ); \n\n // ... now you can invoke any exported functions as you normally would \n console . log ( sum_of_squares ( new Int32Array ([ 1 , 2 , 3 ]))); // 14 \n`",
            "Once done, the generated JavaScript will export an extra `initThreadPool` function. This function\nwill create a pool of Workers and reuse them throughout the lifetime of the program for any\nmultithreaded operations done by Rayon."
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "```\npub use wasm_bindgen_rayon :: init_thread_pool ;\n\n// ...\n```\n\nThis will expose an async `initThreadPool` function in the final generated JavaScript for your library. You'll need to invoke it right after instantiating your module on the main thread in order to prepare the threadpool before calling into actual library functions:",
            "The other issue is that the Rust standard library for the WebAssembly target is built without threads support to ensure maximum portability. Since we want standard library to be thread-safe and [`std::sync`](https://doc.rust-lang.org/std/sync/) APIs to work, you'll need to use the nightly compiler toolchain and pass some flags to rebuild the standard library in addition to your own code."
          ]
        },
        {
          "title": "wasm_bindgen_rayon - Rust",
          "url": "https://docs.rs/wasm-bindgen-rayon",
          "excerpts": [
            "wasm-bindgen-rayon is an adapter for enabling Rayon-based concurrency on the Web with WebAssembly (via wasm-bindgen, Web Workers and SharedArrayBuffer support)."
          ]
        },
        {
          "title": "Rayon in WASM: Idioms and Caveats (Rust with wasm-bindgen-rayon example)",
          "url": "https://rustwasm.github.io/docs/wasm-bindgen/examples/raytrace.html",
          "excerpts": [
            "This is an example of using threads with WebAssembly, Rust, and `wasm-bindgen`,\nculminating in a parallel raytracer demo. There's a number of moving pieces to\nthis demo and it's unfortunately not the easiest thing to wrangle, but it's\nhoped that this'll give you a bit of a taste of what it's like to use threads\nand Wasm with Rust on the web. [### Building the demo]()"
          ]
        }
      ],
      "reasoning": "The most relevant content directly demonstrates the alternative pattern of using a thread pool and Web Workers for Rayon in Wasm. In particular, an example shows initializing a thread pool and using a thread pool mechanism within the Wasm module, which aligns with the proposed alternate pattern of avoiding UI-blocking by moving parallel work into a dedicated worker. Additional excerpts discuss exposing an initThreadPool function and the general approach of creating and reusing a pool of workers for multithreaded Rayon operations, which backs the concept of an alternate pattern beyond a simple default sequential fallback. Another excerpt notes that wasm-bindgen-rayon provides the necessary integration to enable Rayon-based concurrency on the Web with Web Workers, reinforcing the feasibility of the alternate pattern. A supporting excerpt highlights the need to work with WebAssembly threads and worker ecosystems, including caveats around thread support in the std library for Wasm targets, which contextualizes why an alternate pattern (using a worker pool) is considered. The reference to a concrete demo using threads with Wasm and Rust underscores the practicality and expectations of such an alternate pattern in real projects.",
      "confidence": "high"
    },
    {
      "field": "interoperability_patterns.1.usage_context",
      "citations": [
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        }
      ],
      "reasoning": "The field value describes the zip pattern used for element-wise computations across two or more parallel iterators, highlighting its efficiency, preserved element-wise pairing (vec1[i] paired with vec2[i]), and ordering guarantees for IndexedParallelIterator sources. It also notes that zip_eq enforces equal lengths and will panic otherwise. The excerpt explicitly states that Zip is an iterator that zips two inputs into a single iterator of pairs, created by zip() on an IndexedParallelIterator, and it mentions its role in elements pairing and ordering. This aligns with the field values emphasis on element-wise computation, strong ordering guarantees, and guidance about length-matching behavior. Therefore, the excerpt directly supports the stated concept and its implications for correctness (low-bug) and potential performance characteristics (efficiency).",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The claim that the parallel sort in Rayon is unstable and may reorder equal elements directly supports the warning that instability can affect algorithm correctness when the original order matters. This aligns with the anti-pattern concern of using a parallel sort in scenarios where stability is required, as stated in the field value. The note that the parallel sort can be used with a key extractor or comparator and may not preserve order further reinforces the instability caveat and shows multiple ways in which ordering guarantees can be compromised in parallel sorting. The contrasting statement that a stable sort exists (and its stable behavior) provides a clear counterpoint and helps identify a scenario where using par_sort could be problematic if stability is essential. The explicit par_sort function signature anchors the discussion in the concrete API, making the above concerns directly applicable to the finegrained field. Finally, the recurring fragment about equality of elements ties back to the stability discussion, reinforcing why preserving original ordering of equal items matters for correctness. Taken together, these excerpts cohesively support the anti-patterns described: using par_sort on small arrays due to overhead, and using it when stability is required, which can lead to buggy or inefficient patterns.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The most relevant information directly describes an unstable parallel sort and the related function in Rayon. One excerpt states that the sort is unstable (i.e., may reorder equal elements) and provides context about an in-place, parallel approach with a time complexity of O(n log n). This aligns closely with the idea of an unstable parallel replacement for a stable sequential sort. Another excerpt explicitly references a parallel sort function (par_sort) and its behavior, which is central to identifying an alternative pattern to the standard librarys stable sort. A further excerpt notes sorting in parallel with a key extraction function and mentions that it might not preserve the order, which touches on stability concerns in comparison to a stable sort. Additional excerpts describe the standard librarys stable sort and its performance characteristics (stable, O(n log n) worst-case) to contrast with the instability and parallelism in Rayon. Finally, one excerpt mentions a general note about equal elements and ordering, which reinforces the discussion of stability semantics in sorting implementations. Taken together, these excerpts support the field value by illustrating the existence and characteristics of an unstable parallel sorting pattern (par_sort_unstable or analogous) in Rayon, contrasted with the stable, sequential slice::sort in the standard library.",
      "confidence": "high"
    },
    {
      "field": "interoperability_patterns.1.code_template",
      "citations": [
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        }
      ],
      "reasoning": "The finegrained field value shows a code pattern that uses two parallel iterators, zips them together, maps over the pairs to multiply elements, and then sums the results to compute a dot product. The excerpt explicitly states that Zip is an iterator that zips two sequences into a single iterator of pairs, and that this struct is created by the zip() method on an IndexedParallelIterator. This aligns precisely with the code templates approach of pairing elements from two vectors via par_iter().zip(...) and then applying a transformation (multiplication) followed by a reduction (sum). The excerpt directly supports the core mechanism used in the code template (zipping two parallel iterators to form element-wise pairs for further computation).",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.0.pattern_name",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to an idiomatic pattern name that emphasizes an unstable, parallel sort optimized for maximum performance, specifically using a function variant analogous to a parallel unstable sort. The most relevant excerpts directly describe parallel sorts that are unstable (i.e., may reorder equal elements) and operate in-place with no allocation, which aligns with the idea of a high-performance, non-deterministic ordering operation. One excerpt states that the sort is unstable and parallel and in-place, which captures the core properties of an unstable parallel sort. Another excerpt mentions sorting in parallel with a key extraction function and notes that it may not preserve order, reinforcing the instability aspect in a parallel context. A third excerpt references a parallel sort function named in the codebase (par_sort), which is the canonical parallel sort pattern that could be related to the unstable variant described in the value. Additional excerpts discuss a parallel sort with a comparator and confirm that one variant is stable, which is useful for contrast but not the target pattern, thus serving as contextual support. A final excerpt fragment underscores the notion of sorting equal elements, tying into the instability/ordering behavior. Taken together, these excerpts provide direct support for the concept of a parallel, unstable sort pattern by describing instability, parallel execution, and in-place characteristics, while also offering context about a stable counterpart and a specific par_sort-like function. The strongest support comes from the explicit statements about instability and parallelism, followed by the explicit par_sort reference as a basis for the idiomatic pattern, with the stable variant and equality notes offering helpful contrasts and contextual nuance.",
      "confidence": "medium"
    },
    {
      "field": "interoperability_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "let rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "use rayon::iter::ParallelBridge;"
          ]
        },
        {
          "title": "Parallel stream processing with Rayon",
          "url": "https://morestina.net/1432/parallel-stream-processing-with-rayon",
          "excerpts": [
            "`par_bridge()` method defined on iterators with the corresponding [trait](https://docs.rs/rayon/latest/rayon/prelude/trait.ParallelBridge.html) . The method adapts an ordinary iterator into a parallel one, employing [clever design](https://github.com/rayon-rs/rayon/pull/550) to take individual items from the iterator and balance them between Rayons threads. Most importantly, it implements `ParallelIterator` , which means you can use the adapter exactly as you would use the value returned by `par_iter()` on a collection."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        }
      ],
      "reasoning": "The target field value identifies a specific idiomatic pattern, par_bridge(), which is described and exemplified as a bridging mechanism that converts a standard Iterator into a ParallelIterator, effectively acting as a bridge from sequential code to parallel execution. The most directly relevant excerpt states that this conversion creates a bridge from a sequential iterator to a parallel one by distributing items across Rayons thread pool, which directly supports the idea that par_bridge() is an interoperability pattern enabling parallel processing of iterators. Additional excerpts explicitly describe par_bridge() as a method that adapts an ordinary iterator into a parallel one, and show usage with examples and code, reinforcing that par_bridge() is the idiomatic pattern for bridging to parallel iteration. Other excerpts discuss the broader context of the ParallelBridge trait and its documentation, reinforcing that par_bridge() is a practical, widely-used way to parallelize otherwise serial iteration, while also noting trade-offs such as potential ordering changes and lack of buffering, which are important considerations when using this pattern. Collectively, these excerpts support the characterization of par_bridge() as the key interoperability pattern for turning ordinary iterators into parallel iterators via a bridge mechanism in Rayon.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.0.usage_context",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "9    /// of equal elements.",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca"
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpts describe parallel sorting behavior that is in-place and does not guarantee the order of equal elements, which aligns with the finegrained field value that prioritizes performance and in-place operation when stability is not required. The first excerpt explicitly notes that the sort is unstable and in-place, which exactly matches the idea of a fast, parallel sort where preserving relative order is not necessary. The second excerpt similarly states parallel sorting with a key extraction function that does not guarantee order, reinforcing the in-place, unstable nature of the operation. The excerpt describing the par_sort function shows the existence of a parallel sort entry point that operates on a type that implements Ord, which supports the notion of a high-performance, idiomatic parallel sort in the Rayon ecosystem, although it does not explicitly state in-place behavior. The brief fragment about of equal elements provides a small contextual cue related to stability concerns but lacks depth, making it a supplementary reference rather than a primary support. The excerpt describing a stable sort with a comparator introduces a contrasting behavior (stability), which is not aligned with the target field value, but is relevant as a point of comparison to highlight the anti-pattern when stability is desired but not required in a performance-focused context.",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.1",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a pattern that combines try_fold with try_reduce for fallible aggregation in a Rust parallel context. Directly, the excerpt about TryFold in rayon::iter introduces the try_fold primitive, including its signature and purpose, which is to perform a fallible accumulation over items within a parallel iterator. This aligns with the core idea of a fallible aggregation step. Another excerpt notes that these operations are fallible (they deal with a fallible op on items) and that the general idea is to execute a fallible operation on each item, which supports the notion of a fallible, block-local accumulation that can fail. A third excerpt provides a detailed description of try_reduce_with, showing how the reduction step is performed after a fallible fold, returning an Option<T> and explaining the behavior when the iterator is empty or when an error state is encountered, directly connecting to the concept of combining try_fold with try_reduce for a fallible global result. The fourth excerpt explicitly discusses the TryFold API and its signature, reinforcing the specific pattern being analyzed and providing concrete operator names and types that appear in the sample code. Taken together, these excerpts collectively support the identified pattern of using try_fold in conjunction with try_reduce to implement fallible parallel aggregation, including the ergonomics, expected outcomes (Some/None), and the practical code templates. This alignment indicates a coherent, cross-cutting view across multiple sources on the same idiomatic pattern and its usage in a fallible parallel context.",
      "confidence": "medium"
    },
    {
      "field": "interoperability_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "let rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "use rayon::iter::ParallelBridge;",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Parallel stream processing with Rayon",
          "url": "https://morestina.net/1432/parallel-stream-processing-with-rayon",
          "excerpts": [
            "`par_bridge()` method defined on iterators with the corresponding [trait](https://docs.rs/rayon/latest/rayon/prelude/trait.ParallelBridge.html) . The method adapts an ordinary iterator into a parallel one, employing [clever design](https://github.com/rayon-rs/rayon/pull/550) to take individual items from the iterator and balance them between Rayons threads. Most importantly, it implements `ParallelIterator` , which means you can use the adapter exactly as you would use the value returned by `par_iter()` on a collection."
          ]
        },
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        }
      ],
      "reasoning": "The most directly relevant information concerns ordering and performance implications of using the parallel bridge. Statements noting that the bridge does not guarantee to preserve the original iteration order directly support the anti-pattern claim that relying on side effects or order is a bug when using par_bridge. Additional excerpts that discuss efficiency trade-offs  such as the bridge potentially being less efficient than starting with a direct par_iter  bolster the claim that par_bridge is an anti-pattern in contexts where a performant, ordered par_iter is available. Excerpts mentioning buffering behavior and suitability for non-trivially parallelizable producers (e.g., channels or I/O) help contextualize when par_bridge is appropriate or problematic. Other excerpts that broadly say the bridge can be used for many cases or that it is not buffered (or that the resulting iterator may not keep the original order) reinforce the theme that par_bridge introduces non-determinism in ordering and potential inefficiencies if misused. In summary, the strongest support comes from explicit notes about non-order preservation and relative inefficiency compared to par_iter; weaker but supportive context comes from notes about buffering behavior and suitability for difficult-to-parallelize cases, which clarifies when the anti-patterns are not as problematic.",
      "confidence": "medium"
    },
    {
      "field": "parallel_sorting_patterns.1.code_template",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt discusses parallel sorting with a key extraction function and explicitly notes that it may not preserve the order of elements after sorting, which directly relates to the behavior of a par_sort_by_key template and its implications for maintaining relative order among equal keys. It provides a direct constraint about the order semantics when using a key-based parallel sort. The next important excerpt describes parallel sorting in general and states that it is unstable and may reorder equal elements, which reinforces the idea that, without explicit guarantees, equal-key items may not keep their original order. Another excerpt describes a stable, comparator-based parallel sort, indicating that when using a comparator, the sort can be stable, which contrasts with key-based variants and helps delineate the difference between stability guarantees for comparator-based sorts versus key-based sorts. A further excerpt explicitly references the par_sort function, which is the direct function name associated with a parallel sort in this context, helping to map the code template to the actual API surface. The fragment mentioning equal elements further corroborates how stability concerns relate to sorting iterations and can be cross-checked against the example in the code template that asserts a particular post-sort order for tuples with the same first component. Collectively, these excerpts support the interpretation that the code template aims to illustrate key-based parallel sorting semantics and the expectations around preserving or not preserving relative order for equal keys, as well as how stability differs between key-based and comparator-based approaches, which is central to evaluating the correctness of the shown example.",
      "confidence": "medium"
    },
    {
      "field": "structured_parallelism_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "pub fn scope<'scope, OP, R>(op: OP) -> R",
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack.",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned. So in this example, absent any stealing, we can\nexpect `s.2` to execute before `s.1` , and `t.2` before `t.1` . Other\nthreads always steal from the other end of the deque, like FIFO\norder.",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned.",
            "For an alternate approach, consider [`scope_fifo()`](fn.scope_fifo.html \"fn rayon::scope\\_fifo\") instead"
          ]
        }
      ],
      "reasoning": "The most relevant passages explicitly describe the pattern associated with the field value: a fork-join style construct in Rayon referred to as a scope. One passage introduces scope as a flexible building block that can spawn asynchronous tasks and notes that it is used in a fork-join style, with a closure executed in a thread pool and tasks potentially spawned inside it; it also contrasts scope with join and mentions performance considerations, which directly aligns with identifying the exact pattern name and its core characteristics. Another passage provides the signature and plain description of creating a scope, reinforcing the identification of the exact pattern name and its usage. A third excerpt expands on how the closure runs within the Rayon thread pool and notes that scope closures spawn tasks that may outlive the initiating closure, which solidifies the understanding of scope as the pattern named rayon::scope. Additional excerpts reiterate that scope is a flexible alternative to join, highlight the lack of guaranteed order for spawns (a behavior commonly associated with scope-based scheduling), and discuss alternatives like scope_fifo, all of which further corroborate the existence and properties of this specific pattern. The remaining notes about scope behavior (such as ordering implications and panics) provide supplementary context to the patterns practical usage, reinforcing that the core pattern being analyzed is indeed rayon::scope and its behavioral boundaries.",
      "confidence": "high"
    },
    {
      "field": "interoperability_patterns.0.usage_context",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "use rayon::iter::ParallelBridge;",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        }
      ],
      "reasoning": "The core idea in the fine-grained field value is that there exists a pattern that converts a sequential iterator into a parallel iterator via a bridge (ParallelBridge), enabling parallel processing when the source is inherently sequential (such as file I/O or channels). This is directly supported by the excerpts that define the conversion trait as creating a bridge from a sequential iterator to a parallel one and distributing items across a thread pool, which matches the described pattern. Additional excerpts discuss practical aspects of this pattern: that the resulting ParallelIterator may not preserve the original order, that it is useful for sources that are difficult to parallelize (like channels or I/O), and that there are trade-offs in efficiency and buffering when using this approach. Together, these excerpts corroborate the patterns purpose (introducing parallelism for sequential sources), mechanics (a bridging adapter that converts to a ParallelIterator), and typical use cases (I/O-bound or channel-based data sources) and caveats (ordering and efficiency). The combination of a formal description of the bridge, plus notes on ordering, buffering, and applicability to challenging parallelization scenarios aligns with the described usage context in the field value.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.2",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt describes a function that reduces a collection of items using a fallible operation, returning None for an empty iterator and Some(..) for non-empty results, while handling Err/None in a way that mirrors collecting outcomes rather than halting at the first error. This aligns with a pattern that aggregates success and failure across all items to enable comprehensive error reporting, rather than early exit. The next excerpts elaborate on related fallible-iterator methods (try_reduce_with) and their behavior when encountering errors or empty inputs, which reinforces the idea of collecting and reporting across the entire dataset in parallel contexts. Additional excerpts discuss try_fold semantics, which are part of the same family of fallible parallel patterns and illustrate how identity, folding, and per-item operations contribute to an aggregated outcome. Together, these excerpts substantiate a pattern where a parallel iterator processes all items, combines results into a unified collection that preserves success and failure information, and enables comprehensive reporting instead of short-circuiting early. These pieces collectively map to the requested code template and usage context for collecting results for comprehensive error reporting, while also contrasting with anti-patterns and offering alternate strategies like try_for_each or try_reduce when early cancellation is desired.",
      "confidence": "high"
    },
    {
      "field": "parallel_slice_processing_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length.",
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>",
            "fn par_rchunks(&self, chunk_size: usize) -> RChunks<'_, T> { ... }",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>",
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n"
          ]
        }
      ],
      "reasoning": "The core idea behind the finegrained field value is that choosing an extremely small chunk_size introduces disproportionate overhead from creating and scheduling many parallel tasks for each chunk, which can offset the benefits of parallelism. The most directly relevant excerpts define how chunk_size governs how many elements are processed per subunit of work and show concrete methods that operate with a chunk_size parameter. One excerpt explicitly describes that a parallel iterator processes at most a given chunk_size elements at a time, clarifying that the chunk_size setting is what partitions work among workers. Another excerpt outlines the signature and behavior of a method that produces sublists (chunks) of a specified size, reinforcing that chunking is the fundamental unit of work in these parallel operations. Together, these sources establish that chunk_size directly controls the granularity of parallel work, which is the essential context for considering whether very small chunks would introduce per-chunk overhead and potentially degrade performance. Additional excerpts demonstrate related operations (such as exact chunks and non-overlapping chunks) and provide example code illustrating usage of chunking constructs, further informing how chunk_size dictates how work is divided and scheduled in practice. This collection of excerpts supports the notion that while chunking enables parallelism, the choice of too-small chunks can lead to inefficiencies due to scheduling and overhead, even though explicit statements about tiny chunk_size overhead are not present in the excerpts themselves.",
      "confidence": "medium"
    },
    {
      "field": "parallel_sorting_patterns.0.code_template",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The finest-grained field value centers on a concrete code template for parallel sorting in Rayon, namely calling a parallel sort on a mutable slice and observing the result. The most directly relevant excerpt presents the function signature par_sort(&mut self) and shows the trait bound T: Ord, which aligns with a typical Rust API for a parallel sort in Rayon, and it explicitly names the par_sort call pattern. This excerpt provides structural corroboration that a par_sort-like method exists in Rayon and is used to sort a parallel slice in-place, matching the provided code template's intent. The following excerpt explains a parallel sort that operates on a slice in parallel and notes that the sort may be unstable, i.e., might reorder equal elements, and that it is in-place with O(n log n) worst-case complexity. This directly supports the aspects of the code template that perform in-place parallel sorting and acknowledges potential instability, which is a critical nuance of the given snippet. Another excerpt discusses sorting in parallel with a key extraction function and mentions that the order of equal elements might not be preserved, which is conceptually related to the stability characteristics of parallel sorts and reinforces the idea that parallel sorts may not guarantee stability. A further excerpt contrasts the unstable parallel sort with a stable variant by describing a stable parallel sort (with a comparator) and its stability, which is relevant for understanding alternate patterns and confirms the existence of both stable and unstable forms in similar APIs. The remaining excerpt, which contains a fragment about equal elements, reinforces the discussion around stability and behavior when elements are equal, but offers less direct evidence about the exact code template and method name, serving as supplementary context. Overall, the chain of excerpts coherently maps to the code templates core idea (a parallel in-place sort on a slice via Rayon, including stability considerations) and provides corroborating details about the API surface (par_sort, instability, and adjacent patterns).",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.1.usage_context",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The fine-grained field value asserts that for large slices, a sorting approach preserves the relative order of equal elements (stability), is advantageous for multi-pass sorts with secondary keys, and is an adaptive parallel merge sort that excels on nearly-sorted data. The most relevant excerpt directly states that the sort is stable and operates in parallel with a n log n worst-case, which aligns with the described stable parallel merge-sort behavior. A contrasting excerpt explicitly notes instability, indicating that some parallel sorts may reorder equal elements, which provides contradictory evidence and lowers confidence in the claim of universal stability. Other excerpts discuss that a sort can be done in parallel with a key-extraction function (which may or may not preserve original order depending on implementation) and provide a concrete function name for the parallel sort, illustrating practical aspects of the implementation. A fragment about equal elements further contextualizes how stability relates to equal-item handling, and the final excerpt shows the par_sort function signature, which is central to the existence of a parallel sorting mechanism in the library. Taken together, these excerpts support the core idea of a parallel sorting mechanism with stability in some contexts, while also acknowledging that instability can occur in other contexts or configurations, which is why the relationship to the precise described usage context is ",
      "confidence": "medium"
    },
    {
      "field": "interoperability_patterns.0.code_template",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "let rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "use rayon::iter::ParallelBridge;",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O."
          ]
        },
        {
          "title": "Parallel stream processing with Rayon",
          "url": "https://morestina.net/1432/parallel-stream-processing-with-rayon",
          "excerpts": [
            "`par_bridge()` method defined on iterators with the corresponding [trait](https://docs.rs/rayon/latest/rayon/prelude/trait.ParallelBridge.html) . The method adapts an ordinary iterator into a parallel one, employing [clever design](https://github.com/rayon-rs/rayon/pull/550) to take individual items from the iterator and balance them between Rayons threads. Most importantly, it implements `ParallelIterator` , which means you can use the adapter exactly as you would use the value returned by `par_iter()` on a collection."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        }
      ],
      "reasoning": "The target field value is a code template that bridges a sequential iterator to a parallel one using par_bridge from the Rayon library. The most directly relevant excerpts are those that include concrete code demonstrating par_bridge in action, such as converting a regular iterator into a ParallelIterator via par_bridge and subsequently performing parallel operations (e.g., filtering and counting). These excerpts show the exact pattern the field value embodies: opening a file or buffer, obtaining a lines() iterator, applying par_bridge to enable parallel processing, and then applying further processing like contains and count. Content that explicitly labels this behavior as bridging to a parallel iterator and that shows the par_bridge usage is therefore highly relevant for validating the code_template. Excerpts describing the conversion trait and its semantics (that it creates a bridge from a sequential iterator to a parallel one) further support understanding of the template and its intended usage. Additional excerpts that discuss side characteristicssuch as not buffering, potential lack of order preservation, and when parallelization is beneficialprovide context about the constraints and trade-offs of this idiom, which helps substantiate how the template should be used in practice. Finally, excerpts that mention related import statements or ancillary notes (e.g., use rayon::iter::ParallelBridge; or statements about ordering and buffering) reinforce how the code template would be integrated into real code. Overall, the strongest support comes from direct par_bridge code samples, followed by explicit trait descriptions and contextual notes on behavior and performance implications.",
      "confidence": "high"
    },
    {
      "field": "structured_parallelism_patterns.0.usage_context",
      "citations": [
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "pub fn scope<'scope, OP, R>(op: OP) -> R",
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        }
      ],
      "reasoning": "The most directly supportive excerpt states that creating a fork-join scope and invoking the closure allows spawning tasks that may run asynchronously, and when the closure returns, it blocks until all spawned tasks complete. This captures the core idea of the scope as a structured parallelism primitive with a fork-join guarantee, which underpins lifetime-safe borrows of local variables and prevents dangling references. The same excerpt also contrasts scope with join in terms of flexibility and heap allocation, highlighting the performance trade-off and implicitly the intended usage pattern for organizing related tasks. This directly aligns with the claim that scope is the idiomatic pattern for coordinating multiple related tasks with lifetime considerations in Rust. Another excerpt reinforces that scope executes within the Rayon thread pool and that tasks spawned inside it are tied to the scopes lifecycle, reinforcing the borrow-safe, lifetime-aware context that enables low-bug concurrent code. A third excerpt connects scope to a concrete comparison with join, noting that join is generally preferable for performance, which adds nuance to when the idiomatic pattern should be used, but still supports its role as a central structured parallelism construct. A fourth excerpt provides the function signature for scope, which supports understanding how the API is designed to enable this pattern in code. A fifth excerpt explicitly discusses the preference for join and the heap-vs-stack implication, which contextualizes why scope exists as an idiomatic pattern rather than a general-purpose parallel tool, further supporting its role in lifetime-safe or low-bug code characteristics. Collectively, these excerpts establish that scope is tied to the fork-join model, enables borrowing from the local stack, requires completion of spawned tasks, and is presented in contrast to non-lifetime-safe alternatives, which supports the field value's claims about being the idiomatic, safety-focused pattern in this context.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.1.pattern_name",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The target claim identifies a specific idiom: using a par_sort function to achieve stable parallel sorting. The most directly supportive excerpt states that the sort is stable (does not reorder equal elements) with a worst-case complexity, which aligns with a stable parallel sorting pattern. The excerpt containing the par_sort function signature confirms the existence and naming of the parallel sort entry point in the API. However, there is a conflicting assertion elsewhere that parallel sorts may be unstable or may not preserve order in certain contexts, which introduces nuance and potential anti-pattern considerations. The remaining excerpts discuss related parallel sorting behavior (such as sorting with a key extraction function and potential non-preservation of order for equal elements) but do not assert the stability of par_sort themselves, providing contextual support rather than direct confirmation. Taken together, these excerpts most strongly support the existence and stable nature of a par_sort-based pattern, while also signaling that stability can vary depending on how the sort is applied or implemented in related APIs. Because the field value explicitly names a stable par_sort pattern, the most relevant evidence is the explicit stability claim about a parallel sort and the direct par_sort API reference, with less relevance attributed to surrounding notes about potential instability in other parallel sorting variants.",
      "confidence": "medium"
    },
    {
      "field": "parallel_sorting_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explicitly states that a sort in parallel with a comparator function is stable, which directly supports the concept of a stable parallel sort pattern. The code snippet showing a par_sort function implementation reveals the existence of a parallel sorting method on slices, aligning with the field value that par_sort is the focal pattern. Other excerpts discuss parallel sorts that might be unstable (i.e., may reorder equal elements) and mention a parallel sort with a key extraction function; these provide important context showing the trade-offs and variations among parallel sorting patterns, which is relevant when contrasting par_sort with unstable parallel sorts or with sequential sort_unstable. The fragment about equal elements adds to the nuance of stability considerations in parallel sorting. Together, these excerpts collectively support understanding that par_sort is a stable parallel sorting option in Rayon, while also highlighting caveats and alternatives (unstable parallel sort, key-based parallel sorting) that are relevant for comprehensive idiomatic patterns.",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.0",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The target field describes a pattern for short-circuiting or early-exiting in a fallible per-item operation during parallel iteration. The excerpt that explicitly notes a fallible operation on each item in the iterator and mentions the TryFold context is directly aligned with the concept of applying a per-item operation that can fail and potentially stop processing. The passages that document the try_reduce_with and the detailed behavior of try_reduce/try_fold complement this by showing how a fallible operation propagates results (e.g., Some/None or Err) and how an early exit semantics is implemented in similar APIs. These references together support understanding how a try-for-each-like pattern would operate, what advantages it brings (early cancellation on error), and how it is typically expressed in the librarys API surface. The remaining excerpt expands on the same family of fallible-iteration helpers, providing further concrete examples and nuances of the same general mechanism (reducing or folding with a fallible operation), which reinforces the connection to the finegrained field value through analogous semantics and error-propagation behavior.",
      "confidence": "medium"
    },
    {
      "field": "parallel_sorting_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The targeted field value argues that using the parallel sort when stability is not needed is an anti-pattern because it tends to be slower and incurs extra memory allocation compared to a non-stable or alternate approach. In the provided excerpts, there are direct statements about stability and behavior of the parallel sort family: one excerpt explicitly notes that the parallel sort in question is unstable and may reorder equal elements, which directly informs the trade-off between stability and performance in parallel sorting. Other excerpts describe that the parallel sort can be stable and that it operates in parallel, with references to how sorting can be either stable or unstable depending on the variant or context. Taken together, these excerpts illuminate the core tension between stability guarantees, potential reordering, and performance/memory characteristics of parallel sorting routines in rayon, which is precisely the kind of evidence needed to evaluate the described anti-pattern. The function-related excerpt reinforces that there is a concrete API path for parallel sorting, including how it behaves, which is relevant when deciding whether to rely on a stable vs. potentially unstable approach in practice, as the field value suggests. While none of the excerpts explicitly state the exact anti-pattern phrasing, the combination of notes on stability, instability, and performance trade-offs provides direct supporting context for the idea that using the parallel sort when stability is unnecessary can be suboptimal.",
      "confidence": "medium"
    },
    {
      "field": "parallel_slice_processing_patterns.1.pattern_name",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>"
          ]
        }
      ],
      "reasoning": "The field value specifies the idiomatic pattern of par_windows for overlapping neighborhoods. An excerpt explicitly demonstrates this pattern by showing a parallel iterator over all contiguous windows of length window_size with overlapping windows, including a concrete example using par_windows(2) that yields [[1, 2], [2, 3]]. This directly supports the concept of overlapping neighborhood operations. Another excerpt references the par_windows function, which corroborates the existence and naming of this idiomatic pattern, aligning with the field value indicating par_windows as the targeted pattern. Together, these excerpts establish both the existence and the overlapping semantics of the par_windows idiom in the rayon::slice context.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.2.anti_patterns",
      "citations": [
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        }
      ],
      "reasoning": "The field value talks about using a zip pattern when two iterators are expected to have the same length, warning that not verifying this can cause data loss, and recommending a safer alternative (zip_eq). The excerpts describe the Zip construct as a mechanism that combines two iterators into a single iterator. From these excerpts, we can connect the general idea that zip operates on two inputs to the anti-pattern concern: without explicit length checking, zip may behave poorly for unequal-length inputs. The excerpts do not explicitly mention length verification or zip_eq, but they establish the fundamental concept of zipping two streams, which is the basis of the anti-pattern described. The safer alternative and the potential for silent data loss are not directly evidenced in the excerpts, so the connection remains a reasonable but inferential link grounded in the shared topic of using zip in Rust/Rayon.",
      "confidence": "low"
    },
    {
      "field": "order_and_indexing_patterns.2.code_template",
      "citations": [
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        }
      ],
      "reasoning": "The code_template demonstrates creating two vectors, and then producing a zipped iterator that pairs corresponding elements from each vector, ultimately collecting into a vector of tuples. The first excerpt directly says that Zip is an iterator that zips two inputs (a and b) into a single iterator, which aligns with the idea of taking two sequences and iterating over them in parallel to form pairs like (1,4), (2,5), (3,6). This supports the core mechanism of the code_template: pairing elements from two iterables. The second excerpt, while brief, is part of the same concept space and confirms that the focus is on the Zip construct within Rayons iteration model, reinforcing that the code_template centers on zipping two parallel iterators rather than independent iterations. Together, these excerpts substantiate that the code_template uses a zipping pattern to produce a collection of paired elements, which matches the expected idiomatic pattern of parallel zipping in Rayon.",
      "confidence": "high"
    },
    {
      "field": "structured_parallelism_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack.",
            "o reference `bad` we must\ntake ownership of it. One way to do this is to detach the closure\nfrom the surrounding stack frame, using the `move` keyword. This\nwill cause it to take ownership of _all_ the variables it touches,\nin this case including both `ok` _and_ `bad"
          ]
        }
      ],
      "reasoning": "The most relevant content clearly contrasts scope with join and highlights the anti-pattern risks. The excerpts state that scope is a more flexible but more costly alternative to join, implying that using scope when a simpler primitive would suffice is an anti-pattern and that join or parallel iterators should be preferred. This directly supports the anti-pattern claim that using scope unnecessarily is inefficient compared to join. Additionally, the excerpts describe the performance implications of scope (heap allocation for tasks spawned via scope vs stack usage with join), which aligns with the anti-pattern of choosing a heavier mechanism when a lighter one would suffice. Finally, one excerpt discusses detaching closures and ownership semantics in the context of scope, which ties into constraints about borrowing non-static data and the careful handling of captured variables when using scope, reinforcing the idea that scope can be an anti-pattern if used improperly or with non-static data. Collectively, these excerpts support the core anti-patterns: (a) scope should not be used when join or other primitives suffice, (b) scope incurs heap allocation and potential performance penalties, and (c) improper use of scope with non-static or heavily borrowed data can lead to issues that constitute an anti-pattern in this context.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.2.pattern_name",
      "citations": [
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        }
      ],
      "reasoning": "The field value mentions zip in the context of parallel element-wise operations. The excerpts describe the Zip implementation in Rayon as an iterator that zips two inputs into a single iterator, which is the core mechanism enabling element-wise pairing of elements in parallel workloads. This directly supports the notion of a zip-based pattern used for parallel element-wise operations. The first excerpt provides a clear, explicit description of Zips role, while the second excerpt reinforces the same concept with a concise statement about Zip in the same codebase. Together, they substantiate the field value by showing the practical pattern (zip) that enables element-wise parallel work in Rayon.",
      "confidence": "high"
    },
    {
      "field": "interoperability_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "Conversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "The items are not buffered by `IterBridge` , so its fine to use this with\nlarge or even unbounded iterators.",
            "let rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "use rayon::iter::ParallelBridge;"
          ]
        },
        {
          "title": "Parallel stream processing with Rayon",
          "url": "https://morestina.net/1432/parallel-stream-processing-with-rayon",
          "excerpts": [
            "`par_bridge()` method defined on iterators with the corresponding [trait](https://docs.rs/rayon/latest/rayon/prelude/trait.ParallelBridge.html) . The method adapts an ordinary iterator into a parallel one, employing [clever design](https://github.com/rayon-rs/rayon/pull/550) to take individual items from the iterator and balance them between Rayons threads. Most importantly, it implements `ParallelIterator` , which means you can use the adapter exactly as you would use the value returned by `par_iter()` on a collection."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Zip in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Zip.html",
          "excerpts": [
            "Zip is an iterator that zips up a and b into a single iterator of pairs. This struct is created by the zip() method on IndexedParallelIterator."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes concrete alternative patterns to a ParallelBridge workflow, such as collecting to a Vec before parallelizing, using a bounded channel to provide backpressure, and chunking strategies for large data sources. The most relevant information is the recognition that parallelization via a bridging adapter can be advantageous in some cases but may be less efficient than starting from the idiomatic parallel iterator (par_iter) when possible, which aligns with the idea that there are trade-offs between bridge-based approaches and direct parallel iteration. A closely connected excerpt notes that such bridging can be useful for iterators that are difficult to parallelize by other means, such as channels or file I/O, which maps to the notion of applying specialized patterns to manage producer/consumer speed and I/O characteristics. Other excerpts describe the concept of the bridge itself and provide concrete code examples of converting an ordinary iterator to a parallel one, which provides the broader context that bridges exist as an option but do not specify the exact alternative patterns requested. Taken together, the excerpts support the general theme that there are trade-offs and situational best practices for using a bridging approach versus other parallelization strategies, but they do not provide explicit confirmations of the exact alternative patterns listed (collecting into Vec, bounded-channel backpressure, par_chunks with memory-mapped files).\n",
      "confidence": "low"
    },
    {
      "field": "structured_parallelism_patterns.0.code_template",
      "citations": [
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "pub fn scope<'scope, OP, R>(op: OP) -> R",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "There is no guaranteed order of execution for spawns in a scope,\ngiven that other threads may steal tasks at any time. However, they\nare generally prioritized in a LIFO order on the thread from which\nthey were spawned.",
            "Task execution potentially starts as soon as `spawn()` is called. The task will end sometime before `scope()` returns. Note that the _closure_ given to scope may return much earlier."
          ]
        }
      ],
      "reasoning": "The most directly relevant content describes how a fork-join style scope is created and used to spawn tasks that may borrow from the enclosing scope, and how the closure returns only after all spawned tasks complete. The code_template mirrors this pattern: it creates a scope, iterates over a collection, spawns tasks that capture and mutate a shared results array, and relies on scope to guarantee task completion before proceeding. The same excerpts also emphasize that scope is a flexible building block and that spawned tasks can access captured variables via move or borrow semantics, which aligns with the given template where each spawned task updates an element of a results vector derived from input data. Additionally, there is explicit mention of the scopes relationship to join and the heap/stack implications, which helps explain performance and ownership choices seen in the template. The excerpts further reinforce that the closure given to scope executes within Rayons thread pool and that there is no guaranteed execution order among spawns, which is consistent with the concurrent nature of the code template, where order of task completion is not relied upon. Finally, a direct mention of the scope API signature provides context for how scope is invoked in code, supporting the interpretation of the templates usage pattern as a canonical example of scope usage.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.1.usage_context",
      "citations": [
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); ",
            "Multiple Thread Pools"
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ...",
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        }
      ],
      "reasoning": "The most directly relevant content involves examples and discussions of using multiple thread pools or explicitly creating distinct pools to isolate work. Excerpts describing Multiple Thread Pools and Scope Patterns show concrete instances of more than one pool being created for separate tasks, which aligns with isolating workloads and prioritizing tasks. Excerpts that state that a ThreadPool represents a user-created pool and that a ThreadPoolBuilder can configure pools reinforce the pattern of explicit, separate pools rather than a single global pool. Excerpts discussing the existence of a configurable ThreadPoolBuilder and the ability to customize or build global pools further support the pattern of controlled concurrency management. Context about what a ThreadPool is and how it is constructed (e.g., via a builder) provides the necessary background to understand how this isolation pattern is implemented. The remaining excerpts add supportive context about pool limits and basic thread-pool dynamics, which underpin the pattern but do not themselves demonstrate the isolation idiom as clearly.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.2.usage_context",
      "citations": [
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes combining two or more parallel iterators to perform element-wise operations while preserving relative order, with a safety-check variant (zip_eq) that enforces length invariants. The most directly relevant information in the excerpts is that a Zip construct exists to pair two sequences into a single iterator, which embodies the described idiomatic pattern for parallel iteration in Rayon. This supports the idea that zip-based patterns are used to achieve element-wise operations, preserving order across the paired iterators. The second excerpt, though brief, confirms the existence of the Zip implementation referenced in the same context, reinforcing that the idiom centers on zipping two sequences to operate on corresponding elements. Together, these excerpts substantiate the use of a zip-like pattern for element-wise parallel computation and its alignment with the described safety/invariant properties suggested by zip_eq, even if the exact runtime-guard semantics arent fully fleshed out in the excerpts themselves.",
      "confidence": "medium"
    },
    {
      "field": "parallel_slice_processing_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>",
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length.",
            "fn par_rchunks(&self, chunk_size: usize) -> RChunks<'_, T> { ... }",
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>"
          ]
        }
      ],
      "reasoning": "The field value argues that manually creating windows with a par_iter().enumerate().map() is more complex and error-prone, and notes that slice.windows() is the direct sequential equivalent. The excerpts collectively demonstrate built-in parallel alternatives and patterns for windowing and partitioning in rayon, which serve as direct contrasts to the manual approach. For instance, the description of par_windows shows it returns a parallel iterator over all contiguous windows of a given length, with an example collecting those windows. This confirms that there is an official, idiomatic parallel windowing primitive to use instead of hand-rolling an enumerated map. The dedicated par_windows function signature further supports this direct Alternative Pattern claim. Additional excerpts describe non-overlapping chunking (par_chunks) and other related parallel-subslice patterns, which reinforce the broader point that rayon provides composable parallel patterns for operating on slices without resorting to manual, error-prone enumerations. Together, these excerpts substantiate that manual window construction is avoidable in favor of established parallel window/chunk patterns, aligning with the field values contrast between a potentially brittle manual approach and robust built-in APIs such as par_windows or the sequential slice.windows() in a different context.",
      "confidence": "medium"
    },
    {
      "field": "parallel_slice_processing_patterns.2.pattern_name",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length."
          ]
        }
      ],
      "reasoning": "The field value describes a specific idiomatic pattern: using par_split to perform parallel sub-slice processing by a separator. The first excerpt explicitly demonstrates par_split used on a slice with a separator predicate (par_split(|i| *i == 0)) to produce subslices and then aggregate them, which is a direct illustration of the exact pattern in question. It also shows that the method returns a parallel iterator over subslices, aligning with the concept of processing sub-slices in parallel separated by a delimiter. The second excerpt discusses a related parallel-slice concept (parallel chunks of a fixed size) but does not show a separator-based split; it documents chunking behavior rather than the separator-driven sub-slice pattern. This provides contextual support for understanding parallel sub-slice operations but is not as directly aligned with the specific separator-based par_split idiom as the first excerpt. Together, they corroborate the general idea of parallel sub-slice processing patterns in Rayon, with the strongest support coming from the first excerpt and supplementary context from the second.\n",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.2.alternate_patterns",
      "citations": [
        {
          "title": "Zip implementation in Rayon (zip.rs)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/src/iter/zip.rs",
          "excerpts": [
            "`Zip` is an iterator that zips up `a` and `b` into a single iterator",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/ vec.rs (Code excerpts showing IntoParallelIterator implementations)",
          "url": "https://docs.rs/rayon/latest/src/rayon/vec.rs.html",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "ParallelIterator in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon: data parallelism in Rust  baby steps - Small Cult Following",
          "url": "https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon reduce.rs code (KDAB Codebrowser view)",
          "url": "https://codebrowser.dev/slint/crates/rayon/src/iter/reduce.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Multi-threading with Rayon crate | TFHE-rs",
          "url": "https://docs.zama.ai/tfhe-rs/0.6-3/guides/rayon_crate",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "join in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/fn.join.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon join/mod.rs Documentation and Related Context",
          "url": "https://codebrowser.dev/rust/crates/rustc-rayon-core-0.5.0/src/join/mod.rs.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon 1.10.0",
          "url": "https://docs.rs/crate/rayon/latest/source/src/lib.rs",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "src/iter/from_par_iter.rs (Rayon) - FromParallelIterator implementations and collect_extended",
          "url": "https://github.com/rayon-rs/rayon/blob/main/src/iter/from_par_iter.rs",
          "excerpts": [
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "FromParallelIterator in Rayon docs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon/iter/from_par_iter.rs",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/from_par_iter.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "}",
            "}"
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "GitHub - RReverser/wasm-bindgen-rayon",
          "url": "https://github.com/RReverser/wasm-bindgen-rayon",
          "excerpts": [
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/nbody/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/nbody/mod.rs",
          "excerpts": [
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "rayon-demo/src/matmul/mod.rs",
          "url": "https://raw.githubusercontent.com/rayon-rs/rayon/master/rayon-demo/src/matmul/mod.rs",
          "excerpts": [
            "}"
          ]
        }
      ],
      "reasoning": "The central claim is that a higher-level abstraction like zip provides a cleaner and less error-prone approach to combining multiple sequences than manually iterating with enumerate and indexing. The excerpt describes Zip as an iterator that zips two inputs into a single iterator, which directly supports the notion that zip offers a concise, composable pattern for combining sequences rather than manual element-by-element access. Although the excerpts do not explicitly compare enumerate-based indexing to zip, the characterization of zip as a dedicated combinator for pairing elements demonstrates why it would be considered cleaner and less error-prone for this task. The second excerpt, though minimal, reinforces that the same Zip mechanism is used to pair elements, further underscoring its role as an abstraction over raw indexing. Taken together, these excerpts support the idea that using zip is the preferred pattern over manual indexing for combining multiple slices, aligning with the field value that zip is a much cleaner abstraction for this task.",
      "confidence": "medium"
    },
    {
      "field": "parallel_slice_processing_patterns.1.code_template",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>",
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n",
            "Returns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length.",
            ")\n\n#### fn [par\\_chunks](.par_chunks) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Chunks](struct.Chunks.html \"struct rayon::slice::Chunks\") <'\\_, T>",
            "fn par_rchunks(&self, chunk_size: usize) -> RChunks<'_, T> { ... }",
            "l)\n\n#### fn [par\\_chunks\\_exact](.par_chunks_exact) (&self, chunk\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [ChunksExact](struct.ChunksExact.html \"struct rayon::slice::ChunksExact\") <'\\_, T>",
            ",\n\nReturns a parallel iterator over subslices separated by elements that\nmatch the separator. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet products: Vec< _ > = [ 1 , 2 , 3 , 0 , 2 , 4 , 8 , 0 , 3 , 6 , 9 ]\n    .par_split(|i| * i == 0 )\n    .map(|numbers| numbers.iter().product::<i32>())\n    .collect();\nassert_eq!\n(products, [ 6 , 64 , 162 ]);\n```\n"
          ]
        }
      ],
      "reasoning": "The finegrained field value showcases a concrete idiomatic pattern: using a parallel iterator over a slice to produce overlapping windows of a fixed size, collecting those windows, and asserting the expected result. The most directly relevant excerpt contains the exact code template and demonstrates this idiom: creating a windows par_windows(2) from a slice, collecting into a vector, and asserting the resulting windows. Additional excerpts reinforce the same class of pattern by presenting parallel windowing (par_windows) and related parallel-slice operations (par_chunks, par_rchunks, par_split). These snippets collectively support understanding that parallel windowing is an idiomatic pattern for Rust with Rayon, including how to set up the parallel iterator, specify window size, and verify the results. The less directly related excerpts expand the family of parallel slice helpers (par_chunks, par_chunks_exact, par_rchunks) which are adjacent idioms in the same domain, illustrating how Rayon provides multiple parallel traversal patterns on slices. Taken together, the excerpts corroborate the existence and usage of par_windows as a core idiom, while also situating it among related parallel-slice patterns. This alignment directly supports the field value that the code template exemplifies a par_windows-based idiomatic pattern, including syntax for creating windows, collecting them, and asserting expectations.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "By default, Rayon uses the same number of threads as the number of CPUs available.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        }
      ],
      "reasoning": "The finegrained field value asserts that for simple applications the best pattern is to rely on the default global pool, and in asynchronous contexts (like Tokio) to avoid making a custom Rayon pool in favor of delegating blocking work to Tokios blocking thread pool. This is directly supported by statements that: the default behavior involves Rayon using a certain pool configuration by default (e.g., tuning around the global pool rather than a bespoke pool); and that the global pool can be used or built via a builder pattern. One excerpt explicitly notes that by default Rayon uses the same number of threads as CPUs, which underpins the default global pool is sufficient claim. Another excerpt explicitly shows how to use or build the global pool via a builder (build_global), which aligns with an alternate pattern when a custom pool might be considered but is framed as a pattern choice against creating a new pool. Additional excerpts describe the existence of a ThreadPool versus a global pool, reinforcing the contrast between using the default/global pool and creating a separate, custom pool. Taken together, these excerpts support the idea that the idiomatic approach is to rely on the default/global pool and to avoid spawning a separate Rayon thread pool in asynchronous contexts, unless a separate need arises, in which case the global pool can still be configured via the builder. Therefore, the most relevant excerpts are those that discuss the default/global pool behavior, the ability to use the global pool, and how to configure it via build_global, with secondary relevance given to passages that explicitly contrast custom ThreadPool creation with using the global pool.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.1.code_template",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        }
      ],
      "reasoning": "The fine-grained field describes a concrete code template for creating a custom Rayon thread pool, configuring it with a specific number of threads, building it, and then running a parallel computation inside that pool. Excerpts that explicitly describe using a ThreadPoolBuilder to create or configure a pool, and to set thread counts or provide a configuration that results in a custom pool, directly support this pattern. For example, an excerpt stating that ThreadPoolBuilder is used to create a new ThreadPool or to configure the global thread pool directly supports the notion of a reusable code template for pool creation and configuration. Excerpts that mention building the pool with a given configuration and the representation of a pool as a user-created thread pool also directly map to the idea of a template that defines how to instantiate and configure the pool. Excerpts discussing the maximum supported threads or different Stack Overflow discussions about changing thread counts provide contextual support but are less directly tied to a single, concrete code template; they augment the understanding of how to tune the pool but do not show a self-contained code snippet. Excerpts that describe multiple thread pools or more general ThreadPoolBuilder usage without a concrete inline example are still relevant as they establish the pattern and methods used for the code template. Overall, the strongest support comes from excerpts that frame ThreadPoolBuilder as a tool to create and configure a thread pool, and to build it with specific parameters, aligning with the requested code_template. The additional excerpts reinforce the pattern by elaborating on specific methods like num_threads and build, and by illustrating related usage in the context of Rayon pools.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns.0",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "You can combine `fold` with `reduce` if you want to produce a\nsingle value. This is then roughly equivalent to a map/reduce\ncombination in effect:",
            " );\n```\n\n### `fn [fold](.fold) <T, ID, F>(self, identity: ID, fold_op: F) -> [Fold](struct.Fold.html \"struct rayon::iter::Fold\") <Self, ID, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nParallel fold is similar to sequential fold except that the\nsequence of items may be subdivided before it is\nfolded. Consider a list of numbers like `22 3 77 89 46` . If\nyou used sequential fold to add them ( `fold(0, |a,b| a+b)` ,\nyou would wind up first adding 0 + 22, then 22 + 3, then 25 +\n77, and so forth.\nThe **parallel fold** works similarly except\nthat it first breaks up your list into sublists, and hence\ninstead of yielding up a single sum at the end, it yields up\nmultiple sums. The number of results is nondeterministic, as\nis the point where the breaks occur.",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity.",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity.",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        },
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "The field value describes a pattern where each thread builds a local accumulator (a per-thread state) using a fold, and then those local accumulators are merged with a reduce to form the final result, avoiding shared locking in the hot path. It also frames this as the idiomatic, efficient approach and contrasts it with using a global lock (Arc<Mutex<...>>) which serializes work and kills parallelism. Excerpts that explicitly discuss combining fold with reduce to produce a single value map directly onto the described pattern. Excerpts that define the behavior of fold and reduce (including identity handling and when results are deterministic or non-deterministic) provide foundational support for understanding why per-thread locals plus a final reduce is preferable. Excerpts that illustrate the risk of mutex-based contention (the anti-pattern) reinforce why the lock-free fold-then-reduce approach is advantageous. Collectively, these excerpts substantiate the claim that fold creates per-thread state and reduce merges those states, enabling high-efficiency, low-bug code without locking, and highlight the anti-pattern when locking is used. The most relevant portions are those that explicitly mention combining fold with reduce to produce a single value and the explanations that this mirrors a map/reduce-like workflow without shared locking, followed by the general fold/reduce semantics and the antipattern with per-thread mutexes. I cite the content by paraphrase when aligning to the field value: folding creates local accumulators per thread; reducing merges these locals; this avoids lock contention; using locks is an anti-pattern.",
      "confidence": "high"
    },
    {
      "field": "parallel_slice_processing_patterns.1.usage_context",
      "citations": [
        {
          "title": "ParallelSlice in rayon::slice - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/slice/trait.ParallelSlice.html",
          "excerpts": [
            ">\n\nReturns a parallel iterator over all contiguous windows of length `window_size` . The windows overlap.\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet windows: Vec< _ > = [ 1 , 2 , 3 ].par_windows( 2 ).collect();\nassert_eq! ( vec! [[ 1 , 2 ], [ 2 , 3 ]], windows);\n```\n",
            ")\n\n#### fn [par\\_windows](.par_windows) (&self, window\\_size: [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) ) -> [Windows](struct.Windows.html \"struct rayon::slice::Windows\") <'\\_, T>",
            ">\n\nReturns a parallel iterator over at most `chunk_size` elements of `self` at a time. The chunks do not overlap. If the number of elements in the iterator is not divisible by `chunk_size` , the last chunk may be shorter than `chunk_size` . All\nother chunks will have that exact length. ##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nlet chunks: Vec< _ > = [ 1 , 2 , 3 , 4 , 5 ].par_chunks( 2 ).collect();\nassert_eq! (chunks, vec! [ & [ 1 , 2 ][..], & [ 3 , 4 ], & [ 5 ]]);\n```\n"
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to a construct that iterates over contiguous, overlapping windows of a specified size, enabling computations that rely on neighboring elements (e.g., moving averages, stencil-like algorithms, feature detection). The most directly supporting content explicitly defines a parallel iterator over all contiguous windows of a given length and shows an example using par_windows to collect overlapping windows. This aligns exactly with the described behavior and usage. A closely related excerpt reinforces the par_windows idea by naming the method and its signature, confirming how the API is used to obtain overlapping windows. A third excerpt reiterates the concept by describing a parallel iterator over chunks with a specified size and notes that the chunks do not overlap; while this deviates from the overlapping-window emphasis, it still references the same family of parallel-slice iteration utilities and helps situate the idea of windowing vs. chunking, making it supportive though less central. Collectively, these excerpts corroborate the core idea of creating a parallel iterator over overlapping windows of a fixed size, which is the essence of the finegrained field value.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns.1",
      "citations": [
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "The field value centers on evaluating patterns for shared state in parallel code, with a focus on Arc<Mutex<T>> versus atomics. The most relevant excerpts directly state that acquiring a per-thread mutex or using Arc<Mutex<T>> can kill parallelism, which aligns with identifying it as an anti-pattern in high-contention parallel contexts. Related content discusses per-thread storage patterns and the use of atomics as a faster alternative for simple counters, providing concrete examples of when atomics outperform mutexes and reduce contention. Additional excerpts describe alternative patterns like batched lock acquisitions or fold-then-reduce approaches that avoid frequent locking, which directly supports the alternate patterns field. The combined evidence from these excerpts supports the finegrained field values emphasis on when to prefer atomics, when Arc<Mutex<T>> is appropriate (or should be avoided), and what alternative synchronization strategies exist to maintain parallelism and performance.",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.1.usage_context",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```"
          ]
        },
        {
          "title": "FoldWith in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.FoldWith.html",
          "excerpts": [
            "\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "The argument `identity` should be a closure that can produce\nidentity value which may be inserted into the sequence as\nneeded to create opportunities for parallel execution.",
            "\n ID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "\n            "
          ]
        }
      ],
      "reasoning": "The described fine-grained field value centers on a general-purpose reduction pattern that combines all items in a parallel iterator into a single value using an identity element and a combining operation. Several excerpts directly discuss this exact construct: the concept of an identity element for reduction and the idea of reducing items with a binary operation, which corresponds to the essential components of the pattern (identity, op). For instance, one excerpt notes that a reduction should provide an identity and that using an alternative form can be more efficient, indicating the importance of a well-defined starting value and associative operation. Another excerpt highlights a variant that accepts an initial value (identity) and a folding operation, describing how the initial value is threaded through and used with each item, which maps to the idea of starting from an identity and applying a combining function across the sequence. Additional excerpts discuss a fallible reduction variant and the behavior when encountering early termination, aligning with robust reduction semantics in parallel contexts and reinforcing the notion of a well-specified combining operation and termination behavior. There are also excerpts that describe a dedicated sum operation as a specialized form of reduction, explicitly connecting the concept of reducing to a single value with a concrete example and the associated performance considerations. Taken together, these excerpts provide direct support for the target field value: a general-purpose, parallel-reduction pattern that uses an identity element and a combining operation to produce a single result, with notes on efficiency and correctness that reduce bugs when the pattern is applied correctly. The excerpts also illustrate the related patterns (fold and various reduce_with/try_reduce_with variants) that expand the applicability of this idiom, showing different ways to express the same core idea across typical use cases.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); ",
            "Multiple Thread Pools"
          ]
        },
        {
          "title": "Clarify rust rayon nested thread pool worker numbers - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76919721/clarify-rust-rayon-nested-thread-pool-worker-numbers",
          "excerpts": [
            "I have tried to use rayon 's parallel iterators in a nested way. As a global pool would have a fixed number of threads, I tend to create an outer-pool in main.",
            "vec!\n[1, 2, 3, 4].into_par_iter().map(|inner| stress(outer * 10 + inner)).collect(",
            "})"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "})",
            "})"
          ]
        },
        {
          "title": "GitHub Issue: Performance of par_bridge (#685)",
          "url": "https://github.com/rayon-rs/rayon/issues/685",
          "excerpts": [
            "})"
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        }
      ],
      "reasoning": "The anti-pattern of creating multiple long-lived custom pools is directly addressed in discussions about Multiple Thread Pools, where examples show constructing separate pools (hdd_pool and ssd_pool) with different thread counts. This aligns with the idea of proliferating pools for various tasks, which incurs management and scheduling overhead. The anti-pattern of nesting pools is substantiated by examples and questions about nested thread pools, where an outer pool is created in main while a nested structure is used elsewhere, illustrating the risk of oversubscription and coordination complexity. Supporting context comes from references that describe creating a user-created ThreadPool with a ThreadPoolBuilder, which implies the possibility of spawning distinct pools, and from notes that ThreadPool can represent a user-created pool versus the global pool, highlighting configuration choices and their impact. Together, these excerpts directly illustrate both the practice to be avoided (multiple short-lived pools) and the nesting scenario that can cause deadlocks or degraded performance, and they also contextualize the recommended approach of using a builder or a single global pool instead of ad hoc multiple pools.",
      "confidence": "high"
    },
    {
      "field": "structured_parallelism_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Rayon scope docs",
          "url": "https://docs.rs/rayon/latest/rayon/fn.scope.html",
          "excerpts": [
            "Creates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "`scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s` . This closure can then spawn asynchronous tasks\ninto `s` . Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s` . When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()` ,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack. **Prefer `join()` (or, even better, parallel iterators) where possible. **",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:",
            "The Rayon `join()` function launches two closures and waits for them\nto stop.\nOne could implement `join()` using a scope like so, although\nit would be less efficient than the real implementation:\n\n```\npub fn join<A,B,RA,RB>(oper_a: A, oper_b: B) -> (RA, RB)\n    where A: FnOnce() -> RA + Send,\n          B: FnOnce() -> RB + Send,\n          RA: Send,\n          RB: Send,\n{\n    let mut result_a: Option<RA> = None;\n    let mut result_b: Option<RB> = None;\n    rayon::scope(|s| {\n        s.spawn(|_| result_a = Some(oper_a()));\n        s.spawn(|_| result_b = Some(oper_b()));\n    });\n    (result_a.unwrap(), result_b.unwrap())\n}\n```\n",
            "pub fn scope<'scope, OP, R>(op: OP) -> R",
            "For an alternate approach, consider [`scope_fifo()`](fn.scope_fifo.html \"fn rayon::scope\\_fifo\") instead",
            "pub fn scope<'scope, OP, R>(op: OP) -> R\n\nwhere\n    OP: FnOnce(&Scope<'scope>) -> R + Send,\n    R: Send,\n```\n\nExpand description\n\nCreates a fork-join scope `s` and invokes the closure with a\nreference to `s`. This closure can then spawn asynchronous tasks\ninto `s`. Those tasks may run asynchronously with respect to the\nclosure; they may themselves spawn additional tasks into `s`. When\nthe closure returns, it will block until all tasks that have been\nspawned into `s` complete. `scope()` is a more flexible building block compared to `join()`,\nsince a loop can be used to spawn any number of tasks without\nrecursing. However, that flexibility comes at a performance price:\ntasks spawned using `scope()` must be allocated onto the heap,\nwhereas `join()` can make exclusive use of the stack."
          ]
        }
      ],
      "reasoning": "The claim that using a two-task pattern is efficiently handled by a dedicated join operation is supported by passages describing join as a simple, efficient alternative to more flexible scopes, and by examples showing how join works as a two-closure launcher with a final aggregation. This line of reasoning also notes that, for parallel processing of collections, a data-parallel approach such as a parallel iterator is considered idiomatic and often preferable to more manual scope-based spawning. The idea that there are scoped alternatives that behave differently (for example, a scope-like API that allocates tasks onto a heap and a design that can preserve or invalidate thread-local assumptions) is corroborated by descriptions of scope in which tasks spawn and execute potentially out of order, and by explicit statements about the performance trade-offs between scope and join. The mention of a FIFO-ordered variant and other scoped APIs provides additional context about available alternatives and their scheduling guarantees. Finally, the presence of a scoped API that preserves the initial calling thread for the closure (in_place_scope) and references to a FIFO-scoped variant (scope_fifo) support the claim that there are multiple idiomatic patterns within Rayon for scoped parallelism, each with different guarantees and use cases.",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.2.alternate_patterns",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```"
          ]
        }
      ],
      "reasoning": "The field value specifies that, when ownership is not required, the correct pattern is to substitute the standard sequential iteration with par_iter() (immutable access) or par_iter_mut() (mutable access). The most directly relevant content shows: changing a sequential iteration to a parallel one by replacing iter() with par_iter(), which is an explicit, concrete example of the requested alternate pattern. Another excerpt reinforces this by stating that Rayon makes it easy to convert a sequential computation into a parallel one and that you may convert foo.iter() into foo.par_iter(), which directly maps to the stated replacement pattern. A third excerpt provides a concise code snippet using input.par_iter() to enable parallel computation, illustrating the practical application of the alternate pattern in code. Additional context from the prelude-related excerpt explains how to bring ParallelIterator traits into scope, which is an enabling step for these patterns and thus supports the practical adoption of the alternate patterns described. Although the excerpts strongly support the existence and usage of par_iter() as the primary alternative, explicit discussion of par_iter_mut() or all edge cases is not uniformly present across excerpts, which tempers the certainty to a medium level.",
      "confidence": "medium"
    },
    {
      "field": "parallel_collection_building_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:",
            "\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon::prelude::*;\n```\n",
            "```\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```"
          ]
        },
        {
          "title": "rayon::iter::FromParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "Collects (key, value) pairs from a parallel iterator into a hashmap. If multiple pairs correspond to the same key, then the ones produced earlier in the..."
          ]
        }
      ],
      "reasoning": "The finegrained field value asserts an alternative workflow for parallel collection building when an implementation like FromParallelIterator is unavailable: manually implement the logic of creating thread-local collections (fold) and then merging them (reduce). The excerpts that are most relevant discuss mechanisms to start parallelization by widening the scope of iterators into parallel iterators and bridging approaches, which are related concepts to providing alternatives to a direct FromParallelIterator. In particular, excerpts describing the ParallelBridge treatment explain converting or bridging traditional iterators into parallel paths, and those showing how to start parallel processing (such as using par_iter and the prelude) reveal the kinds of patterns researchers might consider as alternatives to a direct FromParallelIterator path. The content about transforming a sequential flow into a parallel one (e.g., changing foo.iter() to foo.par_iter()) demonstrates the practical spirit of seeking alternate idiomatic patterns for parallelization, which is thematically aligned with the notion of an alternative folding/reducing approach, though none of the excerpts explicitly state the fold-reduce pattern. The most relevant parts thus connect in a general way to alternate patterns for building parallel collections, whereas explicit confirmation of a fold-reduce pattern is not present in these excerpts. The remaining excerpts provide additional context about par_bridge and related utilities that serve as complementary patterns for parallelization but do not directly substantiate the exact fold-reduce approach.",
      "confidence": "low"
    },
    {
      "field": "parallel_collection_building_patterns.0.code_template",
      "citations": [
        {
          "title": "rayon::iter::FromParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "Collects (key, value) pairs from a parallel iterator into a hashmap. If multiple pairs correspond to the same key, then the ones produced earlier in the..."
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon::prelude::*;\n```\n",
            "```\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        }
      ],
      "reasoning": "The target code template shows using a parallel iterator to produce key-value pairs and collecting them into a HashMap. The most compelling excerpt describes collecting key-value pairs from a parallel iterator into a hashmap, which directly aligns with the code templates pattern of (i, i*i) pairs being collected into a map. A closely related excerpt discusses extending a hashmap with items from a parallel iterator, which is conceptually the same operation (merging from a parallel source into a hashmap) and supports the idea of building or updating a map via parallel iteration. Additional excerpts demonstrate the practical setup for parallel iteration in Rust: importing the Rayon prelude to enable parallel iterator APIs and using into_par_iter() with map to produce pairs or transformed values, which are the exact ingredients seen in the template. One excerpt provides a concrete demonstration of converting an ordinary iterator to a parallel one via a prelude import and a par_iter call, which underpins the overall approach of the template. Another excerpt shows a minimal example of using par_iter and related constructs to perform a computation, illustrating how the templates parallel iteration pattern is typically used, even though it may not show the exact HashMap collection step. Overall, the most relevant items directly support collecting from a parallel iterator into a HashMap, while the others provide necessary context about enabling and using parallel iterators in Rust with Rayon.",
      "confidence": "high"
    },
    {
      "field": "parallel_iterator_patterns.2.code_template",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt shows a concrete function that uses a parallel iterator and map to transform elements, mirroring the requested template. It demonstrates the exact style of parallel transformation with par_iter and a map step, which aligns with the code_template pattern in the target field value. A closely related excerpt also demonstrates the canonical import of the Rayon prelude and the typical setup to enable parallel iterators, which is essential to the code templates operational context. Another excerpt explicitly states the common, simple pattern of converting a sequential iterator to a parallel one by replacing iter() with par_iter(), which underpins the idiomatic approach captured in the code template. Additional excerpts discuss Rayon as a data-parallelism library and its guarantee of data-race freedom, providing supportive context for why this parallel pattern is used, though they do not show the exact code structure. Collectively, these excerpts corroborate the presence and rationale of the code templates components (importing prelude, using par_iter/into_par_iter, applying map, and collecting results), with the most critical support coming from explicit code examples that resemble the target field value. The content mentioning data-race guarantees adds supportive rationale but is secondary to the concrete code pattern. The least direct but still relevant items reference broader descriptions of Rayon and concrete import patterns, which contextualize but do not replace the exact code snippet relevance.",
      "confidence": "high"
    },
    {
      "field": "parallel_collection_building_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:",
            "\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon::prelude::*;\n```\n",
            "```\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```"
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "```\nuse rayon::iter::ParallelBridge;\nuse rayon::prelude::ParallelIterator;\nuse std::sync::mpsc::channel;\n\nlet rx = {\n    let (tx, rx) = channel();\n\n    tx.send( \"one!\" );\n    tx.send( \"two!\" );\n    tx.send( \"three!\" );\n\n    rx\n};\n\nlet mut output: Vec< & 'static str> = rx.into_iter().par_bridge().collect();\noutput.sort_unstable();\n\nassert_eq! ( &* output, & [ \"one!\" , \"three!\" , \"two!\" ]);\n```",
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead.",
            "However, it can still be useful for iterators that are difficult to\nparallelize by other means, like channels or file or network I/O.",
            "large or even unbounded iterators. The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "rayon::iter::FromParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "Collects (key, value) pairs from a parallel iterator into a hashmap. If multiple pairs correspond to the same key, then the ones produced earlier in the..."
          ]
        }
      ],
      "reasoning": "The anti-pattern centers on manually accumulating results into a shared collection from a parallel computation, which introduces locking overhead and contention. Excerpt describing collecting (key, value) pairs from a parallel iterator into a hashmap directly demonstrates the idiomatic approach of gathering parallel results without manual synchronization. It shows that parallel results can be collected into a hashmap in a single, atomic operation, which avoids the explicit per-item locking pattern. Similarly, the extension of a hashmap with items produced by a parallel iterator illustrates a parallel-friendly alternative to incremental, lock-based accumulation, reinforcing the idea that extend/collect operations are preferred over manual shared-state accumulation. Together, these excerpts support the claim that the recommended practice is to use collect/extend-based patterns rather than constructing a shared collection via Arc<Mutex<Vec<T>>> or similar constructs. The surrounding excerpts about enabling parallel iteration (e.g., bringing the Rayon prelude into scope and switching to par_iter) provide context for why these idiomatic patterns arise and how you typically adopt them in Rust, though they are secondary to the direct anti-pattern discussion. The remaining excerpts add nuance (e.g., potential performance trade-offs or alternative parallelization constructs) but do not directly contradict or confirm the core anti-pattern guidance. ",
      "confidence": "medium"
    },
    {
      "field": "parallel_collection_building_patterns.0.pattern_name",
      "citations": [
        {
          "title": "rayon::iter::FromParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.FromParallelIterator.html",
          "excerpts": [
            "Collects (key, value) pairs from a parallel iterator into a hashmap. If multiple pairs correspond to the same key, then the ones produced earlier in the..."
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:",
            "\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon::prelude::*;\n```\n",
            "```\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```"
          ]
        }
      ],
      "reasoning": "The fine-grained field value refers to the collect() behavior when consuming a parallel iterator through the FromParallelIterator path. The strongest match is a description explicitly stating that Collects (key, value) pairs from a parallel iterator into a hashmap, and that if the same key appears, the earlier ones prevail, which directly supports the existence and usage of collect() via FromParallelIterator in a parallel context. Content that explains how to enable parallel iteration by switching to par_iter and using the rayon prelude provides necessaryOperational context for applying the collect pattern in real code, but it does not directly confirm the exact FromParallelIterator-based collect behavior. The remaining excerpts illustrate related helpers and examples (e.g., using prelude, simple map-and-sum examples) that help understand typical usage but do not specify the collect-via-FromParallelIterator pattern itself. Collectively, the direct match confirms the field value, while the surrounding excerpts supply contextual support about enabling parallel iterators and related patterns, which is why they are secondary in relevance. ",
      "confidence": "medium"
    },
    {
      "field": "parallel_collection_building_patterns.0.usage_context",
      "citations": [
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:",
            "```\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```",
            "\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon::prelude::*;\n```\n"
          ]
        },
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "This has the advantage of being able to parallelize just about\nanything, but the resulting `ParallelIterator` can be less efficient than if you started with `par_iter` instead."
          ]
        }
      ],
      "reasoning": "The field value describes a primary and idiomatic pattern for turning parallel iteration results into a new collection, emphasizing high-throughput construction via per-thread buffers that are merged efficiently without user-visible locking, and explicit order preservation for indexed iterators when collecting into Vec<T>. The most directly relevant content shows collecting from a parallel iterator into a final collection, including cases where key-value pairs are gathered into a hashmap from a parallel source. This demonstrates the core idea of taking parallel-produced items and merging them into a single collection, which aligns with the described high-throughput, lock-free merging concept. Another excerpt demonstrates using a parallel iterator to produce a sequence that is then aggregated (via a map and sum) into a final result, illustrating the end-to-end pattern of transforming and reducing parallel data into a single value or structure. A separate excerpt explicitly notes the ability to extend or collect into a collection from a parallel iterator, which is directly aligned with constructing collections from parallel results. Additional excerpts discuss the API surface and the need to bring the parallel iterator traits into scope, which supports the practical usage of these idioms in real code. Lastly, one excerpt documents converting a sequential iterator into a parallel one via a bridge, which is tangentially related since it enables the parallel collection workflow but does not itself describe the final collection construction in detail. Taken together, these excerpts support the idea that a primary idiomatic pattern is to transform parallel results into a final collection efficiently, with attention to ordering for index-based collection creation and minimal locking during merging.",
      "confidence": "medium"
    },
    {
      "field": "parallel_iterator_patterns.2.anti_patterns",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts.",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```"
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The fine-grained field value centers on whether using a specific parallel iterator (into_par_iter()) when the collection does not need to be consumed constitutes an anti-pattern, and it suggests preferring par_iter() or par_iter_mut() and noting overhead on small workloads. The most relevant excerpts are those that articulate the general model of Rayon: converting a sequential computation to parallel with par_iter(), and the assurance of data-race freedom when using parallel iterators. These excerpts directly discuss the mechanism and rationale for using parallel iterators and the expectation that they preserve results and avoid data races, which provides the contextual backdrop for evaluating whether using a parallel iterator in a non-consumptive way is an anti-pattern. The excerpts that mention bringing the Rayon prelude into scope and how to enable parallel iterator APIs reinforce how developers typically enable and use these patterns, which is relevant for judging when a pattern would be overkill or introduce unnecessary overhead. The content discussing data-race freedom helps explain why parallel patterns are safe, but it does not address the specific into_par_iter() anti-pattern claim. Therefore, the most relevant excerpts are those that describe the standard approach to turning sequential code into parallel code (par_iter) and the general guarantees and caveats of parallel iteration, followed by excerpts that describe API usage and scope. The less directly relevant excerpts provide general context about concurrency safety and API surface but do not substantively connect to the anti-pattern of using into_par_iter() in non-consumptive scenarios.",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.1.pattern_name",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The target field value corresponds to a reduction pattern that uses an explicit identity value and a binary operation. The wording in the excerpts shows that a true reduce form can be used with an identity element, and that in practice this identity is supplied (for example, using a fold-like or reduce-like pattern where the initial value is provided, such as a sum with 0). One excerpt explicitly contrasts reduce with the need for an identity element and notes that if possible, prefer a form that requires an identity, which aligns with the concept of a reduction operating with an identity. Another excerpt provides a concrete example where a reduction uses an identity value (0) with a fold-like operation (sum of squares) and returns a final reduced value, illustrating how the identity is incorporated in the reduction. A further excerpt discusses the existence of a reduce_with variant that applies a binary operation across items, which helps differentiate identity-based reduction from that variant, and includes notes about fallible reductions and empty iterators, reinforcing how identity-based reduction differs from other reduction forms. Collectively, these excerpts connect the idea of an identity element being supplied to the reduce-like operation and demonstrate practical usage patterns consistent with .reduce(identity, op).",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.2.pattern_name",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The field value denotes a specific idiomatic parallel sorting pattern that caches results of expensive key extractions to avoid recomputation. Among the excerpts, the most relevant piece discusses sorting a slice in parallel with a key extraction function, which directly aligns with the idea of using a key to drive sorting in parallel, a prerequisite for any cached-key approach. This excerpt indicates that parallel sorting can be driven by a key function, which is foundational to the concept of par_sort_by_cached_key, even if it does not mention caching itself. The next most relevant excerpt describes sorting in parallel with a comparator, which is another common parallel sort approach but not specifically about key extraction or caching; it helps establish the broader context of parallel sort variants in the library. The excerpts about a specific par_sort function show the existence of a parallel sort entry point and its characteristics (such as stability) and thus are relevant to the general pattern of parallel sorting in the API. The remaining excerpts discuss the instability and ordering behavior of the parallel sort, which provides contextual support about how these sorts behave but do not directly address key-extraction or caching concepts. Taken together, these excerpts support the existence of parallel sort patterns that involve keys (and hence motivate a cached-key variant), while not explicitly proving the exact par_sort_by_cached_key name or its caching behavior.",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```"
          ]
        },
        {
          "title": "FoldWith in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.FoldWith.html",
          "excerpts": [
            "\n ID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "The argument `identity` should be a closure that can produce\nidentity value which may be inserted into the sequence as\nneeded to create opportunities for parallel execution.",
            "\n            "
          ]
        }
      ],
      "reasoning": "The most relevant content directly addresses the anti-pattern described: a parallel reduce can yield incorrect results if the combining operation is not associative, because execution order is non-deterministic in Rayon. This aligns with the field values emphasis on associativity as a critical correctness property in map-reduce style patterns. The text also notes that the identity element is important for correctness and efficiency, and that choosing or understanding the right identity can affect results, which matches the field values concern about an incorrect identity value leading to wrong results. Additional excerpts discuss the behavior and guarantees around fold/reduce operations, the role of identity, and examples illustrating how these patterns are intended to be used or avoided in practice. Collectively, these excerpts substantiate the anti-pattern warning (non-associative op) and the identity-related caveats, while also providing context about how the operations are defined and expected to behave in a parallel setting.",
      "confidence": "high"
    },
    {
      "field": "testing_and_reproducibility_patterns.3.code_template",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        }
      ],
      "reasoning": "The fine-grained field value asserts that collecting from a parallel iterator preserves the original order. One excerpt explicitly states that the resulting iterator is not guaranteed to keep the order of the original iterator, which directly contradicts the field values claim about order preservation. This excerpt provides clear evidence that order preservation is not guaranteed in general for parallel iteration, which is relevant for evaluating the accuracy of the code templates assertion. Another excerpt describes the conversion from a sequential iterator to a parallel one by distributing items across the thread pool, which provides context about how the parallel bridge works but does not address ordering explicitly; it helps explain why order might be non-guaranteed in parallel contexts. The remaining excerpt discusses performance bottlenecks related to synchronization, which is tangential to the specific order-preservation claim but still relevant to understanding the broader implications of parallel iteration patterns. Together, these excerpts help assess whether the code templates order-preserving claim is precisely supported or contradicted in typical Rayon behavior.",
      "confidence": "low"
    },
    {
      "field": "parallel_iterator_patterns.2.pattern_name",
      "citations": [
        {
          "title": "Rayon README and Documentation",
          "url": "https://github.com/rayon-rs/rayon",
          "excerpts": [
            "Rayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post](https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) about Rayon, which gives more background\nand details about how it works, or [this video](https://www.youtube.com/watch?v=gof_OEv71Aw) , from the Rust\nBelt Rust conference.)",
            "```\nuse rayon :: prelude :: * ;\nfn sum_of_squares ( input : & [ i32 ] ) -> i32 {\n    input . par_iter ( ) // <-- just change that! . map ( | & i| i * i )\n         . sum ( )\n}\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "To use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the [Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html) . In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```\nuse rayon :: prelude :: * ;\n```",
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into `foo.par_iter()` , and Rayon does the rest:\n",
            "No data races\n\n[]()\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not",
            "You may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom** , which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles** , it typically does the\nsame thing it did before. For the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts."
          ]
        },
        {
          "title": "Docs.rs Rayon - Prelude and Iterability",
          "url": "https://docs.rs/rayon/",
          "excerpts": [
            "Rayon is a data-parallelism library that makes it easy to convert sequential computations into parallel. It is lightweight and convenient for introducing ... Parallel iterators make it easy to convert a sequential iterator to execute in parallel. The ParallelIterator trait defines general methods for all parallel...",
            "The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need.",
            " The rayon prelude imports the various `ParallelIterator` traits. The intention is that one can include `use rayon::prelude::*` and\nhave easy access to the various traits and methods you will need."
          ]
        }
      ],
      "reasoning": "The most directly relevant content describes the core idea of turning a sequential computation into a parallel one by changing the iterator, which is the essence of the into_par_iter() pattern in the broader family of Rayon idioms. Even though the exact method into_par_iter() is not named, the excerpt explains that converting a sequential iterator to a parallel one often involves replacing iter() with par_iter(), capturing the same idiomatic pattern that into_par_iter() would represent when ownership and transformation are considered. The accompanying example of using foo.par_iter() to parallelize computation directly supports the concept of an idiomatic parallelization pattern built on owning or borrowing the collection and then applying a parallel transformation, which is the mechanism into_par_iter() would leverage in owned scenarios. This is complemented by notes that the Rayon prelude brings the necessary ParallelIterator traits into scope, enabling these idiomatic patterns to be used easily in modules. The documentation also emphasizes data-race freedom guarantees, which is a key reason why such parallel iterator patterns are considered safe and idiomatic in Rust. Together, these excerpts support understanding that into_par_iter() is part of the same family of pattern-driven parallelization strategies: replace a sequential iteration with a parallel one, ensure necessary traits are in scope, and rely on safety guarantees to reduce bugs. Other excerpts elaborate on the practical implications of these patterns (e.g., same results as sequential execution, ease of use) and reinforce that this is part of Rayons idiomatic approach to parallelism, even if the exact name into_par_iter() isnt explicitly shown in the excerpts.",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```"
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt states that summing items is essentially like using sum, and that using an appropriate identity (0) with a reduce pattern is basically equivalent to a simple sum. This supports the idea that for simple sums, .sum() is preferred due to its conciseness. Another excerpt discusses reducing a collection with an identity element and notes that this pattern can be simple but less efficient than some alternatives, which supports the idea that .fold().reduce() is a more flexible alternative when the accumulator type must differ from the item type (for example, promoting a smaller integer to a larger accumulator to prevent overflow). A separate excerpt elaborates that fallible reductions (try_reduce and related) exist, indicating alternate patterns when reductions may fail or abort early. Finally, there is acknowledgement that the order of reduction can affect determinism, with a note that for order-dependent reductions, a sequential Iterator::reduce is the correct option, which directly supports the anti-pattern or alternative pattern requirement for certain contexts. Taken together, these excerpts map cleanly to the field values guidance: use .sum() for simple sums; use .fold().reduce() when accumulator types differ; and recognize that for order-dependent reductions, a sequential reduce is necessary.",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The finegrained field value highlights a specific anti-pattern: using parallel reduction with standard floating-point numbers can yield non-deterministic results because floating-point addition is not strictly associative. The most relevant excerpt directly acknowledges this issue: when reducing items in a parallel iterator, the order is not specified, and if the operator is not truly associative (as with floating-point addition), the results can be non-deterministic. This directly substantiates the anti-pattern by linking non-associativity to nondeterministic results in parallel reductions. The remaining excerpts are progressively less direct but still relevant: they discuss how reduce-like operations work in Rayon, including methods like reduce_with, try_reduce, and fold_with, and they mention determinism and identity considerations in reductions. Taken together, they provide broader context on how parallel reductions are implemented and under which conditions behavior could vary, aligning with the anti-pattern focus on non-deterministic results due to floating-point inaccuracies in parallel sums.",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.0.usage_context",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The field value describes a concise and idiomatic pattern for simple numeric aggregation in parallel, using a map phase in parallel and a subsequent efficient sum, with readability and efficiency as key attributes. The first excerpt explicitly documents summing the items in a parallel iterator and notes that the operation is essentially a parallel reduction with an identity element and that determinism depends on operation associativity, which aligns with encouraging a simple, readable pattern for numeric sums in parallel. The description of reduce_with further reinforces the idiomatic pattern by showing how to reduce with a binary operation that combines items, which is a natural generalization of summation when a simple sum suffices but a more explicit combination rule is needed. The next excerpt expands on a fallible reduction with try_reduce, illustrating how to handle potential early termination or errors during parallel reduction, which is a useful extension of the same aggregation theme when robustness is needed. The following excerpt on try_reduce_with extends the same concept to fallible reductions with an operator, reinforcing the same idiomatic design space for parallel aggregation with error handling. Finally, fold_with demonstrates applying a folding operation across the iterator to accumulate a result, which is another core idiomatic pattern for parallel aggregation, showing how initial values can be integrated and how the folding behavior maps to a straightforward accumulation. Taken together, these excerpts substantiate the field value by demonstrating that a parallel map followed by a straightforward reduction (sum) is a canonical, idiomatic, and efficient pattern in Rayon for numeric aggregation, and that there are related idiomatic reduction patterns that cover broader needs while preserving readability and performance.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.2.usage_context",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The most directly relevant content describes sorting a slice in parallel with a key extraction function, which aligns with the concept that a key can be extracted in parallel to guide the sort. This supports the notion of integrating a key extraction step into a parallel sorting workflow, which is the core idea of using an expensive key to drive an efficient sort. The presence of a parallel sort implementation (par_sort) and the direct mention of parallel key extraction indicates alignment with the high-level pattern described in the field value. Another excerpt confirms that parallel sorting can be done and discusses its characteristics; while it mentions stability concerns (which informs the nuance that parallel sorts may be unstable with respect to equal elements), it still reinforces the mechanism of parallelism in the sort process. The comparator-focused variant indicates an alternative approach to sorting in parallel (using a comparator rather than a separate key), which is conceptually related but not the same as a key extraction pipeline. The least directly relevant excerpt merely repeats a fragment about equal elements and does not add new information about the parallel key extraction pattern. Taken together, these excerpts support the core idea of performing sorting in parallel with an extraction step, but there is insufficient explicit evidence about the caching of keys (compute-once) to fully confirm that exact operational detail.",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.1.code_template",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```"
          ]
        },
        {
          "title": "FoldWith in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.FoldWith.html",
          "excerpts": [
            "The argument `identity` should be a closure that can produce\nidentity value which may be inserted into the sequence as\nneeded to create opportunities for parallel execution.",
            "\n ID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "\n F: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\")",
            "\n            "
          ]
        }
      ],
      "reasoning": "The code template presents a Rayon-based reduction over a parallel iterator that defines an identity value and a combining function to aggregate a pair of numbers. The most directly supportive content is a document snippet that explicitly shows a reduce-like operation with an identity element and a combining function, including an example that reduces a collection of items into a single result. Another highly supporting excerpt demonstrates the parallel reduction pattern with an explicit identity and a fold/reduce-like operation, reinforcing the same idiom of initializing with an identity and then aggregating items. Additional excerpts discuss similar reduce patterns, including fallible reductions (try_reduce) and variants that take an initialization (fold_with) or a custom operator (reduce_with), which align with the notion of a code template that uses an identity and a binary operation to accumulate results. Together, these excerpts substantiate the existence and typical structure of the idiomatic map-reduce pattern in Rust Ryzen/Rayon, including par_iter usage, identity initialization, and the accumulation step.",
      "confidence": "high"
    },
    {
      "field": "testing_and_reproducibility_patterns.3.anti_patterns",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Iterator items are pulled by \\`next()\\` one at a time, synchronized from each thread that is\n22 /// ready for work, so this may become a bottleneck if the serial iterator can't keep up with the\n23 /// para"
          ]
        }
      ],
      "reasoning": "The targeted anti-pattern asserts that performing ordered assertions or relying on ordered side-effects inside a parallel closure is risky because the execution order is not guaranteed, leading to flaky tests. One excerpt directly states that the resulting iterator is not guaranteed to keep the order of the original iterator, which directly undercuts any assumption of a fixed order in parallel processing and supports treating ordered tests or logging inside parallel code as an anti-pattern. Another excerpt discusses how items are pulled by next() from multiple threads and mentions synchronization and potential bottlenecks in parallel execution, indirectly reinforcing that parallel workflows do not preserve strict ordering, contributing to the rationale that ordering-based assertions in parallel closures are fragile. The remaining excerpt provides a general description of converting sequential iterators to parallel ones but does not specifically address ordering guarantees or anti-patterns, making it less directly supportive of the fine-grained value.",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The target field asserts that for more general reductions, a reduce-like approach provides control, and that for floating-point sums where precision matters, a sequential or parallel compensated sum variant is preferable; and for non-numeric types, using reduce or fold is necessary. The most relevant excerpts directly delineate the reduction and folding primitives: one excerpt shows the fold_with pattern, which applies a folding operation across items to produce a final value, illustrating the practical use of a folding pattern in reductions. Another excerpt details reduce_with, describing a variant where an operation combines two items into a new one and returns a new reduced item, highlighting how a custom reduction can be structured and when an identity or empty case yields None. Additional excerpts describe try_reduce_with, which extends the reduction concept to a fallible operation, and try_reduce, which explains a fallible reduction with an identity and termination behavior. A further excerpt discusses the basic reduce operation, including the idea that the reduction of an iterator may be non-deterministic for certain types and that a separate identity-based reduction is often preferable. Collectively, these excerpts establish the core primitives (reduce, fold, and their fallible variants) and their typical usage patterns, which align with the fields focus on general reductions and patterns for correctness and control. The remaining excerpt discusses only summation behavior or specific sum implementations (sum) without introducing new reduction patterns, offering supporting context but not directly extending the reduction-centric claim in the field. ",
      "confidence": "medium"
    },
    {
      "field": "testing_and_reproducibility_patterns.3.usage_context",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool.",
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "Iterator items are pulled by \\`next()\\` one at a time, synchronized from each thread that is\n22 /// ready for work, so this may become a bottleneck if the serial iterator can't keep up with the\n23 /// para",
            "The resulting iterator is not guaranteed to keep the order of the original iterator."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explains the concept of converting a sequential iterator into a parallel one by distributing items across a thread pool, which is central to the idea of parallelized work needing to be reconciled with deterministic verification in tests. This directly supports the notion that there is a bridge between sequential and parallel processing and that such a bridge is used in contexts where order or determinism may matter, aligning with the field values focus on how to verify outputs that depend on the original sequence order. The next excerpt discusses a potential bottleneck when the serial source cannot keep up with parallel execution, highlighting the practical performance and synchronization considerations that accompany preserving or reconciling order in a parallel workflow. The final excerpt explicitly notes that the resulting iterator is not guaranteed to keep the original order, which directly addresses the issue of order preservation and thus provides a counterpoint or limitation to the idea of always collecting into an ordered Vec for deterministic tests. Taken together, these excerpts connect the concepts of bridging, parallel work, and order determinism in tests, with a direct caveat about non-deterministic ordering, which helps evaluate the high-level claim but introduces ambiguity about guaranteed order preservation.",
      "confidence": "medium"
    },
    {
      "field": "testing_and_reproducibility_patterns.3.alternate_patterns",
      "citations": [
        {
          "title": "Rayon ParallelBridge trait documentation",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Expand description\n\nConversion trait to convert an `Iterator` to a `ParallelIterator` . This creates a bridge from a sequential iterator to a parallel one, by distributing its items\nacross the Rayon thread pool."
          ]
        },
        {
          "title": "Rayon par_bridge.rs (source excerpt)",
          "url": "https://docs.rs/rayon/latest/src/rayon/iter/par_bridge.rs.html",
          "excerpts": [
            "The resulting iterator is not guaranteed to keep the order of the original iterator.",
            "Iterator items are pulled by \\`next()\\` one at a time, synchronized from each thread that is\n22 /// ready for work, so this may become a bottleneck if the serial iterator can't keep up with the\n23 /// para"
          ]
        }
      ],
      "reasoning": "The field value discusses streaming ordered results and the choice between complex patterns (such as tagging items with their index and reordering via a channel) versus the simpler collect-then-act approach. The most directly relevant excerpt states that the resulting iterator is not guaranteed to keep the order of the original iterator, which directly concerns ordering guarantees in a parallel context. A closely related excerpt describes converting a sequential Iterator into a ParallelIterator, effectively creating a bridge that distributes items across a thread pool; this contextualizes how items may be processed out of order when parallelized, which is central to evaluating streaming vs. collecting strategies. Another excerpt notes general behavior of pulling items from multiple threads and potential bottlenecks, which while less about ordering, reinforces the complexity of coordinating parallel work. Together, these excerpts support the idea that ordering is not guaranteed in parallel iterations and that patterns to preserve or reorder streaming results require additional mechanisms beyond default parallel processing. The reasoning shows how the cited excerpts align with evaluating the specific pattern of streaming ordered results and the trade-offs with collect-then-act.",
      "confidence": "medium"
    },
    {
      "field": "configuration_and_tuning_patterns.1.pattern_name",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it.",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>"
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); ",
            "Multiple Thread Pools"
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        },
        {
          "title": "Clarify rust rayon nested thread pool worker numbers - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76919721/clarify-rust-rayon-nested-thread-pool-worker-numbers",
          "excerpts": [
            "I have tried to use rayon 's parallel iterators in a nested way. As a global pool would have a fixed number of threads, I tend to create an outer-pool in main.",
            "vec!\n[1, 2, 3, 4].into_par_iter().map(|inner| stress(outer * 10 + inner)).collect(",
            "})"
          ]
        },
        {
          "title": "How can I create a HashMap using Rayon's parallel fold?",
          "url": "https://stackoverflow.com/questions/70096640/how-can-i-create-a-hashmap-using-rayons-parallel-fold",
          "excerpts": [
            "})",
            "})"
          ]
        },
        {
          "title": "GitHub Issue: Performance of par_bridge (#685)",
          "url": "https://github.com/rayon-rs/rayon/issues/685",
          "excerpts": [
            "})"
          ]
        }
      ],
      "reasoning": "The target field value names a specific idiomatic pattern: using a ThreadPoolBuilder to create or configure a thread pool in a per-task customization context. Excerpts that state ThreadPoolBuilder is used to create a new ThreadPool or configure the global thread pool directly support this framing, as they establish ThreadPoolBuilder as the canonical entry point for building pools. References that describe constructing a new thread pool with a given configuration also reinforce the association between the builder and the pool configuration, aligning with the idea of a per-task or per-situation pool configuration. Mentions of using multiple thread pools demonstrate the broader idiomatic pattern where different pools are created for different tasks or contexts, which aligns with the concept of per-task custom pools. Additional excerpts that discuss the existence of a global pool, or general changes to thread counts, provide supportive context for how and why one might choose ThreadPoolBuilder to tailor behavior, though they are less directly tied to the per-task customization idea. Overall, the most directly supportive content is the description of ThreadPoolBuilder as the tool to create and configure pools, while notes on multiple thread pools illustrate the per-task or context-specific pool usage.",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The target pattern describes applying a map operation to each element and then summing the results. The most directly relevant excerpt shows code that maps each item (e.g., computing the square of each element) and then reduces the results to a sum, illustrating the exact flow of map followed by a reduction with a sum-like outcome. Related excerpts discuss the general behavior of summing items and various reduce-like methods (reduce, try_reduce, fold) and their interaction with transformation steps, which provides supporting context about how such idioms behave and when they are advantageous. While not all excerpts present the exact chained call, they collectively demonstrate the same structural pattern: a per-item transformation precedes an aggregation, which is the essence of the requested idiomatic pattern. , ",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.3.code_template",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>"
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        }
      ],
      "reasoning": "The provided code template demonstrates parallel processing of a mutable slice in chunks using a parallel iterator from Rayon. This directly relates to how a Rayon thread pool is created and configured to support parallel work: you can build or configure a thread pool to control the number of worker threads and how tasks are scheduled. Excerpts describing creating or configuring a ThreadPool or its builder show the mechanisms by which such a code pattern would be set up, including how many threads are available and how to initialize the pool. Other excerpts discuss the maximum number of threads Rayon supports and the general role of ThreadPool in Rayon, which further clarifies the operational environment in which this code template would run. Collectively, these excerpts support the idea that a code template for parallel in-place chunk processing relies on a configured thread pool and tuning parameters, which aligns with the finegrained field value focused on configuration and tuning patterns for idiomatic Rayon usage. The most directly connected information is about creating/configuring the thread pool and understanding its limits, while additional excerpts provide context about the role and representation of the ThreadPool in Rayon documentation.",
      "confidence": "medium"
    },
    {
      "field": "order_and_indexing_patterns.0.code_template",
      "citations": [
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Collects the results of the iterator into the specified vector. The vector is always truncated before execution begins. If possible, reusing the vector across ..."
          ]
        }
      ],
      "reasoning": "The code template demonstrates using a parallel iterator that yields index-value pairs by enumerating over the data, and then collecting the results into a vector. The first supporting excerpt explains that enumerating over an IndexedParallelIterator yields the current count alongside each element, and that this enumerator is created via an enumerate() method on an IndexedParallelIterator, which directly matches the pattern shown in the code snippet. The second supporting excerpt describes the concept of an IndexedParallelIterator as one that provides random access to data by allowing the iterator to be split at arbitrary indices, which underpins the parallel enumeration and indexing behavior used in the code template. The third supporting excerpt discusses collecting the results of an iterator into a specified vector, including the behavior that the target vector is truncated before execution begins, which corresponds to the collect() operation in the code template. Together, these excerpts directly support understanding of parallel enumeration, indexing, and collection in the given pattern.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.3.anti_patterns",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>"
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ...",
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        }
      ],
      "reasoning": "The core idea behind the targeted anti-pattern is that choosing an excessively small chunking granularity (chunk_size) can lead to a large number of tiny tasks, which adds overhead and harms performance. While the excerpts do not explicitly mention chunk_size, they provide concrete information on how Rayons thread pool is created and configured, which is precisely where such a tuning decision would be made. Excerpts describing the ThreadPoolBuilder and how a thread pool is configured (including the number of threads and related settings) are highly relevant because they establish the architectural knobs that influence task granularity, scheduling, and potential overhead. Other excerpts describe the ThreadPools role, its construction, and constraints on maximum thread counts, which are important context for understanding the boundaries within which chunking decisions operate. Taken together, these excerpts illustrate the practical mechanisms for tuning Rayon performance and highlight where a misconfiguration (e.g., too many tiny tasks due to overly granular work partitioning) can degrade performance, thus supporting the concept of an anti-pattern in configuration and tuning patterns. The least directly connected excerpts discuss specific configuration topics, such as explicit configuration structures and environmental overrides, which still provide context for how tuning decisions are implemented in code and how they might influence perceived anti-patterns, even if they do not name the anti-pattern explicitly.",
      "confidence": "medium"
    },
    {
      "field": "parallel_sorting_patterns.2.code_template",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The provided code template shows a parallel sort on a vector of strings using a key extraction (to_uppercase) with a cached key, which aligns with the concept described as sorting a slice in parallel with a key extraction function. One excerpt states that such parallel sorts can use a key extraction function and notes that the operation may not preserve order for equal keys, which is consistent with parallel, potentially unstable sorts and supports the notion of a key-based parallel sort being used in practice. Another excerpt demonstrates the concrete parallel sort API, namely the par_sort function, which directly illustrates the parallel sorting mechanism within the Rayon API. Additional excerpts discuss parallel sorts with a comparator and the stability considerations (stable vs unstable) of parallel sorts, which helps contextualize why a cached-key variant can be beneficial for performance, as in the template. Finally, one excerpt explicitly shows a short note about equal elements in the context of sorting, reinforcing the stability/ordering implications of parallel sorts. Taken together, these excerpts substantiate the core ideas of performing parallel sorts, using key extraction or cached keys, and the potential trade-offs in stability and ordering, which underpins the code template provided.",
      "confidence": "medium"
    },
    {
      "field": "configuration_and_tuning_patterns.3.usage_context",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "### impl<S> [Freeze](https://doc.rust-lang.org/nightly/core/marker/trait.Freeze.html \"trait core::marker::Freeze\") for [ThreadPoolBuilder](struct.ThreadPoolBuilder.html \"struct rayon::ThreadPoolBuilder\") <S>"
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ...",
            "Constructs a new thread pool with the given configuration. If the configuration is not valid, returns a suitable Err result. See InitError for more details. fn ..."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        }
      ],
      "reasoning": "The fine-grained field describes a pattern of processing large blocks of data using coarse-grained parallelism to improve efficiency and cache locality. In Rayon, achieving parallelism and performance is largely driven by how you configure and use a thread pool. Excerpts that discuss creating and configuring a ThreadPool and its builder show how you can establish the parallel execution context (e.g., specifying the number of threads, using a builder to customize settings, and understanding the pools role in controlling parallel work). This directly supports the idea that employing a dedicated thread pool and tuning its configuration is a central idiomatic approach to enable coarse-grained parallel execution in Rayon. Other excerpts reinforce the same connection by describing the ThreadPool as a user-created pool and by noting limits or behavior when configuring threads, which further ties the pattern to how Rayon manages parallel workload and performance. While the exact phrasing of the pattern (chunk-at-a-time processing, reduced scheduling overhead, and improved cache locality) is not verbatim in the excerpts, the material aligns with using a tuned thread pool to achieve efficient, coarse-grained parallelism.",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.2.alternate_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The finegrained field value discusses alternate patterns for aggregations in a parallel iterator context, including when to use a simple reduction (reduce) and what presents a non-parallel or variant approach (sequential fold). Excerpts that describe reduction operations show how to combine items into a single value using a binary operation, which directly aligns with the idea of alternate aggregation patterns. For example, one excerpt states that a reduction reduces items into one item using a binary operation, and notes that such a variant can be simpler but possibly less efficient, highlighting why one might choose an alternate pattern like a straightforward fold in some contexts. Another excerpt explains a related fallible reduction variant, which demonstrates a different flavor of aggregation semantics and control flow when errors or empty iterators occur, informing when you might prefer alternative reduction strategies over parallel accumulation. A separate excerpt describes summing as an aggregation pattern, which reinforces that reduction-family patterns (fold, reduce, sum) serve as distinct options for combining items. The remaining excerpts reinforce the general behavior of reduction patterns (e.g., identity requirements, when to prefer reduce over reduce_with, or how try_reduce behaves), which helps map the space of alternative idioms against the specific need to identify non-collect-based aggregation approaches. Taken together, these excerpts support the notion that collect-based assembly from parallel iterators is one possible pattern, while explicit reduction variants and folds are natural alternatives in this codebase.",
      "confidence": "medium"
    },
    {
      "field": "order_and_indexing_patterns.0.usage_context",
      "citations": [
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "nd\") ,\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. ",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n"
          ]
        }
      ],
      "reasoning": "The target field emphasizes an idiom where an elements original position is captured during parallel processing and paired with that element, so that the final output preserves correct ordering when collected. Directly, an example that shows enumerating elements alongside their index demonstrates the basic mechanism of attaching an index to each item. That concept underpins the broader pattern of maintaining and utilizing original positions during parallel work. Several excerpts describe functions that expose or rely on the index of matched or located items, such as returning indices of items that satisfy a predicate. This supports the idea that parallel iteration can track and expose positions, which is essential for maintaining order. Additional excerpts discuss how collecting results into a vector can be ordered or truncated prior to execution, highlighting the practical consequence of linking items with indices to produce ordered outputs. Together, these excerpts map closely to the fine-grained field value: the idiom of pairing items with their original index and using that information to preserve or enforce order, thereby reducing bugs related to ordering when parallelism is involved.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Collects the results of the iterator into the specified vector. The vector is always truncated before execution begins. If possible, reusing the vector across ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt states that Enumerate is an iterator that returns the current count along with the element, and that this struct is created by the enumerate() method on IndexedParallelIterator. This confirms that enumerate() does provide an index for each item, which is central to reasoning about how a for_each over an enumerated parallel iterator could introduce concerns about the order of side effects. The next closest excerpts describe that there exists an iterator with support for random access to data, i.e., indexing into the parallel collection, which relates to how items can be addressed by index in a parallel context. Another excerpt describes collecting results of a parallel iterator into a vector, including vector truncation before execution, which touches on how results from parallel iteration are materialized, and by implication how non-deterministic ordering could affect aggregation of side effects if such non-determinism is involved. Taken together, these excerpts support the notion that while indexing (via enumerate) is available, the execution order of side effects in a parallel for_each is not guaranteed due to the nature of work-stealing and parallel scheduling, which aligns with the anti-pattern concern in the fine-grained field value.",
      "confidence": "medium"
    },
    {
      "field": "parallel_collection_building_patterns.1.code_template",
      "citations": [
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        }
      ],
      "reasoning": "The code template explicitly demonstrates extending a vector by applying a parallel iterator: it uses a parallel-extension method on a mutable vector and passes a range to be extended. The first excerpt directly documents the par_extend method signature, which aligns with the code templates use of par_extend to absorb elements from a parallel iterator. The second excerpt describes the general idiom of converting sequential iterators to parallel ones using Rayon (e.g., turning foo.iter() into foo.par_iter()) and notes that Rayon handles the parallelization. This supports the interpretation that the code template embodies a common parallel-building pattern where a collection is extended by consuming items from a parallel iterator. Together, these excerpts corroborate the field value as a typical parallel-collection-building template in Rayon, with the direct method usage shown in the first excerpt and the idiomatic pattern context shown in the second excerpt.",
      "confidence": "high"
    },
    {
      "field": "parallel_collection_building_patterns.1.pattern_name",
      "citations": [
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to a parallel extension method that adds items to a collection using a parallel iterator, specifically par_extend implemented through ParallelExtend. The excerpt that directly mentions this exact API and the signature par_extend<I>(&mut self, par_iter: I) clarifies how the method is invoked and what it is called in practice. This directly supports the field value by naming the same function and its mechanism (via ParallelExtend). Additionally, the excerpt describing how Rayon typically converts a sequential iterator into a parallel one and uses par_iter, with Rayon handling the rest, provides essential context about the idiomatic pattern for building parallel collections. It reinforces the same idiomatic approach (using a parallel extension/iterator to build a collection) and explains the surrounding usage pattern, which corroborates the identification of the pattern name and its practical deployment. Together, these excerpts map to the pattern of extending a collection in parallel using a dedicated API pathway (ParallelExtend) and the common idiomatic workflow (switching to par_iter and letting Rayon manage parallelism).",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "nd\") ,\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. ",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.",
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []"
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_last](.position_last) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.\n# [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 3 ), Some ( 3 ));\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 100 ), None );\n```\n",
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Collects the results of the iterator into the specified vector. The vector is always truncated before execution begins. If possible, reusing the vector across ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value points to using a manual iterator of indices (0..len) paired with the data iterator as an alternate pattern to enumerate. The most directly relevant excerpt explicitly describes enumerate as an iterator that returns the current count along with the element, which matches the idea of index-based iteration via enumerate-like pattern. Excerpts that discuss patterns for indexing in rayon (such as finding first/last matches in parallel iterators and the notion of position with respect to indices) are relevant as they describe alternative approaches to locating or aligning data by index in parallel contexts. They provide context on how indexing and position-based patterns are implemented or could be used in rayon, which informs the broader category of alternate patterns to manual index-iteration. Other excerpts that elaborate on specific indexing trait methods (like collecting results into a vector with indexed parallel iterators, or examples demonstrating position_first/position_last) further support the broader concept of indexing-based processing patterns, though they do not directly describe the exact enumerate approach. Taken together, the most supportive content is the explicit enumerate description, while the surrounding excerpts illustrate related indexing and position-based strategies in rayon that serve as context for alternate patterns. This yields a medium level of overall confidence since the central claim (enumerate-like pattern as a direct alternative) is strongly supported, while the surrounding indexing-pattern discussions provide supportive but not conclusive evidence about enumerating indices in this exact form.",
      "confidence": "medium"
    },
    {
      "field": "order_and_indexing_patterns.1.code_template",
      "citations": [
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```"
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "<Self>\n\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.\nThis means that if two threads are used there will be **no** speedup **at\nall** . `by_exponential_blocks` on the other hand will start with the leftmost range from 0\nto `p` (threads number), continue with p to 3p, the 3p to 7p\n\nEach subrange is treated in parallel, while all subranges are treated sequentially. We therefore ensure a logarithmic number of blocks (and overhead) while guaranteeing\nwe stop at the first block containing the searched data. [Source](../../src/rayon/iter/mod.rs.html)\n",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice."
          ]
        }
      ],
      "reasoning": "The code template demonstrates a deterministic search for the first matching element using a parallel iterator's position_first, and a non-deterministic search using position_any where the index may be 2 or 3. An excerpt that explicitly defines the semantics of searching for the first match and returning its index, including the idea that further attempts to the right are stopped and earlier matches may still be found, directly supports the concept of a deterministic first-position index lookup within a parallel iterator. The same reasoning applies to the non-deterministic variant described for position_any, which may not yield the first match and may stop processing after a match is found, matching the non-deterministic behavior shown in the code template. Additional excerpts provide general definitions of the relevant methods on the IndexedParallelIterator (searches for items in the parallel iterator that match a predicate and return their indices) and reinforce the context of indexing behavior in rayons parallel iterators. The remaining excerpts elaborate related tooling (e.g., by_exponential_blocks and find_first/find_any semantics) which are contextually adjacent but not directly illustrating the exact code template constructs used (position_first and position_any).",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); "
          ]
        }
      ],
      "reasoning": "The fine-grained field value asserts that the simplest alternative for controlling the thread count is to set the RAYON_NUM_THREADS environment variable, and that when no configuration is provided Rayon defaults to a number of threads equal to the number of logical CPUs. The most directly supporting evidence comes from discussions explicitly stating: (a) you can change the number of threads by setting the RAYON_NUM_THREADS environment variable, which is described as a straightforward approach, (b) there is a default behavior where Rayon uses a number of threads equal to the CPUs when no configuration is provided, and (c) it is useful in scripting or CI environments, which reinforces its role as a simple, environment-driven alternative. Additional excerpts discuss other tuning patterns, such as ThreadPoolBuilder configurations to create and customize thread pools, which contextualize alternate patterns beyond the env-var approach. They show that while env var is the simplest, there are more granular control mechanisms available (e.g., specifying number of threads via ThreadPoolBuilder, or querying the maximum allowed threads). The content about the maximum thread cap provides a boundary that complements the discussion of alternative patterns by explaining constraints when adjusting thread counts. Together, these excerpts support the claim that the environment-variable approach is the simplest alternative pattern, while acknowledging other patterns exist and the default behavior when not configured.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Enumerate in rayon::iter - Rust - Docs.rs",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.Enumerate.html",
          "excerpts": [
            "Enumerate is an iterator that returns the current count along with the element. This struct is created by the enumerate() method on IndexedParallelIterator."
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "nd\") ,\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. ",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.",
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_last](.position_last) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.\n# [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 3 ), Some ( 3 ));\n\n assert_eq! ( a . par_iter (). position_last ( | & x | x = = 100 ), None );\n```\n",
            "An iterator that supports random access to its data, meaning that you can split it at arbitrary indices and draw data from those points.",
            "Collects the results of the iterator into the specified vector. The vector is always truncated before execution begins. If possible, reusing the vector across ..."
          ]
        }
      ],
      "reasoning": "The target field value describes using enumerate to achieve order-preserving indexed processing. The strongest support is found in the excerpt that defines Enumerate as an iterator created by enumerate() on an IndexedParallelIterator and that it returns the current count alongside the element. This directly confirms the core mechanism behind an enumerate-based, order-aware indexing pattern in the context of parallel iteration.\n\nAdditional excerpts discuss indexing semantics and order-sensitive operations within Rayons parallel iterators. For instance, there are descriptions of how to locate the first or last matching element in a parallel iterator and the behavior of the iterator with respect to ordering and indexing, which provide necessary context about how indexing patterns interact with order guarantees in parallel execution. These excerpts help justify when and why an enumerate-based approach would be considered order-preserving or when alternative indexing strategies (e.g., position-based searches) might be used.\n\nOther excerpts describe general capabilities of IndexedParallelIterator, such as random access and collecting results, which situate enumerate within the broader family of indexed operations. While these are not about enumerate itself, they support understanding of how indexing and data access patterns work in this space, reinforcing why enumerate on an IndexedParallelIterator aligns with an order-preserving indexed processing approach.\n",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.2.code_template",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The code template demonstrates two core patterns: a folding step over items with an initial accumulator, followed by a combining step that merges partial results from different threads. The folding pattern is described as applying a fold operation to an initial value with each item in the iterator, producing the value for later use, and it is noted that this behaves similarly to a fold that starts from init.clone(), while not requiring the init type to be Sync or any extra synchronization. This directly supports the codes approach of starting from an initial accumulator and iterating over items to build up a partial result. The discussion of reduce-like patterns explains that items can be reduced into a single item using an operation, with an explicit note that there may be an identity element that can improve efficiency, which aligns with the subsequent combination of partial results from the fold step. Additionally, there is explicit detail that the reduce_with variant reduces items into one item using an operator, with T being the element type and the operation potentially requiring identity semantics, which matches the templates second phase where partial results are merged into a final result (the codes reduce_with corresponds to combining per-thread hash maps into a single map). The documentation around these functions also clarifies that fold is a progressive, item-by-item accumulation, while reduce/reduce_with provides a means to collapse those accumulations into a final value, mirroring the templates overall structure of performing a local fold to accumulate counts per key and then reducing those per-key maps into a single map. The presence of similar fold_with and reduce_with definitions in the excerpts provides direct support for understanding how the given code template would behave and why it is a sound idiomatic pattern for parallel aggregation. Finally, the discussion of identity elements and the distinction between simple reductions and fallible reductions offers contextual justification for why initial values and the choice between different reduction strategies matter for correctness and performance in this idiomatic Rust pattern.",
      "confidence": "high"
    },
    {
      "field": "parallel_collection_building_patterns.1.usage_context",
      "citations": [
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes an idiomatic pattern for growing an existing collection in parallel by using a parallel iterator and an extend/collect-like operation that avoids manual locking, typically via thread-local storage that is later merged into the target collection. The most direct support comes from the excerpt describing a method that extends a collection (a hash map) with items produced by a parallel iterator, explicitly naming this as the parallel analogue of extend, and noting its high-throughput nature. This shows the core pattern: use a parallel iterator to generate items and incorporate them into an existing collection in a thread-safe, efficient manner. The second excerpt reinforces the same idiomatic direction by explaining how Rayon enables converting standard sequential iterators into parallel ones via par_iter, which is the practical entry point for adopting parallel-collection-building patterns in code. Together, these excerpts directly illustrate the intended pattern: use a parallel iterator to feed items into an existing collection in a way that is high-throughput and reduces locking complexity, aligning with the described idiomatic approach to growing a collection in parallel.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```",
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n"
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []"
          ]
        }
      ],
      "reasoning": "The targeted field value flags a prominent anti-pattern: treating find_any as if it returns the first element, which leads to flaky tests and hard-to-reproduce bugs. One excerpt explicitly states that a parallel search using find_any may not find the first match and that you should use find_first when determinism is required, directly supporting the anti-pattern and its remedy. Another excerpt explains that the function searches for the first item in the parallel iterator and compares it to an alternative that may not be ordered, illustrating how first-match semantics are expected in deterministic contexts. A third excerpt reinforces the notion that the first-match semantics are important for performance considerations and determinism, further supporting the recommended shift from find_any to find_first in contexts where determinism matters. Together, these excerpts establish that assuming find_any yields the first element is the anti-pattern, and using find_first is the correct practice when a deterministic result is required.",
      "confidence": "high"
    },
    {
      "field": "parallel_sorting_patterns.2.alternate_patterns",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "9    /// of equal elements."
          ]
        }
      ],
      "reasoning": "The described manual patternforming a collection of (key, original_value) tuples, sorting by the key, and then extracting the original valuesmaps directly to parallel sorting approaches that operate with a key or a comparator. An excerpt stating that a parallel sort can be done with a key extraction function shows the exact mechanism of sorting by a derived key rather than by the full value, which aligns with the idea of ordering by a key and then pulling out the original values. Another excerpt highlights the existence of a parallel sort routine (par_sort), which is the parallel analogue of a standard sort and is relevant when you want to sort a collection based on a key in parallel. A third excerpt notes that parallel sorting can be driven by a comparator function, which is another way to influence how elements are ordered when forming the sorted sequence of pairs. This set of excerpts collectively covers the core steps: (a) define a key-based sort (via a key extraction function), (b) perform the sort in parallel (par_sort), and (c) the comparator-based variation that could be used instead of a key extraction approach. The remaining excerpts reinforce the behavior (e.g., potential non-determinism in order for certain parallel sorts and related notes) and provide additional context about parallel sorting variants, which helps frame the trade-offs in choosing a specific approach. Overall, the most relevant parts describe parallel, key-based sorting and the existence of a parallel sort primitive, directly supporting how the manual pattern could be implemented efficiently in parallel.",
      "confidence": "medium"
    },
    {
      "field": "order_and_indexing_patterns.1.usage_context",
      "citations": [
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```"
          ]
        },
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice.",
            "<Self>\n\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.\nThis means that if two threads are used there will be **no** speedup **at\nall** . `by_exponential_blocks` on the other hand will start with the leftmost range from 0\nto `p` (threads number), continue with p to 3p, the 3p to 7p\n\nEach subrange is treated in parallel, while all subranges are treated sequentially. We therefore ensure a logarithmic number of blocks (and overhead) while guaranteeing\nwe stop at the first block containing the searched data. [Source](../../src/rayon/iter/mod.rs.html)\n",
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []"
          ]
        }
      ],
      "reasoning": "The most relevant content directly contrasts when a guaranteed first matching element should be used versus when any matching element suffices for performance gains. One excerpt explains that position_first finds the first item that matches and stops attempts to the right, ensuring correctness in order-sensitive scenarios, while noting that position_any may not return the first match and can stop earlier for faster results. This directly supports the finegrained field value, which emphasizes using the first option for correctness in order-sensitive algorithms and the any option for speed when the exact position is not required. Another excerpt reiterates that find_any is capable of stopping the search once a match is found, highlighting the performance rationale behind choosing any over the first when possible. A third excerpt discusses how by_exponential_blocks can be used to balance work and improve performance, while still supporting the idea that certain patterns (like find_first) have benefits for predictable performance and early stopping. A fourth excerpt reinforces the idea by describing the behavior of the find_first and find_any patterns and their respective guarantees, which underpins the safety and efficiency trade-offs. The remaining excerpts provide general context about the indexed parallel iterator API and related methods, which help situate the discussed patterns within the broader API surface but do not directly assert usage guidance for correctness versus performance beyond the explicitly cited methods. In sum, the collection of statements supports the central guidance: use the guaranteed-first pattern for correctness in order-sensitive contexts, and use the any-pattern for faster results when the exact position is not essential, with additional optimization via block sizing when appropriate.",
      "confidence": "medium"
    },
    {
      "field": "configuration_and_tuning_patterns.0.code_template",
      "citations": [
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method."
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); "
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        }
      ],
      "reasoning": "The most relevant excerpts directly show the exact pattern of constructing a ThreadPoolBuilder, configuring it with a specific number of threads, optionally configuring stack size, and building the global pool with build_global (or its close equivalent) and handling the result. The excerpt with an explicit call to ThreadPoolBuilder::new().num_threads(4).build_global().unwrap() mirrors the exact structure of the provided code template and thus most strongly supports the fine-grained field value. The adjacent excerpt demonstrates the same builder pattern in a slightly broader context (setting num_threads and constructing/building the pool), which is highly relevant as it reinforces the templates core idea of configuring thread count. Other excerpts reiterate the concept that ThreadPoolBuilder is used to create or configure the global pool and provide the general mechanism, which supports the field value but with less precision about the exact stack_size and error handling usage. Excerpts discussing related topics like max_num_threads offer contextual limits rather than the exact construction flow, so they are less directly supportive. Excerpts describing ThreadPoolBuilder in related modules or wasm variants corroborate the approach of using a builder to configure pools, further validating the notion of configuration-based tuning in the same vein.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "let hdd_pool = rayon::ThreadPoolBuilder::new().num_threads(1).build().unwrap();\nlet ssd_pool = rayon::ThreadPoolBuilder::new().num_threads(16).build().unwrap(); "
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();"
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value identifies a specific idiomatic pattern name: using ThreadPoolBuilder as a global configuration knob for Rayon. The most relevant excerpts explicitly describe ThreadPoolBuilder as a tool to create a new thread pool or configure the global thread pool, aligning directly with the notion of a global configuration pattern. For example, excerpts state that ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool, and that it enables configuring the global pool (build_global). Other excerpts reinforce this focus by showing examples of calling ThreadPoolBuilder::new().num_threads(...) and by discussing its role in global configuration, which directly maps to the idea of a global configuration pattern in the Rayon ecosystem. Additional excerpts mention related capabilities (such as maximum thread counts or nested/thread-pool discussions) that are adjacent to global configuration, and while they provide useful context, they are slightly less direct than the explicit statements about ThreadPoolBuilder enabling global configuration. The strongest support comes from explicit statements that ThreadPoolBuilder either creates a pool or configures the global pool, including notes about build_global, which precisely matches the described pattern name for the target field value.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.1.pattern_name",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        }
      ],
      "reasoning": "The most directly relevant content identifies a fallible aggregation pattern: an operation that applies a function (op) that can fail while reducing items in a parallel iterator. The excerpt describing a method that reduces items using a fallible operation and returns None or Some depending on the presence of errors directly supports the idea of a fallible aggregation pattern. The accompanying explanation that this behaves like an alternative to a non-fallible reduce and that the return value can reflect an empty iterator or an error condition provides concrete alignment with the requested idiomatic pattern for fallible error handling during aggregation. The next most relevant excerpt mentions executing a fallible operation on a value produced by an initializer, which reinforces the concept of a fallible step within a pipeline that aggregates results. It directly connects to the notion of fallibility within a folding-like operation and thus supports the field value. The following excerpts discuss the TryFold surface area and a header that exposes related fallible reduction methods, which adds corroborating context about the API surface that embodies fallible aggregation. While these sections are not as explicit about the exact error-handling semantics as the most relevant excerpt, they still substantiate the idiomatic use of fallible patterns in the parallel-iterator ecosystem. Overall, the field value \"try_fold with try_reduce for Fallible Aggregation\" is best supported by explicit mentions of fallible ops during reduction and aggregation, with additional corroboration from related API descriptions for TryFold and related methods.",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.0.code_template",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The code template shows a parallel iterator over a range, applying a map to square each element, and then summing the results. The most directly relevant excerpt is the one that explains summing items produced by a ParallelIterator and notes that the operation is equivalent to a reduction that adds elements, with the caveat about determinism depending on the operator and data type. This directly aligns with the code pattern of mapping to i*i and then calling sum on the parallel iterator. The same excerpt also contrasts the sum approach with a general reduce pattern (which may or may not specify an identity element) and mentions that the order of reduction is not guaranteed for non-commutative or non-associative operations, which is contextual background for parallel sums. The other excerpts describe related reduction patterns such as reduce_with, try_reduce, try_reduce_with, and fold_with. These are relevant as alternative aggregation strategies in the same API family and help explain different ways to aggregate a collection in parallel, including how to supply an operator, handle empty iterators, and manage potential errors or None values. Collectively, these excerpts support the understanding that a map followed by sum is a straightforward aggregation pattern within Rayons parallel iteration framework, and that other reduction forms exist for more complex or fallible aggregations.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.0.usage_context",
      "citations": [
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let...",
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "rayon_core_wasm - Rust - Docs.rs",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/",
          "excerpts": [
            "ThreadPool can be used to create your own thread pools (using ThreadPoolBuilder ) or to customize the global one. Tasks spawned within the pool (using install() ..."
          ]
        },
        {
          "title": "Configuration in rayon_core_wasm - Rust",
          "url": "https://docs.rs/rayon-core-wasm/latest/rayon_core_wasm/struct.Configuration.html",
          "excerpts": [
            "Contains the rayon thread pool configuration. Use `ThreadPoolBuilder` instead ... Deprecated in favor of ThreadPoolBuilder::stack_size . Source. pub fn..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        }
      ],
      "reasoning": "The strongest support comes from sources that explicitly describe using a ThreadPoolBuilder to configure the global rayon thread pool, which aligns with the field values emphasis on configuring the global pool for the entire application. The documentation notes that ThreadPoolBuilder can be used to create a new ThreadPool or configure the global pool, which directly maps to the idea of a startup-time, global customization to tailor hardware and workload. Additional sources explain that ThreadPool can be used to manage pools and that the global pool can be customized, reinforcing the concept of a centralized, startup-time configuration. Other entries describe what ThreadPoolBuilder can configure (e.g., number of threads, names) and mention the existence of a global pool versus user-created pools, further supporting the notion of a centralized, globally applied optimization pattern. The max_num_threads entry adds context about thread limits that are relevant to global configuration, though it does not itself describe startup behavior. Taken together, these excerpts support the core idea of a startup-time, global configuration pattern using ThreadPoolBuilder to optimize efficiency and resource usage, while also acknowledging the distinction between global and local pools.",
      "confidence": "medium"
    },
    {
      "field": "order_and_indexing_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "<Self>\n\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.\nThis means that if two threads are used there will be **no** speedup **at\nall** . `by_exponential_blocks` on the other hand will start with the leftmost range from 0\nto `p` (threads number), continue with p to 3p, the 3p to 7p\n\nEach subrange is treated in parallel, while all subranges are treated sequentially. We therefore ensure a logarithmic number of blocks (and overhead) while guaranteeing\nwe stop at the first block containing the searched data. [Source](../../src/rayon/iter/mod.rs.html)\n",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "Searches for items in the parallel iterator that match the given\npredicate, and returns their indices.",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```"
          ]
        }
      ],
      "reasoning": "The targeted fine-grained field value describes an idiomatic pattern for using the find_first operation with a specific optimization: applying the by_exponential_blocks adaptor to bias the search toward the beginning of the iterator, and it also mentions alternative patterns for finding all matches (such as using filter().collect() or positions() on IndexedParallelIterator). The most directly supporting content explicitly states using by_exponential_blocks with find_first and notes that this approach helps in scenarios where performance is a concern, along with an example demonstrating the find_first usage. This directly aligns with the requested pattern of selecting an efficient first-match strategy and provides concrete guidance for both the targeted first-match case and alternatives for multiple matches. Additional excerpts describe the general behavior of find_first (searching for the first item) and contrasts with other find/search variants, which helps confirm the core concept of locating the first match and the existence of alternative strategies. A remaining excerpt confirms the existence of other related patterns (such as last-match variants) to help contextualize the recommended approach, though it is less central to the specified first-match optimization. Taken together, these excerpts establish that: (a) by_exponential_blocks can optimize first-match searches, (b) find_first is the intended method for the earliest qualifying element, and (c) there are alternate patterns for gathering all matches.",
      "confidence": "high"
    },
    {
      "field": "map_reduce_aggregation_patterns.2.usage_context",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The most relevant excerpt directly describes a fold-like operation that takes an initial accumulator (init) and applies a fold operation to each item, producing a value suitable for subsequent use. It explicitly frames the operation as something that applies a fold function to an initial value and items, and it notes that the init may not require synchronization, which aligns with the idea of per-thread or local accumulators and reduced merging without heavy synchronization. This supports the core aspects of the fine-grained field value: an accumulator fed through fold, potential separation of accumulator type from items, and avoidance of shared-state locking during parallel aggregation.\n\nThe next-highly-relevant excerpts describe more general reduce/try_reduce patterns where an operation combines elements into a single result, with notes about identity elements and fallible operations. These reinforce the concept of aggregating across items in a parallel iterator, and they imply the existence of an aggregation pipeline that culminates in a single value, which is consistent with the per-thread local accumulator approach that is then merged.\n\nAdditional excerpts present the general sum/reduce APIs and examples, further illustrating how items are aggregated, sometimes with non-deterministic order or with potential overflow considerations. While these excerpts may be slightly more generic, they still underpin the broader mechanism of parallel aggregation and the concept of combining per-item contributions into a final result without requiring explicit intermediate synchronization.\n\nOverall, the set of excerpts collectively supports the idea of a parallel aggregation pattern where (a) there is an initial accumulator (the fold/join seed), (b) an operation combines items into that accumulator, (c) the approach avoids heavy synchronization, and (d) the process yields a final aggregated value, which matches the described field value about using per-thread local accumulators and merging them for efficiency.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.2.pattern_name",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        }
      ],
      "reasoning": "The most relevant content directly demonstrates fallible operations in parallel iterators and how errors propagate or are handled during aggregation. The first excerpt explains reducing items with a fallible operation and shows the possible outcomes when errors occur (None or Some variants) and the interaction with empty iterators. This directly ties to collecting results with error handling, as it makes explicit how errors influence the final outcome and the structure of the result. The second excerpt similarly discusses a function that processes items with a fallible operation and returns an Option, illustrating the pattern of collecting results with error signaling through an optional type. The third excerpt describes executing a fallible operation on each value produced by an initializer, which is a core mechanism for building up a result while accounting for possible errors. The fourth excerpt presents the signature and context of a fallible fold-like construct, reinforcing how errors are integrated into parallel accumulation workflows. Taken together, these excerpts collectively illustrate the idiom of collecting and propagating results (and possible errors) when performing parallel reductions/ folds, which aligns with the notion of assembling results for comprehensive error reporting across a parallel workflow.",
      "confidence": "medium"
    },
    {
      "field": "parallel_sorting_patterns.2.anti_patterns",
      "citations": [
        {
          "title": "mod.rs - rayon/slice",
          "url": "https://docs.rs/rayon/latest/src/rayon/slice/mod.rs.html",
          "excerpts": [
            "/// Sorts the slice in parallel with a key extraction function, but might not preserve the order",
            "/// Sorts the slice in parallel, but might not preserve the order of equal elements. 587    ///\n588    /// This sort is unstable (i.e., may reorder equal elements), in-place\n589    /// (i.e., does not allocate), and *O*(*n* \\* log(*n*)) worst",
            "/// Sorts the slice in parallel with a comparator function. 387    ///\n388    /// This sort is stable (i.e., does not reorder equal elements) and *O*(*n* \\* log(*n*)) worst-ca",
            "9    /// of equal elements.",
            "fn par_sort( &mut self )\n380    where\n381        T: Ord,\n382    {\n383        par_mergesort( self .as_parallel_slice_mut(), T"
          ]
        }
      ],
      "reasoning": "The targeted field value concerns the anti-pattern of using a parallel sort by key when the key function is expensive, which can cause redundant work during comparisons. One excerpt explicitly mentions sorting a slice in parallel with a key extraction function, noting that the operation can affect ordering. This directly relates to the idea of computing a key during sorting in parallel, which is precisely the context where an expensive key function could lead to inefficiency. Another excerpt discusses sorting in parallel with a comparator function, which broadens the context to parallel sorts that rely on element comparisons rather than precomputed keys, highlighting the performance considerations of parallel sorting itself. Taken together, these excerpts illuminate the parallel sorting mechanisms (key-based and comparator-based) and the potential performance implications when keys are expensive to compute, thereby supporting the notion of an anti-pattern around expensive key functions in a parallel sort. The remaining excerpts touch on the behavior of parallel sorts (e.g., instability, possible non-preservation of order) and the existence of specific sort functions (par_sort) but do not directly address the key-based optimization issue, providing context without strongly contradicting the anti-pattern claim.",
      "confidence": "medium"
    },
    {
      "field": "map_reduce_aggregation_patterns.2.pattern_name",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "ach) .\n ... \n### `fn [try_reduce](.try_reduce) <T, OP, ID>(self, identity: ID, op: OP) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . The `identity` argument is used the same way as in [`reduce()`](.reduce) . If a `Result::Err` or `Option::None` item is found, or if `op` reduces\nto one, we will attempt to stop processing the rest of the items in the\niterator as soon as possible, and we will return that terminating value.\nOtherwise, we will return the final reduced `Result::Ok(T)` or `Option::Some(T)` . If there are multiple errors in parallel, it is not\nspecified which will be returned. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n // Compute the sum of squares, being careful about overflow. fn sum_squares < I : IntoParallelIterator < Item = i32 > > ( iter : I ) - > Option < i32 > {\n    iter . into_par_iter ()\n        . map ( | i | i . checked_mul ( i ))            // square each item, \n        . try_reduce ( | | 0 , i32::checked_add )   // and add them up! \n} assert_eq! ( sum_squares ( 0 .. 5 ), Some ( 0 + 1 + 4 + 9 + 16 ));\n\n // The sum might overflow \n assert_eq! ( sum_squares ( 0 .. 10_000 ), None );\n\n // Or the squares might overflow before it even reaches `try_reduce` \n assert_eq!\n( sum_squares ( 1_000_000 .. 1_000_001 ), None );\n```",
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` .",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The most relevant content explicitly discusses a reduction operator that follows a folding operation, namely a reduce_with pattern that reduces items produced by the iterator using a binary operator. This directly aligns with the idea of combining a fold phase with a reduction phase in an idiomatic pattern. Closely related posts describe a general fold operation that applies a folding function to each item, accumulating an intermediate result, which is the natural precursor to a subsequent reduction step in idiomatic Rust Rayon code. Additional passages cover alternative reduction patterns such as try_reduce and try_reduce_with, which extend the folding-reduction concept to fallible operations, reinforcing the broader idiomatic approach of composing folding with reduction. There are also examples and descriptions showing a simple fold-like accumulation (fold_with) that is compatible with downstream reduction semantics, emphasizing how these operations can be composed in parallel iterator pipelines. The combination of folding (accumulation) and reduction (combining into a single result) is thus illustrated across multiple excerpts, supporting the notion of an idiomatic pattern where fold and reduce are used in conjunction to obtain efficient, low-bug code. The presence of a dedicated sum example further corroborates how reduction-like behavior is commonly expressed after an accumulation step, even though it focuses on summation rather than a generic reduction operation. Overall, the content demonstrates both direct and adjacent coverage of fold and reduce in Rust Rayon, aligning well with the requested pattern behavior and providing concrete references for constructing the pattern in code.",
      "confidence": "high"
    },
    {
      "field": "parallel_collection_building_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        }
      ],
      "reasoning": "The target field value describes an anti-pattern where manually locking and extending a shared collection from multiple threads is inefficient, recommending par_extend as the high-level, efficient solution. The first excerpt discusses the ParExtend-capable method par_extend and provides the function signature, illustrating an idiomatic, safe way to extend a hash map in parallel rather than manually coordinating concurrent updates. The second excerpt explains the Rayon librarys core idea: turning sequential iterators into parallel ones with par_iter and delegating the rest to Rayon, which supports the notion of replacing manual parallel extension with higher-level parallel abstractions like par_extend. Taken together, these excerpts directly support the idea that manual locking and ad-hoc parallel extension is discouraged and that par_extend is the appropriate, efficient alternative, thereby aligning with the described anti-pattern and its remedy.",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.0.usage_context",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes executing a fallible operation across items in parallel, aborting on the first failure, with emphasis on efficiency and early error signaling to reduce wasted work. The most relevant excerpts directly discuss the fallible operation over items and how a fallible operation is applied in a parallel iterator context. The description of a function that reduces items using a fallible operation explicitly ties the concept of an error-aware or fallible fold/reduction to the parallel iterator, including behavior semantics such as returning Some/None depending on the iterators state and handling of early termination. This directly supports the idea of executing a fallible op for side effects with an emphasis on efficiency and early error signaling. Related excerpts describe the generic idea of executing a fallible operation on each item in parallel, and the existence of try-fold/try-reduce-with APIs that embody this pattern. While additional excerpts also mention the fallible fold/reduce concept, they provide supportive but slightly less direct statements about the same pattern, reinforcing the core idea without adding conflicting interpretations. Therefore, the excerpts with explicit reference to try_fold and try_reduce_with, and the description of reducing items with a fallible operation, are most relevant. Together they substantiate the field value's claim about efficiency, early error signaling, and fallible item-wise processing in parallel contexts.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.2.usage_context",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The most directly relevant content states that a fallible operation is executed on each item produced by an initializer, which aligns with the idea of applying a fallible operation across all items and aggregating results. It describes applying a fallible operator to each item, which directly supports the notion of per-item processing that can produce a report of successes and failures in a batch task. The next closely related content explains reducing items with a fallible operator, including behavior when items are missing (None) and how Err/None are handled, which supports understanding how failures can be tracked in a batch or map-reduce style operation without short-circuiting on the first failure. A closely related excerpt elaborates the presence of a try_reduce_with function that uses a fallible operator to combine items into a single result, again reinforcing the concept of aggregating outcomes of per-item fallible operations rather than stopping early. The remaining excerpt mentions try_fold in the same family of fallible, non-strict folding operations, which corroborates the broader pattern of fallible per-item processing and aggregation, though it provides less direct detail about reporting all successes and failures. In sum, the collection of excerpts collectively supports the notion of using fallible per-item operations with aggregation in a parallel iteration context, aligning with the requested field value about batch validation/parsing and non-short-circuit behavior.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.2.code_template",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The code template shows applying a function that returns a Result to each element in parallel and collecting the results, which aligns with the excerpt that states an operation is executed as a fallible OP on a value returned by init for each item. This directly mirrors the idea of mapping over data in a parallel iterator with a function that can fail, producing a Vec<Result<_, _>>. The surrounding excerpts describe how reduction behaves when the operation can fail, such as a fallible reduction where the operator returns Ok or Err, and the iterators items are transformed with possible errors. They also explain that certain parallel reduction helpers (like a TryReduce version) handle the possibility of an error or a None outcome, which matches the concept of a fallible operation within a Rayon pipeline. Finally, an excerpt illustrating a similar fallible pattern for folding (try_fold) reinforces the same theme of propagating errors during parallel accumulation. Taken together, these excerpts coherently support the field value by describing explicit fallible operations in Rayons parallel iteration and how their results are handled and collected.",
      "confidence": "high"
    },
    {
      "field": "parallel_collection_building_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "rayon::iter::ParallelExtend - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelExtend.html",
          "excerpts": [
            "Extends a hash map with items from a parallel iterator. [+] Show hidden undocumented items. fn par_extend<I>(&mut self, par_iter: I) where"
          ]
        },
        {
          "title": "README.md - Rayon (rayon-rs/rayon)",
          "url": "https://github.com/rayon-rs/rayon/blob/master/README.md",
          "excerpts": [
            "Rayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:"
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explicitly discusses a direct, parallel extension operation: it states that par_extend<I>(&mut self, par_iter: I) is a function that extends a collection with items from a parallel iterator and highlights its direct, optimized nature as a single operation. This directly supports the field value's claim that using par_extend can be more direct and potentially more efficient than assembling items in a temporary collection and then inserting them. The second excerpt provides context on how Rayon simplifies converting sequential iterators to parallel ones by enabling par_iter() in place of a normal iterator, which reinforces the surrounding practice of parallel collection-building and explains the practical workflow that would precede or accompany a par_extend call. Together, these excerpts connect the described alternative pattern (collect into a temporary collection and then extend) with the established direct pattern (par_extend) and show why the latter is often preferred for straightforward parallel extension. Specifically, the first excerpt demonstrates the direct, optimized parallel extension operation, and the second excerpt clarifies how parallel iteration is typically initiated in Rayon, which underpins the use of par_extend in idiomatic code.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.2.anti_patterns",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt describes executing a fallible operation on each value, which directly relates to the concept of having a fallible OP and how it operates within the iterator; this supports understanding how early-exit logic is applied per item and the semantics of a fallible workflow. The next relevant excerpt explains a specific method (try_reduce_with) that reduces items using a fallible operation and notes behavior when the iterator is empty or when results indicate failure, which aligns with the idea of short-circuiting on errors and the notion of not necessarily guaranteeing immediate cross-thread cancellation. Following this, the excerpt that documents TryFold in rayon::iter is relevant because it covers the same domain of fold-like operations with fallibility, reinforcing how try-fold-like constructs handle errors and identity values. The least directly relevant excerpt provides additional structure and a signature around a try_fold operation, which complements the understanding of how fallible patterns are wired but adds less direct evidence about the anti-pattern in the given context. Together, these excerpts collectively support the interpretation that using these fallible patterns when early exit is desired can be suboptimal if strong, cross-thread cancellation semantics are required, which corresponds to the anti-pattern described by the field value.",
      "confidence": "high"
    },
    {
      "field": "configuration_and_tuning_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "How can I change the number of threads Rayon uses? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/59205184/how-can-i-change-the-number-of-threads-rayon-uses",
          "excerpts": [
            "If you want to alter the number of threads spawned, you can set the environmental variable `RAYON_NUM_THREADS` to the desired number of threads or use the [`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html.build_global) method.",
            "Just include in fn main(). The num\\_threads accepts the number of threads. `rayon::ThreadPoolBuilder::new().num_threads(4).build_global().unwrap();",
            "By default, Rayon uses the same number of threads as the number of CPUs available."
          ]
        },
        {
          "title": "ThreadPoolBuilder - Rayon docs (docs.rs/rayon)",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "ThreadPoolBuilder is used to create a new ThreadPool or configure the global rayon thread pool. It returns a valid builder, but does not initialize it.",
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "ThreadPoolBuilder in rayon - Rust - Shadow",
          "url": "https://shadow.github.io/docs/rust/rayon/struct.ThreadPoolBuilder.html",
          "excerpts": [
            "Used to create a new ThreadPool or to configure the global rayon thread pool. Creating a ThreadPool. The following creates a thread pool with 22 threads. i let..."
          ]
        },
        {
          "title": "Docs.rs Rayon: max_num_threads",
          "url": "https://docs.rs/rayon/latest/rayon/fn.max_num_threads.html",
          "excerpts": [
            "Returns the maximum number of threads that Rayon supports in a\nsingle thread pool. If a higher thread count is requested by calling `ThreadPoolBuilder::num_threads` or by setting\nthe `RAYON_NUM_THREADS` environment variable, then it will be reduced to this maximum. The value may vary between different targets, and is subject to change in new Rayon versions."
          ]
        },
        {
          "title": "rayon::ThreadPool - Rust",
          "url": "https://slide-rs.github.io/specs-website/docs/docs/0.9/rayon/struct.ThreadPool.html",
          "excerpts": [
            "The ThreadPool struct represents a user created thread-pool. ThreadPool::new() takes a Configuration struct that you can use to specify the number and/or names ..."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://doc.servo.org/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "ThreadPool in rayon - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/struct.ThreadPool.html",
          "excerpts": [
            "Represents a user-created thread pool. Use a ThreadPoolBuilder to specify the number and/or names of threads in the pool."
          ]
        },
        {
          "title": "Rayon: Multiple Thread Pools and Scope Patterns",
          "url": "https://pkolaczk.github.io/multiple-threadpools-rust/",
          "excerpts": [
            "Multiple Thread Pools"
          ]
        }
      ],
      "reasoning": "The most directly relevant content discusses how to adjust the number of threads and how to apply ThreadPoolBuilder and build_global, which are core to configuring the pool and potential anti-patterns in misconfiguring threads. Specifically, guidance showing how to change thread counts and invoking build_global points to the practical risks and patterns around configuration. One excerpt notes that a builder is valid but not initialized, which highlights a nuance in the initialization flow that can lead to misconfiguration if misused. Other excerpts explain that the number of threads can be changed via environment variables or through ThreadPoolBuilder, which is highly relevant to anti-patterns involving over- or under-provisioning threads and potential performance degradation due to incorrect sizing. Additionally, information about the maximum number of threads provides boundary expectations that can influence when a configuration is suboptimal. Collectively, these excerpts support the notion that incorrect or repeated configuration calls (like build_global) can cause errors or degraded performance, even if the explicit statement about calling build_global multiple times as an anti-pattern is not verbatim present in any single excerpt.",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.1.code_template",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The code template demonstrates a fallible accumulation pattern by using a fallible operator inside a parallel iterator's fold-like operation, followed by an optional result in the final reduce step. The first relevant excerpt presents the signature and context of a TryFold in rayon, which aligns with the use of a try_fold-style operation on a parallel iterator. The second excerpt explicitly states that the operation executes a fallible operator on each value, which directly supports the idea of handling potential errors during accumulation. The third excerpt introduces and explains a try_reduce_with pattern, describing how reductions can occur with a fallible operation and how the result becomes an Option depending on emptiness and error handling, matching the overall flow of try_fold followed by a fallible reduction. The fourth excerpt reiterates the availability of a try_reduce_with API, reinforcing the presence of a cohesive fallible pattern in this API surface. Collectively, these excerpts corroborate the presence of idiomatic fallible/error-handling templates in the code sample, including the use of try_fold with a fallible closure, and the subsequent try_reduce_with behavior that yields an Option when errors or emptiness occur, consistent with the provided code snippet and its assertion using Some for a successful computation.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns.1.code_template",
      "citations": [
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        },
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "The finegrained field value demonstrates replacing a mutex-based shared counter with an atomic counter wrapped in Arc for parallel reduction with Rayon. Excerpts describing the use of atomics as an alternative to locks directly support this approach, including notes that an atomic can be faster for simple increments and that there are playground/test cases showing atomic usage. Additional excerpts discuss the limitations of atomics for more complex updates and the performance implications of locking, which provides context that atomics are a suitable pattern for simple cases like a shared counter but may not fit more complicated state updates. Other excerpts highlight that per-thread locks can kill parallelism and that contention on Arc<Mutex<T>> is a known pitfall, reinforcing why the atomic pattern is used in the provided template. Together, these excerpts corroborate the field values emphasis on using atomics for simple, high-performance shared counters in a parallel setting and discuss the trade-offs with mutex-based approaches and contention.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.0.code_template",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        }
      ],
      "reasoning": "The target field value shows a pattern for handling fallible operations in a Rayon iterator, specifically focusing on error handling within parallel reductions and fallible steps. Excerpts that document try_reduce_with and the behavior of reducing a sequence with a fallible operator provide direct evidence of idiomatic fallible patterns in Rayon (e.g., the pattern reduces items using an operation that can fail, returning an Option or a similar fallible result). The description of a function that reduces with a fallible operator and the explanation that, in the presence of empty iterators or failure, the behavior resembles returning None or a similar fallible outcome, directly aligns with the concept of fallible/error-handling patterns in the code template. Additional excerpts that discuss the TryFold construct, and that there are try variants of fold/reduce APIs in Rayon, reinforce the notion that idiomatic error-aware patterns exist for iterators in Rayon, which is precisely what the provided code template demonstrates by wiring an operation that may fail (or stop) during iteration and then handling the outcome (in this case via an expect on the write operation). The combination of these excerpts supports the notion that fallible/error-aware patterns (like TryFold, try_reduce_with) are idiomatic in Rayon and can lead to safer or more robust parallel code, which is the essence of the requested code-template-focused pattern analysis.",
      "confidence": "medium"
    },
    {
      "field": "state_management_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "The anti-pattern described centers on using a single shared data structure protected by a lock (such as Arc<Mutex<HashMap<...>>>) and having each thread acquire the lock for every item, which serializes execution and erodes or eliminates parallelism. This is explicitly illustrated by discussions about acquiring a per-thread mutex killing parallelism, including notes that removing the lock restores parallel execution and that locking can cause contention and slowdown. Additionally, discussions about Arc<Mutex<T>> spam and its downsides provide supporting context that such locking strategies are problematic for performance in parallel workloads. Taken together, these excerpts directly address the anti-pattern of guarding extensive work with a heavy coarse-grained lock across threads, which matches the described anti-pattern in the fine-grained field value.",
      "confidence": "medium"
    },
    {
      "field": "state_management_patterns.1.pattern_name",
      "citations": [
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        }
      ],
      "reasoning": "The most directly relevant information comes from discussions about per-thread mutex usage and its impact on parallelism. The excerpts describe acquiring a per-thread mutex in a rayon setting, showing how locking can affect parallelism and how removing or replacing lock calls with alternatives (like try_lock) changes behavior. This directly connects to the Arc<Mutex<T>> pattern in Rust, which revolves around wrapping data in a Mutex behind an Arc to share state across threads, including potential performance pitfalls when contention occurs. The excerpts also touch on the broader critique of Arc<Mutex<T>> as a pattern, including statements that a Mutex can become a contention point and that alternative synchronization primitives may be preferable in multi-threaded contexts. Together, these pieces map to the idea of Arc<Mutex<T>> as a pattern and the considerations around its usage (contention, correctness, and when to prefer atomics or other strategies).\nAdditionally, several excerpts explicitly discuss atomics as an alternative for performance-sensitive scenarios where per-task or per-thread data is involved. These references help illustrate the trade-offs between using atomic primitives versus locking, which is central to choosing between Arc<Mutex<T>> and atomic patterns. Finally, there are excerpts that discuss broader opinions about Arc<Mutex<T>> spam and its drawbacks, reinforcing the association between the pattern and performance concerns, while still acknowledging when such a pattern might be considered in practice.\n",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.0.anti_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explicitly describes a fallible operation and how the reduction handles errors: it explains reducing items with a fallible operation and that the result is None if the iterator is empty, otherwise Some of the reduced value, and it discusses propagating Err/None semantics in a way that mirrors controlled error handling rather than panicking. This directly aligns with the fields emphasis on avoiding panics for recoverable errors and using structured propagation mechanisms. The next two excerpts, which document specific TryFold/TryReduce helpers and their signatures, provide substantive context about how automatic error propagation is modeled in these APIs (e.g., fallible operations, propagation of None/Some/Ok, and the connection to Op that can fail). They illustrate the pattern of handling failures within iterator reductions in a controlled way, reinforcing the notion that panicking is not the intended approach for recoverable errors. The least directly relevant excerpt repeats the theme of a try-fold API surface and includes function references, which are API details but still support understanding of how errors are managed in these patterns, albeit with less explicit discussion of error propagation semantics.",
      "confidence": "medium"
    },
    {
      "field": "state_management_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "In a Rayon context, acquiring a per-thread mutex can kill parallelism, as one excerpt explicitly states that creating a rayon threadpool with per-thread data behind mutexes processes data in chunks but ultimately harms parallel execution unless the lock is removed. The observation that removing the lock restores parallelism reinforces the idea that lock contention is a core anti-pattern in hot loops. Additionally, an alternative approach is suggested by noting atomics as a possible option in certain scenarios, highlighting that relying on mutexes can be inappropriate for performance reasons, especially when contention and serialization risks are high. The discussion also acknowledges that mutexes are a known contention point and that coarser locking can serialize work, both of which align with the anti-patterns described in the finegrained field. Taken together, the content supports the notion that locking inside hot loops (or holding locks for long durations) and relying on shared-state order are detrimental in a parallel runtime like Rayon, and that more granular or lock-free strategies (e.g., atomics) or finer-grained isolation are preferable. The excerpts collectively map to the specific anti-patterns described (per-element locking in hot loops, long-held locks, and non-deterministic effects due to non-deterministic scheduling), illustrating why these patterns degrade performance and correctness in parallel code.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.1.usage_context",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The field value outlines a pattern where a fallible operation is performed during per-item accumulation within each worker (thread) chunk, with short-circuiting confined to that local chunk, followed by a combination step (try_reduce) that merges intermediate results to enable global short-circuiting. The most direct support comes from the excerpt that presents the signature and name of the TryFold path, which anchors the concept of a per-item, panicking-safe accumulation workflow in the parallel iterator. It signals the API surface used for the per-item accumulation phase in a parallel reduction. The next piece of evidence describes executing a fallible operation on each item as it is processed, which matches the per-item, fallible-OP aspect of the pattern and confirms the existence of a local, per-item computation step. The following excerpt introduces a related reduction pattern using a fallible op and discusses how the result may be None or Some depending on the iterators state, illustrating the error-handling/short-circuit semantics that underpin the broader idiom. Finally, the excerpt that explicitly ties these ideas together by mentioning combining with a try_reduce-like mechanism to achieve global short-circuiting reinforces the overall idiomatic pattern described in the field value. Taken together, these excerpts directly map to the described flow: per-item fallible work during accumulation, local short-circuiting within a thread, and a subsequent cross-thread reduction step to enable global short-circuiting and correctness.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns.1.usage_context",
      "citations": [
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem.",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)"
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "The most directly relevant content notes that acquiring a per-thread mutex in a rayon setup can kill parallelism, and that removing the lock restores parallel execution, illustrating a practical pitfall of mutex-heavy designs in parallel contexts. This directly supports the idea that shared mutable state via mutexes should be avoided or used cautiously in parallel workloads when contention hurts performance. In addition, explicit statements about contention being a problem with Mutex (every Mutex is a point of contention) reinforce the performance penalties of locked shared state in multi-threaded execution. Further, there is nuanced discussion about atomics being suitable for simple primitive types and the limitations of atomics for more complex data structures, which aligns with recommending Atomics for simple counters and contrasting with Arc<Mutex<T>> in more complex scenarios. Finally, the notes on mutexes not being suitable for more complicated updates, and the need for locking mechanisms in certain complex cases, provide a balanced view showing when Arc<Mutex<T>> or Arc<RwLock<T>> might be necessary, thus supporting the stated value that this pattern should be used only when unavoidable and when simpler patterns like atomics do not apply. Together, these points map directly to the evaluation of a usage_context that weighs the trade-offs between locks, atomics, and more complex synchronized structures in a parallel Rust environment.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.1.anti_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item"
          ]
        }
      ],
      "reasoning": "The strongest support comes from descriptions of try_reduce_with and its behavior in the context of a fallible operation. It explains that a fallible operation can be reduced across items, and that the return value is optional (None to indicate emptiness or an error path) and that the mechanism handles Err/None distinctly, reducing the risk of propagating partial or incorrect results. This directly supports the finegrained field value, which argues that ignoring potential overflow and relying on a sentinel value is error-prone, and that using try_reduce with Result or Option helps prevent leaking partial results. Additional confirmation comes from explicit references to try_reduce_with returning an Option of the item type and delineating behavior when the iterator is empty, which aligns with the goal of safer error handling in fallible reductions. The related material discussing TryFold and fallible operations reinforces the same pattern: using try_fold/try_reduce variants to handle errors explicitly rather than relying on standard fold/reduce with sentinel checks. The excerpts discussing the TryFold API show that there exist specialized fallible variants for iterators, underscoring the idiomatic approach of using these APIs to avoid the anti-pattern described (ignoring overflow or errors). Together, these excerpts collectively support the claim that the idiomatic pattern to avoid is ignoring potential errors and instead utilizing try_* variants to manage errors safely in parallel reductions in Rust/Rayon.",
      "confidence": "high"
    },
    {
      "field": "fallible_and_error_handling_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a pattern where, for non-critical errors, one maps operations to Result types and then collects them into a collection of results, enabling post-processing of successes and failures but sacrificing early cancellation. The excerpts collectively illustrate concrete Rust parallel-iteration idioms for handling errors. They show that a fallible computation can be modeled with a fallible fold operation on each item, and that reduction patterns exist which propagate or combine errors (for example, a reduce_with variant that operates with a fallible operation and yields an optional result depending on emptiness and error propagation). These excerpts demonstrate the practical mechanisms in Rayon for embedding error-aware logic into parallel iterators, which directly informs the recommended alternate patterns and their trade-offs between early abortion and post-hoc aggregation. The excerpts also provide concrete function and trait signatures that reveal how error propagation is expressed in code, which supports mapping to Result and collection strategies described in the field value.",
      "confidence": "medium"
    },
    {
      "field": "state_management_patterns.0.usage_context",
      "citations": [
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        },
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "You can combine `fold` with `reduce` if you want to produce a\nsingle value. This is then roughly equivalent to a map/reduce\ncombination in effect:",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The field value advocates an idiomatic approach where each parallel thread maintains its own local accumulator to avoid locking in the hot path, followed by a merge step to produce the final result. Excerpts that discuss per-thread storage patterns and custom reductions explicitly address this idea of local per-thread state and later reductions to a single result, which aligns with the described pattern. The discussion about per-thread mutex usage and its impact on parallelism provides direct evidence that locking in workers is detrimental and that avoiding locks is a recognized idiom for achieving high scalability. Notes that atomics can be considered but are often not suitable for performance reasons, reinforce the notion that per-thread accumulators (state kept per thread) are the preferred pattern to reduce contention. Descriptions contrasting fold/reduce semantics with the benefits of parallel reduction (and the caution about nondeterministic ordering without strict associativity) further support how a per-thread local state can be merged efficiently in the final step. Collectively, these excerpts support the idea that the recommended idiomatic pattern in Rayon for aggregation tasks is to use per-thread local state (local accumulators) and a lock-free final merge, which leads to high efficiency and fewer bugs due to deadlocks and contention.",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.2.alternate_patterns",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        },
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>"
          ]
        }
      ],
      "reasoning": "The field value discusses primary alternates for fallible/error-handling patterns, including try_for_each or try_reduce, and using fold/reduce to manage partial successes/failures. The excerpts provide concrete examples of fallible patterns in Rayon: an API that reduces items using a fallible operation via try_reduce_with, which yields an optional result and propagates errors; documentation for TryFold that describes executing a fallible operation across items; and general explanation that these fallible patterns exist alongside the non-fallible counterparts. Specifically, one excerpt explains how try_reduce_with reduces items into one item using a fallible operation, returning None on empty iterators and Some on success, with behavior aligned to handling Err/None cases; another excerpt introduces a TryFold construct and shows a TryFold-related method that accepts an identity and a fold operation, denoting a fallible folding process across parallel items; another excerpt explicitly situates try_reduce_with in the context of fallible reductions, detailing its return types and how success/failure is propagated; a further excerpt notes that a function in this API is executed in a fallible way over values produced by an init function. Collectively, these excerpts directly support the field values assertion that fallible/error-handling patterns in Rayon include alternate approaches such as try_reduce_with, TryFold, and related fallible folding/reducing operations, which can serve as alternates to non-fallible patterns. The excerpts do not merely mention abstract concepts; they provide concrete signatures and behavior that illustrate how fallible patterns operate and what they return, reinforcing the idea of multiple viable idiomatic fallible patterns for error handling within parallel iterators.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns.0.pattern_name",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "You can combine `fold` with `reduce` if you want to produce a\nsingle value. This is then roughly equivalent to a map/reduce\ncombination in effect:",
            " );\n```\n\n### `fn [fold](.fold) <T, ID, F>(self, identity: ID, fold_op: F) -> [Fold](struct.Fold.html \"struct rayon::iter::Fold\") <Self, ID, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nParallel fold is similar to sequential fold except that the\nsequence of items may be subdivided before it is\nfolded. Consider a list of numbers like `22 3 77 89 46` . If\nyou used sequential fold to add them ( `fold(0, |a,b| a+b)` ,\nyou would wind up first adding 0 + 22, then 22 + 3, then 25 +\n77, and so forth.\nThe **parallel fold** works similarly except\nthat it first breaks up your list into sublists, and hence\ninstead of yielding up a single sum at the end, it yields up\nmultiple sums. The number of results is nondeterministic, as\nis the point where the breaks occur.",
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity.",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity.",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()"
          ]
        }
      ],
      "reasoning": "The most directly supportive information notes that you can combine fold with reduce to produce a single value, which is the core idea of a fold-then-reduce pattern: you perform an intermediate fold (aggregation) across chunks in parallel, and then a final reduction aggregates those intermediate results into one value. Additional excerpts describe parallel fold, how it breaks work into sublists and yields multiple partial sums, and then how reduce can combine those partial results. This chain aligns with the fold-then-reduce idea: use a fold to locally aggregate, then reduce to a single final result. Other excerpts discuss the behavior of the reduce operation in the presence of non-determinism and the role of an identity element, which are relevant constraints or considerations when applying the fold-then-reduce idiom in a parallel setting. In sum, the combination of fold and reduce to obtain a single final value is the central concept these excerpts collectively illustrate, supporting the notion of a fold-then-reduce pattern as an idiomatic approach in this context.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns.0.alternate_patterns",
      "citations": [
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        },
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        }
      ],
      "reasoning": "The users target describes a pattern where, for simple aggregations, a high-level abstraction like sum is used, but for more complex scenarios one might create a manual per-thread data structure (a separate accumulator per thread) and then perform a final merge after a scoped, thread-parallel section. The most relevant excerpts discuss per-thread patterns and contention points in parallelism. One excerpt explicitly describes a setup with a rayon threadpool and per-thread data behind mutexes, illustrating the trade-off between per-thread data and synchronization, which is directly connected to the idea of maintaining per-thread accumulators and controlling how they are merged. Another excerpt also centers on per-thread storage patterns and the limitations of atomics, which informs the feasibility of per-thread accumulators and aggregated results, relevant to the notion of a final merge after parallel work. Additional excerpts discuss per-thread reductions and the consequences of per-thread data management, which provide context for how per-thread accumulators could be organized and later merged, aligning with the proposed manual per-thread data structure approach. A related external discussion mentions alternative patterns to Arc<Mutex<T>>, further supporting the broader concept of avoiding heavy locking and orchestrating per-thread work with more granular synchronization strategies, which complements the idea of per-thread accumulators and a post-scope merge. While none of the excerpts provide an explicit code example of rayon::scope creating per-thread accumulators and a final merge, the content collectively supports the core idea of per-thread data management and merging strategies as an alternative to global synchronization. ",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.0.pattern_name",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >"
          ]
        }
      ],
      "reasoning": "The target fine-grained field value references a pattern name that suggests an idiom where iteration short-circuits on an error while performing side-effects. The most directly relevant excerpts describe the TryFold and related fallible iteration constructs. One excerpt states that a fallible operation is executed on each item, which directly captures the core notion of applying a potentially failing operation per element during iteration. Another excerpt presents the signature and documentation of the try_fold method, illustrating how a consumer provides an operation that can fail and how the framework handles such fallibility in a parallel iterator context. A third excerpt discusses a try_reduce_with pattern, showing how fallible reductions are handled and how a None/Some result can reflect error/empty conditions, which reinforces the broader concept of short-circuiting and controlled flow when errors occur. Collectively, these excerpts support the idea of an idiomatic approach to early-exit behavior in fallible iteration, including per-item processing and controlled termination, which aligns with the specified field value about try_for_each for early exit on side-effects.",
      "confidence": "high"
    },
    {
      "field": "state_management_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "Is there an alternative to Arc<Mutex<T>> spam for ...",
          "url": "https://www.reddit.com/r/rust/comments/1htxwwk/is_there_an_alternative_to_arcmutext_spam_for/",
          "excerpts": [
            "Every Mutex is a point of contention. A program with 10 threads all waiting on a single mutex all the time will perform worse than a single..."
          ]
        },
        {
          "title": "Acquiring a per-thread mutex in rayon kills parallelism",
          "url": "https://users.rust-lang.org/t/acquiring-a-per-thread-mutex-in-rayon-kills-parallelism/105931",
          "excerpts": [
            "Jan 27, 2024  The following snippet (playground) creates a rayon threadpool, a vector with per-thread data behind mutexes, and processes data by chunks.",
            "Removing the .lock() call restores parallel execution. Replacing lock by try_lock panics. This should not be the case as each thread should ..."
          ]
        },
        {
          "title": "Per-thread storage patterns & custom reductions",
          "url": "https://users.rust-lang.org/t/per-thread-storage-patterns-custom-reductions/76441",
          "excerpts": [
            "In this specific case, you could just use atomics ( [Playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=395d996dc6e43d27ae995fc576068333) ). (Here is also a [smaller test case](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c476628b05f9e721d455eb54b54c5e9e) that actually manages to complete within the time limit of the Playground.)",
            "Thanks! I'm aware of atomics, and they aren't suitable for performance reasons (with one integer per task, this code is terrible anyway, but I'm very aware of the costs of atomics on CPUs).",
            "They also won't work if we need to do more complicated things like update a compound data structure. Sure, we could use mutexes or some other locking mechanism, but contention would still be a problem."
          ]
        }
      ],
      "reasoning": "The core idea in the field value is to avoid or minimize locking by using patterns that batch work and merge results, thereby reducing contention. The excerpts explicitly caution that every mutex is a point of contention and that a program with many threads waiting on a single mutex will perform worse than simpler designs, which supports the notion that avoiding frequent locks is desirable. Furthermore, the discussions about alternatives to Arc<Mutex<T>> emphasize that a lock-based approach often incurs performance penalties and that developers consider other strategies (such as better threading patterns or atomics) to mitigate those costs. One excerpt notes that atomics may be suitable in some cases where per-task updates are simple, which aligns with the broader fold-then-reduce ethos of performing work locally and only consolidating results in a controlled, minimized synchronization step. Additional excerpts discuss per-thread storage and reductions, acknowledging that while more complex updates to shared structures may be problematic, reductions and carefully designed per-thread patterns can help avoid locking contention. Collectively, these excerpts map onto the field value's emphasis on reducing lock acquisitions and leveraging batching or local processing before merging results, thereby supporting the general approach of fold-then-reduce as a means to improve parallel efficiency and reduce bugs associated with locking. They also acknowledge limitations when the data structure updates are complex, which aligns with the idea that folding-and-reducing should be preferred but may not always be applicable without careful design. In summary, the excerpts substantiate the principle of minimizing locking and using alternative patterns (including batching, atomics, and per-thread reductions) to achieve lower contention, which is in line with the stated fold-then-reduce-focused field value, albeit without a direct explicit naming of the fold-then-reduce pattern in the sources.",
      "confidence": "medium"
    },
    {
      "field": "fallible_and_error_handling_patterns.1.alternate_patterns",
      "citations": [
        {
          "title": "TryFold in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/struct.TryFold.html",
          "excerpts": [
            "d)\n\n#### fn [try\\_fold](trait.ParallelIterator.html.try_fold) <T, R, ID, F>(\n self,\n identity: ID,\n fold\\_op: F,\n) -> [TryFold](struct.TryFold.html \"struct rayon::iter::TryFold\") <Self, R, ID, F>",
            "\n\nExecutes a fallible `OP` on a value returned by `init` with each item",
            "#### fn [try\\_reduce\\_with](trait.ParallelIterator.html.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") >"
          ]
        },
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "`\n\n### `fn [try_reduce_with](.try_reduce_with) <T, OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, T) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nSelf:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") : Try<Ok = T>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using a fallible `op` . Like [`reduce_with()`](.reduce_with) , if the iterator is empty, `None` is returned;\notherwise, `Some` is returned. Beyond that, it behaves like [`try_reduce()`](.try_reduce) for handling `Err` / `None` . For instance, with `Option` items, the return value may be:\n\n* `None` , the iterator was empty\n* `Some(None)` , we stopped after encountering `None` . * `Some(Some(x))` , the entire iterator reduced to `x` ."
          ]
        }
      ],
      "reasoning": "The most directly relevant content describes the TryFold concept as a way to apply a fallible operation across items, which is exactly the kind of operation you would want to perform without first collecting all intermediate results into a Vec<Option<T>>. The description for TryFold shows it is a structured, parallel-capable pattern for processing items with a fallible operation. This supports the idea that instead of accumulating intermediate results in a vector of options and then reducing, one can use a TryFold-like pattern to process items in a streaming or integrated fashion. Additionally, the material discussing try_reduce_with and related constructs demonstrates how parallel reductions can be composed with fallible logic, further illustrating alternative patterns to a purely sequential reduction of collected results. Importantly, there is explicit mention that a sequential try_fold from the standard library is the alternative for small datasets or when parallelism is not required, which directly aligns with the proposed alternate pattern in the field value. Taken together, the excerpts support: (a) the concept of avoiding a manual Vec<Option<T>> collection for intermediate results by using fallible iterator adapters (TryFold), (b) how reductions can be performed in a fallible, possibly parallel fashion (try_reduce_with), and (c) the explicit alternative of using a sequential try_fold when parallelism is unnecessary, which is the precise alternate pattern described in the field value.",
      "confidence": "medium"
    },
    {
      "field": "state_management_patterns.0.code_template",
      "citations": [
        {
          "title": "Rayon Iter - reduce, fold, sum docs",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.ParallelIterator.html",
          "excerpts": [
            "c. And of course `identity()` should\nproduce a true identity.\n### `fn [reduce_with](.reduce_with) <OP>(self, op: OP) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > where  \nOP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") , Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nReduces the items in the iterator into one item using `op` . If the iterator is empty, `None` is returned; otherwise, `Some` is returned. This version of `reduce` is simple but somewhat less\nefficient. If possible, it is better to call `reduce()` , which\nrequires an identity element. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n let sums = [( 0",
            "`\n\n### `fn [fold_with](.fold_with) <F, T>(self, init: T, fold_op: F) -> [FoldWith](struct.FoldWith.html \"struct rayon::iter::FoldWith\") <Self, T, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Clone](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html \"trait core::clone::Clone\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nApplies `fold_op` to the given `init` value with each item of this\niterator, finally producing the value for further use. This works essentially like `fold(|| init.clone(), fold_op)` , except\nit doesnt require the `init` type to be `Sync` , nor any other form\nof added synchronization. # [Examples]()",
            "You can combine `fold` with `reduce` if you want to produce a\nsingle value. This is then roughly equivalent to a map/reduce\ncombination in effect:",
            " );\n```\n\n### `fn [fold](.fold) <T, ID, F>(self, identity: ID, fold_op: F) -> [Fold](struct.Fold.html \"struct rayon::iter::Fold\") <Self, ID, F> where  \nF: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (T, Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nID: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") () -> T + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,  \nT: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nParallel fold is similar to sequential fold except that the\nsequence of items may be subdivided before it is\nfolded. Consider a list of numbers like `22 3 77 89 46` . If\nyou used sequential fold to add them ( `fold(0, |a,b| a+b)` ,\nyou would wind up first adding 0 + 22, then 22 + 3, then 25 +\n77, and so forth.\nThe **parallel fold** works similarly except\nthat it first breaks up your list into sublists, and hence\ninstead of yielding up a single sum at the end, it yields up\nmultiple sums. The number of results is nondeterministic, as\nis the point where the breaks occur.",
            "`\n\n### `fn [sum](.sum) <S>(self) -> S where  \nS: [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") > + [Sum](https://doc.rust-lang.org/nightly/core/iter/traits/accum/trait.Sum.html \"trait core::iter::traits::accum::Sum\") <S>,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSums up the items in the iterator. Note that the order in items will be reduced is not specified,\nso if the `+` operator is not truly [associative](https://en.wikipedia.org/wiki/Associative_property) (as is the\ncase for floating point numbers), then the results are not\nfully deterministic. Basically equivalent to `self.reduce(|| 0, |a, b| a + b)` ,\nexcept that the type of `0` and the `+` operation may vary\ndepending on the type of value being produced. # [Examples]()",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity.",
            "**Note:** unlike a sequential `fold` operation, the order in\nwhich `op` will be applied to reduce the result is not fully\nspecified. So `op` should be [associative](https://en.wikipedia.org/wiki/Associative_property) or else the results\nwill be non-deterministic. And of course `identity()` should\nproduce a true identity."
          ]
        }
      ],
      "reasoning": "The target code template uses a parallel fold to accumulate counts into per-thread HashMaps, then reduces those local maps into a single final map. An excerpt explaining parallel fold is directly relevant because it describes how the sequence may be subdivided and how local results are combined, which mirrors the templates per-thread local accumulation. A second excerpt detailing the exact operation of reduce_with is highly relevant because it maps directly to the templates step of merging per-thread HashMaps. A third excerpt discussing sum semantics alongside the description of fold provides additional general context about how iterators combine results. A fourth excerpt that describes fold_with complements the template by showing an alternative form of folding with an initial value and cloning behavior, which aligns with the pattern of initializing per-thread accumulators. A fifth excerpt notes that the order of application in parallel reductions is not fully specified and that an identity element should be used, which is pertinent to understanding the guarantees (or lack thereof) in the templates reduce phase. A sixth excerpt elaborates on the sum/reduction pattern in the same API family, reinforcing the overall concept of combining per-thread results into a final value. Collectively, these excerpts support interpreting the code template as a canonical parallel map-reduce style histogram construction using per-thread folding followed by a reduction step to merge results.",
      "confidence": "high"
    },
    {
      "field": "order_and_indexing_patterns.1.pattern_name",
      "citations": [
        {
          "title": "IndexedParallelIterator in rayon::iter - Rust",
          "url": "https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "<Self>\n\nDivides an iterator into sequential blocks of exponentially-increasing size. Normally, parallel iterators are recursively divided into tasks in parallel. This adaptor changes the default behavior by splitting the iterator into a **sequence** of parallel iterators of increasing sizes. Sizes grow exponentially in order to avoid creating\ntoo many blocks. This also allows to balance the current block with all previous ones. This can have many applications but the most notable ones are:\n\n* better performance with [`find_first()`](trait.ParallelIterator.html.find_first \"method rayon::iter::ParallelIterator::find\\_first\")\n* more predictable performance with [`find_any()`](trait.ParallelIterator.html.find_any \"method rayon::iter::ParallelIterator::find\\_any\") or any interruptible computation\n\n##### []() Examples\n\n```\nuse rayon::prelude:: * ;\nassert_eq! (( 0 .. 10_000 ).into_par_iter()\n                      .by_exponential_blocks()\n                      .find_first(| & e| e== 4_999 ), Some ( 4_999 ))\n```\n\nIn this example, without blocks, rayon will split the initial range into two but all work\non the right hand side (from 5,000 onwards) is **useless** since the sequential algorithm\nnever goes there.\nThis means that if two threads are used there will be **no** speedup **at\nall** . `by_exponential_blocks` on the other hand will start with the leftmost range from 0\nto `p` (threads number), continue with p to 3p, the 3p to 7p\n\nEach subrange is treated in parallel, while all subranges are treated sequentially. We therefore ensure a logarithmic number of blocks (and overhead) while guaranteeing\nwe stop at the first block containing the searched data. [Source](../../src/rayon/iter/mod.rs.html)\n",
            "html) >\n\nwhere\n P: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) \\+ [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") \\+ [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. ##### []",
            "Searches for the sequentially **last** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_last` , once a match is found,\nall attempts to the left of the match will be stopped, while\nattempts to the right must continue in case a later match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so last may be nebulous. When the\norder doesnt actually matter to you, `position_any` is a better\nchoice."
          ]
        },
        {
          "title": "rayon::iter::IndexedParallelIterator - Rust",
          "url": "https://rust-lang.github.io/hashbrown/rayon/iter/trait.IndexedParallelIterator.html",
          "excerpts": [
            "### `fn [position_first](.position_first) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for the sequentially **first** item in the parallel iterator\nthat matches the given predicate, and returns its index. Like `ParallelIterator::find_first` , once a match is found,\nall attempts to the right of the match will be stopped, while\nattempts to the left must continue in case an earlier match\nis found. Note that not all parallel iterators have a useful order, much like\nsequential `HashMap` iteration, so first may be nebulous. If you\njust want the first match that discovered anywhere in the iterator, `position_any` is a better choice. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n assert_eq! ( a .\npar_iter (). position_first ( | & x | x = = 3 ), Some ( 2 ));\n\n assert_eq! ( a . par_iter (). position_first ( | & x | x = = 100 ), None );\n```\n",
            "### `fn [position_any](.position_any) <P>(self, predicate: P) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") < [usize](https://doc.rust-lang.org/nightly/std/primitive.usize.html) > where  \nP: [Fn](https://doc.rust-lang.org/nightly/core/ops/function/trait.Fn.html \"trait core::ops::function::Fn\") (Self:: [Item](trait.ParallelIterator.html.Item \"type rayon::iter::ParallelIterator::Item\") ) -> [bool](https://doc.rust-lang.org/nightly/std/primitive.bool.html) + [Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html \"trait core::marker::Sync\") + [Send](https://doc.rust-lang.org/nightly/core/marker/trait.Send.html \"trait core::marker::Send\") ,` [[src]](../../src/rayon/iter/mod.rs.html \"goto source code\")\n\nSearches for **some** item in the parallel iterator that\nmatches the given predicate, and returns its index. Like `ParallelIterator::find_any` , the parallel search will not\nnecessarily find the **first** match, and once a match is\nfound well attempt to stop processing any more. # [Examples]()\n\n```\n use rayon::prelude :: * ;\n\n let a = [ 1 , 2 , 3 , 3 ];\n\n let i = a . par_iter (). position_any ( | & x | x = = 3 ). expect ( \"found\" );\n assert! ( i = = 2 | | i = = 3 );\n\n assert_eq! ( a . par_iter ().\nposition_any ( | & x | x = = 100 ), None );\n```"
          ]
        }
      ],
      "reasoning": "The finegrained field value concerns the difference between a deterministic first-match approach and a non-deterministic any-match approach in the context of parallel iterators. The most directly relevant excerpts explicitly discuss the behavior of find_first and find_any: one excerpt explains that find_first stops all further right-side attempts once a match is found, emphasizing determinism, while also noting that find_any may not locate the first match and may stop processing earlier due to discovery, highlighting non-determinism. Another excerpt states that searches for the first item in a parallel iterator and describes the deterministic nature of the first match, reinforcing the contrast. Additional excerpts describe how find_any is used as a non-deterministic alternative, and how position_any may return any index rather than the first, further illustrating the non-deterministic pattern. Collectively, these excerpts map directly to the concepts of deterministic versus non-deterministic patterns in the specified field value, including the naming and semantics of find_first versus find_any, and their implications for ordering and stopping behavior in indexing patterns. When considered together, they provide a coherent explanation of how the two patterns differ and when each is appropriate in a parallel iteration context.",
      "confidence": "high"
    }
  ],
  "outputSchema": {
    "type": "object",
    "properties": {
      "introduction_to_rayon_idioms": {
        "type": "string",
        "description": "A high-level overview of Rayon's design philosophy and what makes a pattern 'idiomatic' in its context, focusing on data-race freedom, efficiency, and readability as requested by the user."
      },
      "parallel_iterator_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific parallel iterator pattern (e.g., 'par_iter', 'par_iter_mut')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of core parallel iteration patterns (`par_iter`, `par_iter_mut`, `into_par_iter`). For each pattern, provide a code template, the context for its use (e.g., immutable vs. mutable vs. consuming iteration), common anti-patterns (e.g., using on tiny workloads), and alternate patterns (e.g., sequential `iter`)."
      },
      "map_reduce_aggregation_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific map-reduce pattern (e.g., '.map().sum()', '.reduce()')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of idiomatic patterns for parallel aggregation using map-reduce constructs like `.map(...).sum()`, `.reduce()`, and `.fold().reduce()`. For each, provide a code template, context (e.g., numeric aggregation, histogram building), anti-patterns (e.g., non-associative operations), and alternates (e.g., sequential reduce)."
      },
      "fallible_and_error_handling_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific fallible pattern (e.g., 'try_for_each', 'try_reduce')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of patterns for handling errors and early termination in parallel iterators using `try_for_each`, `try_fold`, and `try_reduce`. For each, provide a code template, context (e.g., validation, parsing), anti-patterns (e.g., panicking instead of returning a Result), and alternates (e.g., collecting all Results)."
      },
      "divide_and_conquer_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific divide-and-conquer pattern (e.g., 'rayon::join')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of patterns for divide-and-conquer algorithms, focusing on `rayon::join`. For each, provide a code template for recursive splitting (e.g., quicksort), context (e.g., balanced, CPU-bound subproblems), anti-patterns (e.g., deep recursion without a base case), and alternate patterns (e.g., `rayon::scope`)."
      },
      "structured_parallelism_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific structured parallelism pattern (e.g., 'rayon::scope')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of patterns for structured parallelism using `rayon::scope` to spawn multiple tasks that can borrow from the local stack. For each, provide a code template, context (e.g., lifetime-safe task orchestration), anti-patterns (e.g., using `std::thread::spawn` with non-'static data), and alternates (`rayon::join`)."
      },
      "parallel_slice_processing_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific slice processing pattern (e.g., 'par_chunks', 'par_windows')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of idioms for processing slices in parallel using methods from `ParallelSlice` and `ParallelSliceMut`, such as `par_chunks`, `par_windows`, and `par_split`. For each, provide a code template, context (e.g., image processing, matrix operations), anti-patterns (e.g., tiny chunk sizes), and alternates (e.g., manual chunking)."
      },
      "parallel_sorting_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific sorting pattern (e.g., 'par_sort', 'par_sort_unstable_by_key')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of patterns for parallel sorting using `par_sort`, `par_sort_unstable`, and their variants. For each, provide code templates, context (e.g., stable vs. unstable, expensive comparisons), anti-patterns (e.g., sorting small arrays), and alternates (e.g., sequential sort)."
      },
      "parallel_collection_building_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific collection building pattern (e.g., 'collect()', 'par_extend()')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of idioms for building collections in parallel using `FromParallelIterator` (`collect()`) and `ParallelExtend` (`par_extend()`). For each, provide code templates for `Vec`, `HashMap`, etc., context (high-throughput construction), anti-patterns (pushing to a shared `Mutex`-wrapped collection), and alternates (fold-then-reduce)."
      },
      "order_and_indexing_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific ordering pattern (e.g., 'enumerate', 'find_first vs find_any')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of patterns for handling order and determinism using `IndexedParallelIterator`, including `enumerate`, `zip`, and the distinction between `find_first` (deterministic) and `find_any` (non-deterministic). For each, provide code templates, context (algorithms requiring stable order), anti-patterns (assuming order on non-indexed iterators), and alternates (tagging with indices and re-sorting)."
      },
      "interoperability_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific interoperability pattern (e.g., 'par_bridge()', 'zip()')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of idioms for bridging sequential and parallel code, focusing on `par_bridge()`. For each, provide a code template, context (consuming from a channel or file), anti-patterns (producer/consumer bottlenecks, deadlocks), and alternates (collecting into a Vec first)."
      },
      "state_management_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific state management pattern (e.g., 'fold-then-reduce', 'Arc<Mutex<T>>')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of patterns for managing state in parallel computations. Covers the idiomatic 'thread-local fold then reduce' pattern to avoid locks, and the safe use of atomics or `Arc<Mutex<T>>` when unavoidable. For each, provide code templates, context (e.g., histogramming), anti-patterns (locking in hot loops), and alternates."
      },
      "configuration_and_tuning_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific configuration pattern (e.g., 'ThreadPoolBuilder', 'with_min_len')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of idioms for configuring Rayon's execution, including custom thread pools (`ThreadPoolBuilder`) and granularity tuning (`with_min_len`). For each, provide code templates, context (e.g., limiting concurrency), anti-patterns (e.g., creating many short-lived pools), and alternates (e.g., `RAYON_NUM_THREADS` environment variable)."
      },
      "platform_specific_patterns_wasm": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific WASM pattern (e.g., 'wasm-bindgen-rayon setup', 'Sequential Fallback')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of idioms for using Rayon in WebAssembly (WASM) contexts, focusing on the `wasm-bindgen-rayon` adapter. For each, provide code templates for setup, context (browser worker pools), anti-patterns (expecting parallelism without `SharedArrayBuffer`), and alternates (sequential fallback for compatibility)."
      },
      "testing_and_reproducibility_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "pattern_name": {
              "type": "string",
              "description": "The name of the specific testing pattern (e.g., 'Per-Test Custom Thread Pool', 'Single-Threaded Mode')."
            },
            "code_template": {
              "type": "string",
              "description": "A concise code snippet demonstrating the pattern."
            },
            "usage_context": {
              "type": "string",
              "description": "Explanation of when to use this pattern and how it leads to low bugs or high efficiency."
            },
            "anti_patterns": {
              "type": "string",
              "description": "Description of contexts where this pattern is an anti-pattern or common pitfalls."
            },
            "alternate_patterns": {
              "type": "string",
              "description": "A list of alternative patterns that can be used instead."
            }
          },
          "required": [
            "pattern_name",
            "code_template",
            "usage_context",
            "anti_patterns",
            "alternate_patterns"
          ],
          "additionalProperties": false
        },
        "description": "A list of patterns for writing reliable and reproducible tests for Rayon-based code. Covers isolating tests with custom thread pools (`install`) and controlling thread counts. For each, provide code templates, context (e.g., flaky tests in CI), anti-patterns (relying on the global pool), and alternates (single-threaded mode for debugging)."
      },
      "demonstrated_pipelines_from_rayon_demo": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "demo_name": {
              "type": "string",
              "description": "The name of the demonstration from the rayon-demo directory (e.g., 'N-body Simulation', 'Game of Life')."
            },
            "illustrated_pattern": {
              "type": "string",
              "description": "The primary idiomatic pattern illustrated by the demo."
            },
            "code_template_concept": {
              "type": "string",
              "description": "A conceptual description or snippet of the code pattern used, such as toggling between sequential and parallel versions."
            },
            "usage_context": {
              "type": "string",
              "description": "The context in which this pipeline is used, such as for embarrassingly parallel numeric kernels."
            },
            "anti_patterns_avoided": {
              "type": "string",
              "description": "Anti-patterns that the demo's implementation successfully avoids, like parallelizing tiny kernels."
            },
            "alternate_patterns_shown": {
              "type": "string",
              "description": "Alternative or advanced patterns demonstrated, such as Z-order traversal for cache locality."
            }
          },
          "required": [
            "demo_name",
            "illustrated_pattern",
            "code_template_concept",
            "usage_context",
            "anti_patterns_avoided",
            "alternate_patterns_shown"
          ],
          "additionalProperties": false
        },
        "description": "A list of end-to-end idiomatic pipelines illustrated in the `rayon-demo` directory, such as the N-body simulation and Game of Life. For each, describe the pattern (e.g., toggling between sequential and parallel), context (embarrassingly parallel kernels), anti-patterns avoided (e.g., tiny kernels), and alternate patterns shown (e.g., Z-order traversal for cache locality)."
      }
    },
    "required": [
      "introduction_to_rayon_idioms",
      "parallel_iterator_patterns",
      "map_reduce_aggregation_patterns",
      "fallible_and_error_handling_patterns",
      "divide_and_conquer_patterns",
      "structured_parallelism_patterns",
      "parallel_slice_processing_patterns",
      "parallel_sorting_patterns",
      "parallel_collection_building_patterns",
      "order_and_indexing_patterns",
      "interoperability_patterns",
      "state_management_patterns",
      "configuration_and_tuning_patterns",
      "platform_specific_patterns_wasm",
      "testing_and_reproducibility_patterns",
      "demonstrated_pipelines_from_rayon_demo"
    ],
    "additionalProperties": false
  }
}