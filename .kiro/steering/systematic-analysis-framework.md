---
inclusion: always
---

# Systematic Analysis Framework for Complex Knowledge Extraction

## Meta-Pattern: Chunked Processing with Multi-Perspective Analysis

This steering document establishes a systematic approach for extracting comprehensive insights from large, complex documentation or content repositories. Based on proven methodologies for strategic intelligence extraction.

## Core Methodology

### 1. Content Segmentation Strategy

**Principle**: Break large content into manageable, overlapping chunks to ensure thorough analysis without cognitive overload.

**Implementation Pattern**:
- Process content in fixed-size chunks (typically 300-500 lines for text, or logical units for code)
- Use 10-20 line overlap between chunks to maintain context continuity
- Track progress systematically with chunk identifiers and source mapping
- Maintain source traceability throughout the process

### 2. Multi-Persona Expert Council Framework

**Principle**: Activate diverse expert perspectives to ensure comprehensive analysis and challenge assumptions.

**Required Personas**:
- **Domain Expert**: Deep technical knowledge of the subject matter
- **Strategic Analyst**: Business and competitive positioning insights
- **Implementation Specialist**: Practical execution and technical feasibility
- **User Experience Advocate**: End-user perspective and workflow optimization
- **Skeptical Engineer/Devil's Advocate**: Challenge assumptions and identify risks (MANDATORY)

**Council Process**:
1. Each persona provides opening analysis
2. Skeptical Engineer challenges primary assertions
3. Other experts respond to challenges
4. Synthesize refined insights into cohesive conclusions

### 3. Conceptual Blending for Innovation

**Principle**: Fuse core concepts with unexpected distant domains to generate novel insights.

**Process**:
- Identify conventional approaches first
- Generate 3+ alternative approaches using conceptual blending
- Blend with distant domains (e.g., biology, physics, economics, psychology)
- Evaluate and select most promising hybrid approach
- Justify selection with clear reasoning

### 4. Verification and Quality Assurance

**Principle**: Generate fact-checkable questions to validate major claims and insights.

**Implementation**:
- Generate 5-10 specific, verifiable questions per major insight
- Answer verification questions based on available evidence
- Identify and correct inconsistencies or weaknesses
- Ensure claims are grounded and actionable

## Task Breakdown Patterns

### Pattern 1: Systematic Processing Tasks

**Structure**: Break large processing jobs into measurable, trackable units

**Example Format**:
```
- [ ] Process [Source] chunks X-Y (lines A-B)
  - Apply analytical framework to each chunk
  - Extract [specific insight types]
  - Maintain [quality standards]
  - Cross-reference with [previous findings]
  - _Requirements: [specific requirement references]_
```

**Key Characteristics**:
- Specific line ranges or logical boundaries
- Clear deliverables for each chunk
- Progress tracking built into task structure
- Quality assurance steps included
- Requirement traceability maintained

### Pattern 2: Synthesis and Organization Tasks

**Structure**: Transform extracted insights into structured, actionable formats

**Example Format**:
```
- [ ] Categorize [insights] by [classification system]
  - Organize by [primary dimension] and [secondary dimension]
  - Ensure each [item] includes [required elements]
  - Cross-reference [related items] and identify [dependencies]
  - _Requirements: [specific requirement references]_
```

**Key Characteristics**:
- Clear categorization criteria
- Required elements specified for each item
- Cross-referencing and relationship mapping
- Dependency identification

### Pattern 3: Quality Assurance Tasks

**Structure**: Validate completeness, consistency, and quality of extracted insights

**Example Format**:
```
- [ ] Verify [aspect] of [deliverable]
  - Confirm [specific quality criteria]
  - Validate [consistency requirements]
  - Ensure [completeness standards]
  - Document [traceability requirements]
  - _Requirements: [specific requirement references]_
```

## Application Guidelines

### When to Use This Framework

- **Large Documentation Analysis**: Processing extensive technical documentation, specifications, or advisory materials
- **Strategic Intelligence Extraction**: Extracting actionable insights from complex source materials
- **Multi-Source Synthesis**: Combining insights from multiple documents or data sources
- **Comprehensive Research Projects**: Ensuring thorough coverage of complex subject matter

### Task Granularity Principles

1. **Measurable Progress**: Each task should represent 2-4 hours of focused work
2. **Clear Deliverables**: Specific outputs that can be verified and validated
3. **Incremental Value**: Each task builds on previous work and adds measurable value
4. **Quality Gates**: Built-in verification and quality assurance steps
5. **Requirement Traceability**: Clear links to specific requirements or objectives

### Progress Tracking Standards

- **Completion Metrics**: Quantifiable measures of progress (chunks processed, insights extracted)
- **Quality Indicators**: Verification questions answered, cross-references validated
- **Source Mapping**: Traceability from insights back to source material
- **Milestone Markers**: Clear checkpoints for major phases of work

## Quality Standards

### Analysis Rigor
- Apply systematic methodology to every content unit
- Maintain consistent analytical standards throughout
- Document reasoning and decision-making process
- Validate insights through multiple perspectives

### Output Quality
- Ensure actionable and implementable recommendations
- Maintain logical consistency across all insights
- Provide sufficient detail for implementation
- Include success metrics and validation criteria

### Documentation Standards
- Clear source attribution for all insights
- Structured format for easy navigation and reference
- Cross-references between related concepts
- Progress tracking and completion verification

This framework ensures comprehensive, rigorous analysis while maintaining systematic progress tracking and quality assurance throughout complex knowledge extraction projects.


# Use Folder analysis scripts to check your work and progress 

Use folder analysis script such as /home/amuldotexe/Desktop/Game20250926/number-12-grimmauld-place/scripts/tree-with-wc.sh to constantly check your progress -and you complete a file make a simple git commit with some details on the progress